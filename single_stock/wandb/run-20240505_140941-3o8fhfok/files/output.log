
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 1/50
212/212 [==============================] - 3s 7ms/step - loss: 0.0045 - val_loss: 0.0011
Epoch 2/50
212/212 [==============================] - 1s 5ms/step - loss: 9.5599e-04 - val_loss: 1.8103e-04
Epoch 3/50
212/212 [==============================] - 1s 5ms/step - loss: 7.2589e-04 - val_loss: 1.8093e-04
Epoch 4/50
212/212 [==============================] - 1s 5ms/step - loss: 5.3320e-04 - val_loss: 2.8893e-04
Epoch 5/50
212/212 [==============================] - 1s 5ms/step - loss: 5.7971e-04 - val_loss: 9.7264e-05
Epoch 6/50
212/212 [==============================] - 1s 5ms/step - loss: 5.0802e-04 - val_loss: 7.4623e-05
Epoch 7/50
212/212 [==============================] - 1s 5ms/step - loss: 4.6035e-04 - val_loss: 8.0937e-04
Epoch 8/50
212/212 [==============================] - 1s 5ms/step - loss: 4.1251e-04 - val_loss: 1.4477e-04
Epoch 9/50
212/212 [==============================] - 1s 5ms/step - loss: 4.0822e-04 - val_loss: 5.2159e-04
Epoch 10/50
212/212 [==============================] - 1s 5ms/step - loss: 4.5515e-04 - val_loss: 7.7809e-04
Epoch 11/50
212/212 [==============================] - 1s 5ms/step - loss: 3.4361e-04 - val_loss: 1.6264e-04
Epoch 12/50
212/212 [==============================] - 1s 5ms/step - loss: 3.6647e-04 - val_loss: 1.7093e-04
Epoch 13/50
212/212 [==============================] - 1s 5ms/step - loss: 3.3637e-04 - val_loss: 7.3794e-05
Epoch 14/50
212/212 [==============================] - 1s 5ms/step - loss: 3.3422e-04 - val_loss: 4.4542e-04
Epoch 15/50
212/212 [==============================] - 1s 5ms/step - loss: 3.4263e-04 - val_loss: 1.0963e-04
Epoch 16/50
212/212 [==============================] - 1s 5ms/step - loss: 3.1981e-04 - val_loss: 4.3185e-04
Epoch 17/50
212/212 [==============================] - 1s 5ms/step - loss: 3.0148e-04 - val_loss: 7.2178e-05
Epoch 18/50
212/212 [==============================] - 1s 5ms/step - loss: 2.8716e-04 - val_loss: 2.2319e-04
Epoch 19/50
212/212 [==============================] - 1s 5ms/step - loss: 2.9106e-04 - val_loss: 1.0310e-04
Epoch 20/50
212/212 [==============================] - 1s 5ms/step - loss: 3.3888e-04 - val_loss: 7.4455e-04
Epoch 21/50
212/212 [==============================] - 1s 5ms/step - loss: 2.9234e-04 - val_loss: 5.7035e-05
Epoch 22/50
212/212 [==============================] - 1s 5ms/step - loss: 3.0370e-04 - val_loss: 4.6932e-05
Epoch 23/50
212/212 [==============================] - 1s 5ms/step - loss: 2.7055e-04 - val_loss: 5.7281e-05
Epoch 24/50
212/212 [==============================] - 1s 5ms/step - loss: 2.7478e-04 - val_loss: 3.0690e-04
Epoch 25/50
212/212 [==============================] - 1s 5ms/step - loss: 2.9595e-04 - val_loss: 2.2143e-04
Epoch 26/50
212/212 [==============================] - 1s 5ms/step - loss: 2.6996e-04 - val_loss: 2.5689e-04
Epoch 27/50
212/212 [==============================] - 1s 5ms/step - loss: 2.8477e-04 - val_loss: 0.0023
Epoch 28/50
212/212 [==============================] - 1s 5ms/step - loss: 3.0798e-04 - val_loss: 1.0787e-04
Epoch 29/50
212/212 [==============================] - 1s 5ms/step - loss: 3.0698e-04 - val_loss: 2.8380e-04
Epoch 30/50
212/212 [==============================] - 1s 5ms/step - loss: 3.3197e-04 - val_loss: 1.9022e-04
Epoch 31/50
212/212 [==============================] - 1s 5ms/step - loss: 2.8086e-04 - val_loss: 7.3354e-05
Epoch 32/50
181/212 [========================>.....] - ETA: 0s - loss: 2.5569e-04
212/212 [==============================] - 1s 5ms/step - loss: 2.6414e-04 - val_loss: 2.8239e-04
53/53 [==============================] - 0s 1ms/step
53/53 [==============================] - 0s 2ms/step
CSCO : 4.69318633723878e-05 0.00529454430492112 0.0068506834237459695
CSCO : 53.91968911039742 34.86776929979485 -19.05191981060257
Data for CSCO appended successfully.
Epoch 1/50
111/111 [==============================] - 3s 8ms/step - loss: 0.0261 - val_loss: 0.0013
Epoch 2/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0029 - val_loss: 0.0010
Epoch 3/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 8.7746e-04
Epoch 4/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0022 - val_loss: 7.6060e-04
Epoch 5/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 8.0795e-04
Epoch 6/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 6.0824e-04
Epoch 7/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 0.0016
Epoch 8/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 9.4442e-04
Epoch 9/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0022
Epoch 10/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0012
Epoch 11/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 4.4861e-04
Epoch 12/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 5.6704e-04
Epoch 13/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 7.1780e-04
Epoch 14/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 8.7322e-04
Epoch 15/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 4.5418e-04
Epoch 16/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 5.9277e-04
Epoch 17/50
Epoch 19/50============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 7.8358e-04
Epoch 18/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 4.7000e-04
Epoch 19/50============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 7.8358e-04
111/111 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 7.1288e-04
Epoch 20/50
111/111 [==============================] - 1s 5ms/step - loss: 9.5745e-04 - val_loss: 7.2391e-04
Epoch 21/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 4.0539e-04
Epoch 22/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 9.8292e-04
Epoch 23/50
111/111 [==============================] - 1s 5ms/step - loss: 9.5745e-04 - val_loss: 7.2391e-04
Epoch 24/50
 73/111 [==================>...........] - ETA: 0s - loss: 8.6884e-04 - val_loss: 4.4165e-04
Epoch 25/50
111/111 [==============================] - 1s 5ms/step - loss: 9.7565e-04 - val_loss: 4.1361e-04
Epoch 26/50
111/111 [==============================] - 1s 5ms/step - loss: 9.8581e-04 - val_loss: 3.8621e-04
Epoch 27/50
111/111 [==============================] - 1s 5ms/step - loss: 8.8881e-04 - val_loss: 4.5347e-04
Epoch 28/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 4.2221e-04
Epoch 29/50
111/111 [==============================] - 1s 5ms/step - loss: 8.9726e-04 - val_loss: 5.0631e-04
Epoch 30/50
111/111 [==============================] - 1s 5ms/step - loss: 8.7231e-04 - val_loss: 3.9610e-04
Epoch 31/50
 58/111 [==============>...............] - ETA: 0s - loss: 8.6103e-04
111/111 [==============================] - 1s 5ms/step - loss: 7.7953e-04 - val_loss: 7.2635e-04
Epoch 33/50
111/111 [==============================] - 1s 5ms/step - loss: 7.7894e-04 - val_loss: 4.4655e-04
Epoch 34/50
111/111 [==============================] - 1s 5ms/step - loss: 8.0943e-04 - val_loss: 5.3039e-04
Epoch 35/50
 49/111 [============>.................] - ETA: 0s - loss: 7.0928e-04
111/111 [==============================] - 1s 5ms/step - loss: 7.7953e-04 - val_loss: 7.2635e-04
111/111 [==============================] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
28/28 [==============================] - 0s 1ms/step
28/28 [==============================] - 0s 1ms/step
UAL : 0.0003862061912814982 0.013314544619299283 0.01965212943376616
UAL : 37.87905254234436 29.492990490691962 -8.386062051652399
Data for UAL appended successfully.
Epoch 1/50
111/111 [==============================] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
Epoch 2/50=============================] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
Epoch 2/50=============================] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
Epoch 6/50=============================] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
Epoch 6/50=============================] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
Epoch 6/50=============================] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
Epoch 10/50============================] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
Epoch 10/50============================] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
Data for TROW appended successfully.===] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
Data for TROW appended successfully.===] - 1s 5ms/step - loss: 8.0032e-04 - val_loss: 5.1326e-04
143/146 [============================>.] - ETA: 0s - loss: 3.4775e-04e-04 - val_loss: 5.1326e-04
146/146 [==============================] - 1s 5ms/step - loss: 3.4562e-04 - val_loss: 0.0015e-04
146/146 [==============================] - 1s 5ms/step - loss: 2.1138e-04 - val_loss: 0.0018e-04
37/37 [==============================] - 0s 1ms/stepep - loss: 2.1138e-04 - val_loss: 0.0018e-04
37/37 [==============================] - 0s 1ms/stepep - loss: 2.1138e-04 - val_loss: 0.0018e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
37/37 [==============================] - 0s 1ms/stepep - loss: 2.1138e-04 - val_loss: 0.0018e-04
Epoch 3/50===========================] - 0s 1ms/stepep - loss: 2.1138e-04 - val_loss: 0.0018e-04
Epoch 3/50===========================] - 0s 1ms/stepep - loss: 2.1138e-04 - val_loss: 0.0018e-04
Epoch 7/50===========================] - 0s 1ms/stepep - loss: 2.1138e-04 - val_loss: 0.0018e-04
Epoch 7/50===========================] - 0s 1ms/stepep - loss: 2.1138e-04 - val_loss: 0.0018e-04
Epoch 11/50==========================] - 0s 1ms/stepep - loss: 2.1138e-04 - val_loss: 0.0018e-04
Epoch 11/50==========================] - 0s 1ms/stepep - loss: 2.1138e-04 - val_loss: 0.0018e-04
NVR : 0.00032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
NVR : 0.00032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 3/50032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 6/50032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 8/50032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 11/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 14/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 16/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 19/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 22/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 25/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 28/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 31/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 34/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 36/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 39/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 42/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 45/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 47/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 50/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 50/5032357582005098354 0.01462208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Data for TPR appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Data for TPR appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Data for TPR appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 5/50PR appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 7/50PR appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 7/50PR appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 10/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 12/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 12/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 15/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 17/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 17/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 20/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 20/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 23/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 23/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 26/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 28/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 28/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 31/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 33/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 33/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 36/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 36/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 39/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 39/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 42/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 42/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
Epoch 45/50R appended successfully.2208641418365 0.017988213364616948e-04 - val_loss: 0.0018e-04
DVN : 0.00011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
DVN : 0.00011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 3/50011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 6/50011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 10/5011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 13/5011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 13/5011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 13/5011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 13/5011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 13/5011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 13/5011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 13/5011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 13/5011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 13/5011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 9/50011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 9/50011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 9/50011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 9/50011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
Epoch 9/50011038836007813394 0.007232023999385791 0.010506586509334701-04 - val_loss: 0.0018e-04
MRO : 0.0003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
MRO : 0.0003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
MRO : 0.0003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
MRO : 0.0003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
MRO : 0.0003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
MRO : 0.0003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
Epoch 6/5003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
Epoch 6/5003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
Epoch 6/5003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
Epoch 6/5003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
Epoch 6/5003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
Epoch 6/5003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
Epoch 6/5003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
Epoch 6/5003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
Epoch 6/5003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
Epoch 6/5003400547656069667 0.013268361374761261 0.0184405738958137271-04 - val_loss: 0.0018e-04
BA : 0.0005999726991529625 0.013841603672804619 0.02449434014528586271-04 - val_loss: 0.0018e-04
BA : 0.0005999726991529625 0.013841603672804619 0.02449434014528586271-04 - val_loss: 0.0018e-04
Epoch 3/505999726991529625 0.013841603672804619 0.02449434014528586271-04 - val_loss: 0.0018e-04
Epoch 5/505999726991529625 0.013841603672804619 0.02449434014528586271-04 - val_loss: 0.0018e-04
Epoch 8/505999726991529625 0.013841603672804619 0.02449434014528586271-04 - val_loss: 0.0018e-04
Epoch 10/50999726991529625 0.013841603672804619 0.02449434014528586271-04 - val_loss: 0.0018e-04
Epoch 12/50999726991529625 0.013841603672804619 0.02449434014528586271-04 - val_loss: 0.0018e-04
51/51 [==============================] - 0s 1ms/step449434014528586271-04 - val_loss: 0.0018e-04
51/51 [==============================] - 0s 1ms/step449434014528586271-04 - val_loss: 0.0018e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
51/51 [==============================] - 0s 1ms/step449434014528586271-04 - val_loss: 0.0018e-04
Epoch 4/50===========================] - 0s 1ms/step449434014528586271-04 - val_loss: 0.0018e-04
Epoch 6/50===========================] - 0s 1ms/step449434014528586271-04 - val_loss: 0.0018e-04
Epoch 8/50===========================] - 0s 1ms/step449434014528586271-04 - val_loss: 0.0018e-04
Epoch 10/50==========================] - 0s 1ms/step449434014528586271-04 - val_loss: 0.0018e-04
Epoch 13/50==========================] - 0s 1ms/step449434014528586271-04 - val_loss: 0.0018e-04
Epoch 13/50==========================] - 0s 1ms/step449434014528586271-04 - val_loss: 0.0018e-04
Epoch 13/50==========================] - 0s 1ms/step449434014528586271-04 - val_loss: 0.0018e-04
GILD : 81.77009549143963 69.41463844559038 -12.35545704584925528586271-04 - val_loss: 0.0018e-04
GILD : 81.77009549143963 69.41463844559038 -12.35545704584925528586271-04 - val_loss: 0.0018e-04
Epoch 4/5077009549143963 69.41463844559038 -12.35545704584925528586271-04 - val_loss: 0.0018e-04
Epoch 4/5077009549143963 69.41463844559038 -12.35545704584925528586271-04 - val_loss: 0.0018e-04
Epoch 4/5077009549143963 69.41463844559038 -12.35545704584925528586271-04 - val_loss: 0.0018e-04