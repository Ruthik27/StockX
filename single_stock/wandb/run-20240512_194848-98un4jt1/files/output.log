Columns available: Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')
Epoch 1/50
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
203/203 [==============================] - 3s 4ms/step - loss: 0.0214 - val_loss: 0.0212
Epoch 2/50
203/203 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0199
Epoch 3/50
203/203 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0201
Epoch 4/50
203/203 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 0.0201
Epoch 5/50
203/203 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0202
Epoch 6/50
203/203 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0204
Epoch 7/50
203/203 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0203
Epoch 8/50
203/203 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0203
Epoch 9/50
203/203 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0203
Epoch 10/50
203/203 [==============================] - 1s 2ms/step - loss: 0.0011 - val_loss: 0.0202
Epoch 11/50
203/203 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0202
Epoch 12/50
203/203 [==============================] - 0s 2ms/step - loss: 9.6615e-04 - val_loss: 0.0201
51/51 [==============================] - 0s 821us/step
KeyError: 'Close' column is not available in the dataset for ticker ZBRA.
An error occurred while transforming prediction: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.
Unable to save data for ZBRA due to missing information.
Columns available: Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')
Epoch 1/50
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
1/1 [==============================] - 2s 2s/step - loss: 0.3823 - val_loss: 5.9798e-04
Epoch 2/50
1/1 [==============================] - 0s 15ms/step - loss: 0.3602 - val_loss: 0.0016
Epoch 3/50
1/1 [==============================] - 0s 15ms/step - loss: 0.3503 - val_loss: 0.0031
Epoch 4/50
1/1 [==============================] - 0s 14ms/step - loss: 0.3303 - val_loss: 0.0052
Epoch 5/50
1/1 [==============================] - 0s 14ms/step - loss: 0.3141 - val_loss: 0.0078
Epoch 6/50
1/1 [==============================] - 0s 14ms/step - loss: 0.3043 - val_loss: 0.0112
Epoch 7/50
1/1 [==============================] - 0s 15ms/step - loss: 0.2832 - val_loss: 0.0154
Epoch 8/50
1/1 [==============================] - 0s 14ms/step - loss: 0.2783 - val_loss: 0.0205
Epoch 9/50
1/1 [==============================] - 0s 14ms/step - loss: 0.2649 - val_loss: 0.0266
Epoch 10/50
1/1 [==============================] - 0s 14ms/step - loss: 0.2380 - val_loss: 0.0338
Epoch 11/50
1/1 [==============================] - 0s 15ms/step - loss: 0.2279 - val_loss: 0.0424
1/1 [==============================] - 0s 350ms/step
KeyError: 'Close' column is not available in the dataset for ticker VLTO.
An error occurred while transforming prediction: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.
Unable to save data for VLTO due to missing information.
Columns available: Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')
Epoch 1/50
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
68/68 [==============================] - 2s 8ms/step - loss: 0.0820 - val_loss: 0.0713
Epoch 2/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0518
Epoch 3/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0511
Epoch 4/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0528
Epoch 5/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0489
Epoch 6/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0490
Epoch 7/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0442
Epoch 8/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0416
Epoch 9/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0408
Epoch 10/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0443
Epoch 11/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0390
Epoch 12/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0416
Epoch 13/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0355
Epoch 14/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0371
Epoch 15/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0315
Epoch 16/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0270
Epoch 17/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0261
Epoch 18/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0243
Epoch 19/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0182
Epoch 20/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0198
Epoch 21/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0121
Epoch 22/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0118
Epoch 23/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0111
Epoch 24/50
Epoch 27/50==========================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0081
Epoch 25/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0071
Epoch 26/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0066
Epoch 27/50==========================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0081
68/68 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0056
Epoch 28/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0055
Epoch 29/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0058
Epoch 30/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0054
Epoch 31/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0043
Epoch 32/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0054
Epoch 33/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0053
Epoch 34/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0052
Epoch 35/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0042
Epoch 36/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0045
Epoch 37/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0046
Epoch 38/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0047
Epoch 39/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0040
Epoch 40/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0054
Epoch 41/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0038
Epoch 42/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0043
Epoch 43/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0054
Epoch 44/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0047
Epoch 45/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0041
Epoch 46/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0035
Epoch 47/50
48/68 [====================>.........] - ETA: 0s - loss: 0.0016
68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0036
Epoch 49/50
68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0045
Epoch 50/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0037
17/17 [==============================] - 0s 893us/step
KeyError: 'Close' column is not available in the dataset for ticker ZTS.
An error occurred while transforming prediction: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.
Unable to save data for ZTS due to missing information.
Columns available: Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')
Epoch 1/50
68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0036
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 8/50===========================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0036
Epoch 8/50===========================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0036
Epoch 20/50==========================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0036
Epoch 20/50==========================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0036
Epoch 32/50==========================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0036
Epoch 32/50==========================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0036
Epoch 40/50==========================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0036
Epoch 40/50==========================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0036