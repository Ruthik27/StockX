
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 1/50
212/212 [==============================] - 3s 7ms/step - loss: 0.0043 - val_loss: 2.9866e-04
Epoch 2/50
212/212 [==============================] - 1s 5ms/step - loss: 8.4691e-04 - val_loss: 8.3722e-05
Epoch 3/50
212/212 [==============================] - 1s 5ms/step - loss: 7.5432e-04 - val_loss: 1.6457e-04
Epoch 4/50
212/212 [==============================] - 1s 5ms/step - loss: 5.8115e-04 - val_loss: 6.6989e-04
Epoch 5/50
212/212 [==============================] - 1s 5ms/step - loss: 5.3483e-04 - val_loss: 1.0053e-04
Epoch 6/50
212/212 [==============================] - 1s 5ms/step - loss: 5.1046e-04 - val_loss: 0.0013
Epoch 7/50
212/212 [==============================] - 1s 5ms/step - loss: 4.5406e-04 - val_loss: 1.1496e-04
Epoch 8/50
212/212 [==============================] - 1s 5ms/step - loss: 3.8677e-04 - val_loss: 9.5606e-05
Epoch 9/50
212/212 [==============================] - 1s 5ms/step - loss: 3.8581e-04 - val_loss: 4.2755e-04
Epoch 10/50
212/212 [==============================] - 1s 5ms/step - loss: 3.6249e-04 - val_loss: 2.2497e-04
Epoch 11/50
212/212 [==============================] - 1s 5ms/step - loss: 3.7538e-04 - val_loss: 6.0115e-05
Epoch 12/50
212/212 [==============================] - 1s 5ms/step - loss: 3.4177e-04 - val_loss: 0.0020
Epoch 13/50
212/212 [==============================] - 1s 5ms/step - loss: 3.5367e-04 - val_loss: 6.9425e-05
Epoch 14/50
212/212 [==============================] - 1s 5ms/step - loss: 3.2227e-04 - val_loss: 9.5241e-05
Epoch 15/50
212/212 [==============================] - 1s 5ms/step - loss: 3.0303e-04 - val_loss: 4.2787e-04
Epoch 16/50
212/212 [==============================] - 1s 5ms/step - loss: 3.4493e-04 - val_loss: 0.0017
Epoch 17/50
212/212 [==============================] - 1s 5ms/step - loss: 3.4806e-04 - val_loss: 7.5744e-04
Epoch 18/50
212/212 [==============================] - 1s 5ms/step - loss: 3.5598e-04 - val_loss: 0.0011
Epoch 19/50
212/212 [==============================] - 1s 5ms/step - loss: 3.1177e-04 - val_loss: 4.9526e-04
Epoch 20/50
212/212 [==============================] - 1s 5ms/step - loss: 3.1141e-04 - val_loss: 1.1636e-04
Epoch 21/50
212/212 [==============================] - 1s 5ms/step - loss: 2.6337e-04 - val_loss: 2.3863e-04
53/53 [==============================] - 0s 1ms/step
53/53 [==============================] - 0s 1ms/step
CSCO : 6.011477031999619e-05 0.006082819132664554 0.007753371545334081
CSCO : 53.91968911039742 35.23382720477659 -18.685861905620833
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Data for CSCO appended successfully.
Epoch 1/50
111/111 [==============================] - 3s 8ms/step - loss: 0.0215 - val_loss: 0.0015
Epoch 2/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0032 - val_loss: 0.0017
Epoch 3/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.0012
Epoch 4/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0022 - val_loss: 0.0015
Epoch 5/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 8.5631e-04
Epoch 6/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 6.4131e-04
Epoch 7/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0012
Epoch 8/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 0.0011
Epoch 9/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 7.1253e-04
Epoch 10/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 8.7120e-04
Epoch 11/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0020
Epoch 12/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 5.5545e-04
Epoch 13/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 4.6580e-04
Epoch 14/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 4.4512e-04
Epoch 15/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0010
Epoch 16/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 4.2857e-04
Epoch 17/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 4.4358e-04
Epoch 18/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 4.3126e-04
Epoch 19/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0011
Epoch 20/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 5.1494e-04
Epoch 21/50
111/111 [==============================] - 1s 5ms/step - loss: 9.7899e-04 - val_loss: 7.7645e-04
Epoch 22/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 4.4224e-04
Epoch 23/50
111/111 [==============================] - 1s 5ms/step - loss: 9.9858e-04 - val_loss: 7.4566e-04
Epoch 24/50
111/111 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 4.7770e-04
Epoch 25/50
111/111 [==============================] - 1s 5ms/step - loss: 9.0556e-04 - val_loss: 5.6529e-04
Epoch 26/50
111/111 [==============================] - 1s 5ms/step - loss: 8.9305e-04 - val_loss: 3.9751e-04
Epoch 27/50
111/111 [==============================] - 1s 5ms/step - loss: 9.3976e-04 - val_loss: 9.4746e-04
Epoch 28/50
Epoch 30/50============================] - 1s 5ms/step - loss: 8.8016e-04 - val_loss: 4.7889e-04
Epoch 29/50
111/111 [==============================] - 1s 5ms/step - loss: 8.8750e-04 - val_loss: 6.0184e-04
Epoch 30/50============================] - 1s 5ms/step - loss: 8.8016e-04 - val_loss: 4.7889e-04
111/111 [==============================] - 1s 5ms/step - loss: 8.1584e-04 - val_loss: 7.8843e-04
Epoch 31/50
111/111 [==============================] - 1s 5ms/step - loss: 8.7572e-04 - val_loss: 4.1313e-04
Epoch 32/50
 25/111 [=====>........................] - ETA: 0s - loss: 7.3055e-04e-04 - val_loss: 6.3855e-04
Epoch 33/50
111/111 [==============================] - 1s 5ms/step - loss: 7.1755e-04 - val_loss: 5.1045e-04
Epoch 34/50
111/111 [==============================] - 1s 5ms/step - loss: 7.2338e-04 - val_loss: 3.8127e-04
Epoch 35/50
111/111 [==============================] - 1s 5ms/step - loss: 7.3826e-04 - val_loss: 4.5819e-04
Epoch 36/50
111/111 [==============================] - 1s 5ms/step - loss: 7.3873e-04 - val_loss: 3.8987e-04
Epoch 37/50
111/111 [==============================] - 1s 5ms/step - loss: 7.0398e-04 - val_loss: 4.9594e-04
Epoch 38/50
111/111 [==============================] - 1s 5ms/step - loss: 6.5444e-04 - val_loss: 4.0605e-04
Epoch 39/50
105/111 [===========================>..] - ETA: 0s - loss: 7.0296e-04
111/111 [==============================] - 1s 5ms/step - loss: 7.2553e-04 - val_loss: 3.5528e-04
Epoch 41/50
111/111 [==============================] - 1s 5ms/step - loss: 7.2517e-04 - val_loss: 4.8620e-04
Epoch 42/50
111/111 [==============================] - 1s 5ms/step - loss: 6.2092e-04 - val_loss: 4.8743e-04
Epoch 43/50
 73/111 [==================>...........] - ETA: 0s - loss: 6.3123e-04
111/111 [==============================] - 1s 5ms/step - loss: 6.6849e-04 - val_loss: 4.2427e-04
Epoch 45/50
111/111 [==============================] - 1s 5ms/step - loss: 6.6158e-04 - val_loss: 3.9897e-04
Epoch 46/50
111/111 [==============================] - 1s 5ms/step - loss: 6.5164e-04 - val_loss: 5.2719e-04
Epoch 47/50
 37/111 [=========>....................] - ETA: 0s - loss: 5.7562e-04
111/111 [==============================] - 1s 5ms/step - loss: 6.2683e-04 - val_loss: 4.1877e-04
Epoch 49/50
111/111 [==============================] - 1s 5ms/step - loss: 6.4980e-04 - val_loss: 5.2997e-04
Epoch 50/50
104/111 [===========================>..] - ETA: 0s - loss: 6.1635e-04
111/111 [==============================] - 1s 5ms/step - loss: 6.2683e-04 - val_loss: 4.1877e-04
UAL : 37.87905254234436 29.686633709641818 -8.192418832702543: 6.2683e-04 - val_loss: 4.1877e-04
Data for UAL appended successfully.
Epoch 1/50
UAL : 37.87905254234436 29.686633709641818 -8.192418832702543: 6.2683e-04 - val_loss: 4.1877e-04
UAL : 37.87905254234436 29.686633709641818 -8.192418832702543: 6.2683e-04 - val_loss: 4.1877e-04
Epoch 4/507905254234436 29.686633709641818 -8.192418832702543: 6.2683e-04 - val_loss: 4.1877e-04
Epoch 4/507905254234436 29.686633709641818 -8.192418832702543: 6.2683e-04 - val_loss: 4.1877e-04
Epoch 8/507905254234436 29.686633709641818 -8.192418832702543: 6.2683e-04 - val_loss: 4.1877e-04
Epoch 8/507905254234436 29.686633709641818 -8.192418832702543: 6.2683e-04 - val_loss: 4.1877e-04
Epoch 12/50905254234436 29.686633709641818 -8.192418832702543: 6.2683e-04 - val_loss: 4.1877e-04
Epoch 12/50905254234436 29.686633709641818 -8.192418832702543: 6.2683e-04 - val_loss: 4.1877e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
 34/146 [=====>........................] - ETA: 0s - loss: 0.0068  83e-04 - val_loss: 4.1877e-04
146/146 [==============================] - 3s 7ms/step - loss: 0.0025 - val_loss: 8.8556e-04e-04
146/146 [==============================] - 1s 5ms/step - loss: 2.5385e-04 - val_loss: 0.0016e-04
 73/146 [==============>...............] - ETA: 0s - loss: 2.4525e-04e-04 - val_loss: 0.0016e-04
146/146 [==============================] - 1s 5ms/step - loss: 2.5298e-04 - val_loss: 8.3543e-04
146/146 [==============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
146/146 [==============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
Epoch 1/50=============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
Epoch 1/50=============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
Epoch 1/50=============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
Epoch 5/50=============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
Epoch 5/50=============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
Epoch 5/50=============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
Epoch 9/50=============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
Epoch 9/50=============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
Epoch 9/50=============================] - 1s 5ms/step - loss: 1.9550e-04 - val_loss: 0.0049e-04
NVR : 0.0004150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
NVR : 0.0004150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 4/5004150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 7/5004150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 10/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 13/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 15/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 17/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 20/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 23/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 26/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 29/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 31/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 34/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 37/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 40/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 42/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
Epoch 42/504150756772283379 0.01822548211041993 0.0203734061273106250e-04 - val_loss: 0.0049e-04
TPR : 9.418350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
TPR : 9.418350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 3/508350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 3/508350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 6/508350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 8/508350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 10/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 10/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 13/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 15/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 17/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 17/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 20/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 22/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 22/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 25/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 25/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 28/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 30/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 32/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 32/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 32/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
Epoch 32/50350755937608e-05 0.006750649582268487 0.009704818780347013e-04 - val_loss: 0.0049e-04
DVN : 46.97485821893462 28.291350095971225 -18.6835081229633960347013e-04 - val_loss: 0.0049e-04
Epoch 3/507485821893462 28.291350095971225 -18.6835081229633960347013e-04 - val_loss: 0.0049e-04
Epoch 6/507485821893462 28.291350095971225 -18.6835081229633960347013e-04 - val_loss: 0.0049e-04
Epoch 10/50485821893462 28.291350095971225 -18.6835081229633960347013e-04 - val_loss: 0.0049e-04
Epoch 10/50485821893462 28.291350095971225 -18.6835081229633960347013e-04 - val_loss: 0.0049e-04
30/30 [==============================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
30/30 [==============================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
30/30 [==============================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
30/30 [==============================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
30/30 [==============================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
30/30 [==============================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
30/30 [==============================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
30/30 [==============================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
30/30 [==============================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
30/30 [==============================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
Epoch 11/50==========================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
Epoch 11/50==========================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
Epoch 11/50==========================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
Epoch 11/50==========================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
Epoch 11/50==========================] - 0s 1ms/step81229633960347013e-04 - val_loss: 0.0049e-04
MRO : 26.376944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
MRO : 26.376944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
MRO : 26.376944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
MRO : 26.376944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
MRO : 26.376944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
MRO : 26.376944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
MRO : 26.376944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
MRO : 26.376944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
MRO : 26.376944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 10/506944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 10/506944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 10/506944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 10/506944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 10/506944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 10/506944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 1/5006944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 1/5006944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 4/5006944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 6/5006944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 8/5006944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 10/506944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 12/506944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
Epoch 12/506944180242987 32.78964797212493 6.412703791881945960347013e-04 - val_loss: 0.0049e-04
VRTX : 9.79923643119076e-05 0.007321478713045366 0.009899109268611374e-04 - val_loss: 0.0049e-04
VRTX : 9.79923643119076e-05 0.007321478713045366 0.009899109268611374e-04 - val_loss: 0.0049e-04
Epoch 3/509923643119076e-05 0.007321478713045366 0.009899109268611374e-04 - val_loss: 0.0049e-04
Epoch 5/509923643119076e-05 0.007321478713045366 0.009899109268611374e-04 - val_loss: 0.0049e-04
Epoch 8/509923643119076e-05 0.007321478713045366 0.009899109268611374e-04 - val_loss: 0.0049e-04
Epoch 11/50923643119076e-05 0.007321478713045366 0.009899109268611374e-04 - val_loss: 0.0049e-04
Epoch 11/50923643119076e-05 0.007321478713045366 0.009899109268611374e-04 - val_loss: 0.0049e-04
EQIX : 0.00011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
EQIX : 0.00011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
EQIX : 0.00011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
EQIX : 0.00011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
EQIX : 0.00011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
EQIX : 0.00011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
EQIX : 0.00011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
Epoch 8/500011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
Epoch 8/500011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
Epoch 11/50011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
Epoch 11/50011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
Epoch 11/50011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
Epoch 11/50011280280881926374 0.008305583398402018 0.01062086666987509804 - val_loss: 0.0049e-04
TER : 0.00011147629672313515 0.007431722743901033 0.010558233598625063804 - val_loss: 0.0049e-04
TER : 0.00011147629672313515 0.007431722743901033 0.010558233598625063804 - val_loss: 0.0049e-04
Epoch 3/50011147629672313515 0.007431722743901033 0.010558233598625063804 - val_loss: 0.0049e-04
Epoch 7/50011147629672313515 0.007431722743901033 0.010558233598625063804 - val_loss: 0.0049e-04
Epoch 11/5011147629672313515 0.007431722743901033 0.010558233598625063804 - val_loss: 0.0049e-04
Epoch 11/5011147629672313515 0.007431722743901033 0.010558233598625063804 - val_loss: 0.0049e-04
26/26 [==============================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
26/26 [==============================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
26/26 [==============================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
26/26 [==============================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
Epoch 5/50===========================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
Epoch 5/50===========================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
Epoch 5/50===========================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
Epoch 9/50===========================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
Epoch 9/50===========================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
Epoch 9/50===========================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
Epoch 9/50===========================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
Epoch 9/50===========================] - 0s 1ms/step010558233598625063804 - val_loss: 0.0049e-04
MDT : 72.50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
MDT : 72.50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 3/500378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 5/500378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 5/500378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 8/500378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 10/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 12/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 12/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 15/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 17/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 19/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 19/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 22/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 24/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 24/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 27/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 29/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 31/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 31/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 34/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 36/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 36/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 39/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 41/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 41/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 44/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 46/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 46/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 49/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 49/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 49/50378006109729 52.06716279062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Data for CIK appended successfully.062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 3/50IK appended successfully.062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 6/50IK appended successfully.062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 10/50K appended successfully.062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 14/50K appended successfully.062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 18/50K appended successfully.062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 22/50K appended successfully.062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 26/50K appended successfully.062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 30/50K appended successfully.062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
Epoch 30/50K appended successfully.062855 -20.436617270468737598625063804 - val_loss: 0.0049e-04
V : 0.00014629182595798747 0.009434224186760275 0.01209511578935842463804 - val_loss: 0.0049e-04
Epoch 3/504629182595798747 0.009434224186760275 0.01209511578935842463804 - val_loss: 0.0049e-04
Epoch 11/50629182595798747 0.009434224186760275 0.01209511578935842463804 - val_loss: 0.0049e-04
Epoch 15/50629182595798747 0.009434224186760275 0.01209511578935842463804 - val_loss: 0.0049e-04
Epoch 23/50629182595798747 0.009434224186760275 0.01209511578935842463804 - val_loss: 0.0049e-04
Epoch 27/50629182595798747 0.009434224186760275 0.01209511578935842463804 - val_loss: 0.0049e-04
Epoch 27/50629182595798747 0.009434224186760275 0.01209511578935842463804 - val_loss: 0.0049e-04
Data for QRVO appended successfully.24186760275 0.01209511578935842463804 - val_loss: 0.0049e-04
Data for QRVO appended successfully.24186760275 0.01209511578935842463804 - val_loss: 0.0049e-04
150/150 [==============================] - 1s 5ms/step - loss: 2.8659e-04 - val_loss: 0.0020e-04
150/150 [==============================] - 1s 5ms/step - loss: 2.8659e-04 - val_loss: 0.0020e-04
150/150 [==============================] - 1s 5ms/step - loss: 1.9859e-04 - val_loss: 5.1579e-04
Epoch 12/50============================] - 1s 5ms/step - loss: 1.9859e-04 - val_loss: 5.1579e-04
38/38 [==============================] - 0s 1ms/stepep - loss: 1.9859e-04 - val_loss: 5.1579e-04
38/38 [==============================] - 0s 1ms/stepep - loss: 1.9859e-04 - val_loss: 5.1579e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 11/50==========================] - 0s 1ms/stepep - loss: 1.9859e-04 - val_loss: 5.1579e-04
Epoch 23/50==========================] - 0s 1ms/stepep - loss: 1.9859e-04 - val_loss: 5.1579e-04
Epoch 31/50==========================] - 0s 1ms/stepep - loss: 1.9859e-04 - val_loss: 5.1579e-04
Epoch 43/50==========================] - 0s 1ms/stepep - loss: 1.9859e-04 - val_loss: 5.1579e-04
Epoch 43/50==========================] - 0s 1ms/stepep - loss: 1.9859e-04 - val_loss: 5.1579e-04
8/8 [==============================] - 0s 2ms/stepepep - loss: 1.9859e-04 - val_loss: 5.1579e-04
8/8 [==============================] - 0s 2ms/stepepep - loss: 1.9859e-04 - val_loss: 5.1579e-04
  1/388 [..............................] - ETA: 2s - loss: 9.1834e-04e-04 - val_loss: 5.1579e-04
388/388 [==============================] - 2s 5ms/step - loss: 9.3204e-04 - val_loss: 4.8885e-04
388/388 [==============================] - 2s 5ms/step - loss: 9.3204e-04 - val_loss: 4.8885e-04
388/388 [==============================] - 2s 5ms/step - loss: 9.3204e-04 - val_loss: 4.8885e-04
181/388 [============>.................] - ETA: 0s - loss: 6.1507e-04e-04 - val_loss: 4.8885e-04
388/388 [==============================] - 2s 5ms/step - loss: 6.0648e-04 - val_loss: 4.9778e-04
388/388 [==============================] - 2s 5ms/step - loss: 6.0648e-04 - val_loss: 4.9778e-04
388/388 [==============================] - 2s 5ms/step - loss: 6.0648e-04 - val_loss: 4.9778e-04
387/388 [============================>.] - ETA: 0s - loss: 4.9423e-04e-04 - val_loss: 4.9778e-04
388/388 [==============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 13/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 13/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 13/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 13/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 13/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 13/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 13/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 13/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 22/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 22/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 22/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 22/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 22/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 22/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 22/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 22/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 22/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
Epoch 22/50============================] - 2s 5ms/step - loss: 4.9599e-04 - val_loss: 3.1915e-04
MO : 7.813607825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
MO : 7.813607825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
MO : 7.813607825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
Epoch 4/50607825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
Epoch 6/50607825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
Epoch 8/50607825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
Epoch 8/50607825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
Epoch 11/5007825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
Epoch 13/5007825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
Epoch 13/5007825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
Epoch 16/5007825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
Epoch 18/5007825152459e-05 0.005662617044721839 0.0088394614231594789e-04 - val_loss: 3.1915e-04
CTRA : 0.00014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
CTRA : 0.00014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
CTRA : 0.00014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
Epoch 4/500014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
Epoch 6/500014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
Epoch 8/500014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
Epoch 8/500014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
Epoch 11/50014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
Epoch 13/50014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
Epoch 13/50014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
Epoch 13/50014433090509809098 0.008328196389886633 0.01201377980063272904 - val_loss: 3.1915e-04
SWKS : 92.49054930573293 65.14256310166937 -27.34798620406356980063272904 - val_loss: 3.1915e-04
Epoch 3/5049054930573293 65.14256310166937 -27.34798620406356980063272904 - val_loss: 3.1915e-04
Epoch 9/5049054930573293 65.14256310166937 -27.34798620406356980063272904 - val_loss: 3.1915e-04
Epoch 13/509054930573293 65.14256310166937 -27.34798620406356980063272904 - val_loss: 3.1915e-04
Epoch 17/509054930573293 65.14256310166937 -27.34798620406356980063272904 - val_loss: 3.1915e-04
Epoch 25/509054930573293 65.14256310166937 -27.34798620406356980063272904 - val_loss: 3.1915e-04
Epoch 29/509054930573293 65.14256310166937 -27.34798620406356980063272904 - val_loss: 3.1915e-04
Epoch 29/509054930573293 65.14256310166937 -27.34798620406356980063272904 - val_loss: 3.1915e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
192/192 [==============================] - 3s 7ms/step - loss: 0.0022 - val_loss: 0.00311915e-04
192/192 [==============================] - 3s 7ms/step - loss: 0.0022 - val_loss: 0.00311915e-04
192/192 [==============================] - 1s 5ms/step - loss: 1.8674e-04 - val_loss: 0.0095e-04
Epoch 8/50=============================] - 1s 5ms/step - loss: 1.8674e-04 - val_loss: 0.0095e-04
Epoch 11/50============================] - 1s 5ms/step - loss: 1.8674e-04 - val_loss: 0.0095e-04
Epoch 13/50============================] - 1s 5ms/step - loss: 1.8674e-04 - val_loss: 0.0095e-04
48/48 [==============================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
48/48 [==============================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
48/48 [==============================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
48/48 [==============================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
Epoch 5/50===========================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
Epoch 7/50===========================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
Epoch 9/50===========================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
Epoch 11/50==========================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
Epoch 13/50==========================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
Epoch 13/50==========================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
Epoch 13/50==========================] - 0s 1ms/stepep - loss: 1.8674e-04 - val_loss: 0.0095e-04
CDNS : 0.00100861179720088 0.02427986417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
CDNS : 0.00100861179720088 0.02427986417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 4/500100861179720088 0.02427986417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 8/500100861179720088 0.02427986417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 12/50100861179720088 0.02427986417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 16/50100861179720088 0.02427986417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 20/50100861179720088 0.02427986417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 20/50100861179720088 0.02427986417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Data for MSCI appended successfully.6417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 3/50SCI appended successfully.6417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 6/50SCI appended successfully.6417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 14/50CI appended successfully.6417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 18/50CI appended successfully.6417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
Epoch 18/50CI appended successfully.6417737325 0.03175864917153877674e-04 - val_loss: 0.0095e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
 87/318 [=======>......................] - ETA: 1s - loss: 0.0090  74e-04 - val_loss: 0.0095e-04
 87/318 [=======>......................] - ETA: 1s - loss: 0.0090  74e-04 - val_loss: 0.0095e-04