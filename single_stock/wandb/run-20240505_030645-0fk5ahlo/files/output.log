
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 1/50
153/153 [==============================] - 3s 8ms/step - loss: 0.0057 - val_loss: 6.2591e-04
Epoch 2/50
153/153 [==============================] - 1s 5ms/step - loss: 9.9200e-04 - val_loss: 3.2521e-04
Epoch 3/50
153/153 [==============================] - 1s 5ms/step - loss: 7.2006e-04 - val_loss: 3.4883e-04
Epoch 4/50
153/153 [==============================] - 1s 5ms/step - loss: 6.1590e-04 - val_loss: 0.0021
Epoch 5/50
153/153 [==============================] - 1s 5ms/step - loss: 5.5143e-04 - val_loss: 4.6660e-04
Epoch 6/50
153/153 [==============================] - 1s 5ms/step - loss: 5.2913e-04 - val_loss: 0.0019
Epoch 7/50
153/153 [==============================] - 1s 5ms/step - loss: 5.0988e-04 - val_loss: 8.2619e-04
Epoch 8/50
153/153 [==============================] - 1s 5ms/step - loss: 4.7376e-04 - val_loss: 0.0012
Epoch 9/50
153/153 [==============================] - 1s 5ms/step - loss: 4.3411e-04 - val_loss: 0.0024
Epoch 10/50
153/153 [==============================] - 1s 5ms/step - loss: 4.3041e-04 - val_loss: 9.6443e-04
Epoch 11/50
153/153 [==============================] - 1s 5ms/step - loss: 3.8705e-04 - val_loss: 0.0014
Epoch 12/50
153/153 [==============================] - 1s 5ms/step - loss: 3.6407e-04 - val_loss: 0.0011
39/39 [==============================] - 0s 1ms/step
39/39 [==============================] - 0s 1ms/step
GS : 0.00032521222404098505 0.014657043784624775 0.018033641452601442
GS : 327.596475822835 152.44750369232028 -175.1489721305147
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 1/50
274/274 [==============================] - 4s 6ms/step - loss: 0.0059 - val_loss: 3.0439e-04
Epoch 2/50
274/274 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 5.1172e-04
Epoch 3/50
274/274 [==============================] - 1s 5ms/step - loss: 9.0392e-04 - val_loss: 5.0153e-04
Epoch 4/50
274/274 [==============================] - 1s 5ms/step - loss: 7.0474e-04 - val_loss: 1.0435e-04
Epoch 5/50
274/274 [==============================] - 1s 5ms/step - loss: 6.2868e-04 - val_loss: 1.3908e-04
Epoch 6/50
274/274 [==============================] - 1s 5ms/step - loss: 6.2541e-04 - val_loss: 1.1280e-04
Epoch 7/50
274/274 [==============================] - 1s 5ms/step - loss: 5.5628e-04 - val_loss: 7.8609e-04
Epoch 8/50
274/274 [==============================] - 1s 5ms/step - loss: 5.2592e-04 - val_loss: 2.3054e-04
Epoch 9/50
274/274 [==============================] - 1s 5ms/step - loss: 5.3157e-04 - val_loss: 8.4336e-04
Epoch 10/50
274/274 [==============================] - 1s 5ms/step - loss: 4.7961e-04 - val_loss: 4.7051e-04
Epoch 11/50
274/274 [==============================] - 1s 5ms/step - loss: 4.5716e-04 - val_loss: 1.4684e-04
Epoch 12/50
274/274 [==============================] - 1s 5ms/step - loss: 4.7601e-04 - val_loss: 2.8912e-04
Epoch 13/50
274/274 [==============================] - 1s 5ms/step - loss: 4.1015e-04 - val_loss: 8.2012e-04
Epoch 14/50
174/274 [==================>...........] - ETA: 0s - loss: 4.4763e-04
274/274 [==============================] - 1s 5ms/step - loss: 4.5785e-04 - val_loss: 1.9343e-04
69/69 [==============================] - 0s 1ms/step
69/69 [==============================] - 0s 1ms/step
L : 0.0001043485237897087 0.007619614960309186 0.010215112519679296
L : 65.90829252932343 42.72320419549942 -23.185088333824012
Epoch 1/50
252/252 [==============================] - 3s 6ms/step - loss: 0.0012 - val_loss: 0.0028
Epoch 2/50
252/252 [==============================] - 1s 5ms/step - loss: 1.4980e-04 - val_loss: 1.5767e-04
Epoch 3/50
252/252 [==============================] - 1s 5ms/step - loss: 1.0944e-04 - val_loss: 2.6205e-04
Epoch 4/50
252/252 [==============================] - 1s 5ms/step - loss: 1.0204e-04 - val_loss: 2.1104e-04
Epoch 5/50
252/252 [==============================] - 1s 5ms/step - loss: 1.1386e-04 - val_loss: 0.0017
Epoch 6/50
252/252 [==============================] - 1s 5ms/step - loss: 8.4686e-05 - val_loss: 0.0017
Epoch 7/50
252/252 [==============================] - 1s 5ms/step - loss: 8.0183e-05 - val_loss: 0.0014
Epoch 8/50
252/252 [==============================] - 1s 5ms/step - loss: 7.7277e-05 - val_loss: 0.0037
Epoch 9/50
252/252 [==============================] - 1s 5ms/step - loss: 7.5842e-05 - val_loss: 0.0027
Epoch 10/50
252/252 [==============================] - 1s 5ms/step - loss: 7.4110e-05 - val_loss: 0.0039
Epoch 11/50
252/252 [==============================] - 1s 5ms/step - loss: 7.2830e-05 - val_loss: 0.0037
Epoch 12/50
241/252 [===========================>..] - ETA: 0s - loss: 7.4538e-05
252/252 [==============================] - 1s 5ms/step - loss: 7.3562e-05 - val_loss: 0.0031
63/63 [==============================] - 0s 1ms/step
63/63 [==============================] - 0s 1ms/step
RJF : 0.00015767002526397226 0.008874257090541775 0.012556672539489602
RJF : 102.17855765778425 37.77063871097767 -64.40791894680657
Epoch 1/50
323/323 [==============================] - 3s 6ms/step - loss: 8.0676e-04 - val_loss: 0.0015
Epoch 2/50
323/323 [==============================] - 1s 4ms/step - loss: 1.4768e-04 - val_loss: 8.5071e-04
Epoch 3/50
323/323 [==============================] - 1s 4ms/step - loss: 1.2451e-04 - val_loss: 1.3410e-04
Epoch 4/50
323/323 [==============================] - 1s 4ms/step - loss: 1.1184e-04 - val_loss: 0.0010
Epoch 5/50
323/323 [==============================] - 1s 4ms/step - loss: 9.4159e-05 - val_loss: 5.3936e-04
Epoch 6/50
323/323 [==============================] - 1s 4ms/step - loss: 9.2803e-05 - val_loss: 0.0056
Epoch 7/50
323/323 [==============================] - 1s 4ms/step - loss: 8.3055e-05 - val_loss: 0.0049
Epoch 8/50
323/323 [==============================] - 1s 4ms/step - loss: 8.3055e-05 - val_loss: 0.0049
Epoch 9/50
 31/323 [=>............................] - ETA: 0s - loss: 6.3640e-05e-05 - val_loss: 0.0115
Epoch 10/50
323/323 [==============================] - 1s 4ms/step - loss: 7.9775e-05 - val_loss: 0.0142
Epoch 11/50
323/323 [==============================] - 1s 4ms/step - loss: 8.1185e-05 - val_loss: 0.0184
Epoch 12/50
260/323 [=======================>......] - ETA: 0s - loss: 7.0035e-05
323/323 [==============================] - 1s 4ms/step - loss: 6.9963e-05 - val_loss: 0.0161
81/81 [==============================] - 0s 1ms/step
 1/81 [..............................] - ETA: 0s
323/323 [==============================] - 1s 4ms/step - loss: 6.9963e-05 - val_loss: 0.0161
TXN : 150.42363872203288 38.8675175534236 -111.55612116860928: 6.9963e-05 - val_loss: 0.0161
Epoch 1/50
 49/261 [====>.........................] - ETA: 0s - loss: 1.2768e-04e-05 - val_loss: 0.0161
261/261 [==============================] - 1s 5ms/step - loss: 1.4121e-04 - val_loss: 3.3177e-04
261/261 [==============================] - 1s 5ms/step - loss: 9.3089e-05 - val_loss: 2.6995e-04
261/261 [==============================] - 1s 5ms/step - loss: 7.0524e-05 - val_loss: 0.0018e-04
217/261 [=======================>......] - ETA: 0s - loss: 6.8073e-05e-05 - val_loss: 0.0018e-04
121/261 [============>.................] - ETA: 0s - loss: 7.1444e-05e-05 - val_loss: 0.0015e-04
 13/261 [>.............................] - ETA: 1s - loss: 5.3808e-05e-05 - val_loss: 8.7856e-04
261/261 [==============================] - 1s 5ms/step - loss: 6.8204e-05 - val_loss: 8.4192e-04
261/261 [==============================] - 1s 5ms/step - loss: 6.8204e-05 - val_loss: 8.4192e-04
66/66 [==============================] - 0s 1ms/stepep - loss: 6.8204e-05 - val_loss: 8.4192e-04
214/388 [===============>..............] - ETA: 0s - loss: 9.9826e-04e-05 - val_loss: 8.4192e-04
388/388 [==============================] - 4s 6ms/step - loss: 6.1919e-04 - val_loss: 4.2416e-04
205/388 [==============>...............] - ETA: 0s - loss: 9.7947e-05e-04 - val_loss: 4.2416e-04
388/388 [==============================] - 2s 5ms/step - loss: 1.0119e-04 - val_loss: 6.6928e-04
273/388 [====================>.........] - ETA: 0s - loss: 7.7858e-05e-04 - val_loss: 6.6928e-04
388/388 [==============================] - 2s 5ms/step - loss: 7.7940e-05 - val_loss: 9.6017e-04
346/388 [=========================>....] - ETA: 0s - loss: 7.9654e-05e-05 - val_loss: 9.6017e-04
388/388 [==============================] - 2s 5ms/step - loss: 7.8922e-05 - val_loss: 0.0034e-04
388/388 [==============================] - 2s 5ms/step - loss: 7.2210e-05 - val_loss: 0.0052e-04
388/388 [==============================] - 2s 5ms/step - loss: 7.2210e-05 - val_loss: 0.0052e-04
358/388 [==========================>...] - ETA: 0s - loss: 6.9596e-05e-05 - val_loss: 0.0052e-04
388/388 [==============================] - 2s 5ms/step - loss: 6.9643e-05 - val_loss: 0.0038e-04
388/388 [==============================] - 2s 5ms/step - loss: 6.9643e-05 - val_loss: 0.0038e-04
97/97 [==============================] - 0s 1ms/stepep - loss: 6.9643e-05 - val_loss: 0.0038e-04
201/228 [=========================>....] - ETA: 0s - loss: 0.0093  43e-05 - val_loss: 0.0038e-04
 85/228 [==========>...................] - ETA: 0s - loss: 0.0014     - val_loss: 0.00160038e-04
 60/228 [======>.......................] - ETA: 0s - loss: 0.0011     - val_loss: 6.8413e-04e-04
 37/228 [===>..........................] - ETA: 0s - loss: 8.6830e-04 - val_loss: 7.9667e-04e-04
  1/228 [..............................] - ETA: 1s - loss: 9.3314e-04e-04 - val_loss: 5.3185e-04
228/228 [==============================] - 1s 5ms/step - loss: 7.6261e-04 - val_loss: 7.2334e-04
228/228 [==============================] - 1s 5ms/step - loss: 6.3810e-04 - val_loss: 7.3479e-04
228/228 [==============================] - 1s 5ms/step - loss: 5.4164e-04 - val_loss: 9.4139e-04
228/228 [==============================] - 1s 5ms/step - loss: 5.1704e-04 - val_loss: 0.0010e-04
228/228 [==============================] - 1s 5ms/step - loss: 4.8916e-04 - val_loss: 7.0383e-04
228/228 [==============================] - 1s 5ms/step - loss: 4.8916e-04 - val_loss: 7.0383e-04
CCL : 10.768195013527713 44.61447006821633 33.84627505468862s: 4.8916e-04 - val_loss: 7.0383e-04
144/175 [=======================>......] - ETA: 0s - loss: 4.6207e-04e-04 - val_loss: 7.0383e-04
119/175 [===================>..........] - ETA: 0s - loss: 2.3467e-04e-04 - val_loss: 1.8416e-04
175/175 [==============================] - 1s 5ms/step - loss: 1.9737e-04 - val_loss: 0.0027e-04
175/175 [==============================] - 1s 5ms/step - loss: 1.7111e-04 - val_loss: 0.0011e-04
175/175 [==============================] - 1s 5ms/step - loss: 1.5847e-04 - val_loss: 8.8750e-04
WAT : 261.06861793069476 213.29867010983816 -47.7699478208566: 1.3375e-04 - val_loss: 0.0041e-04
WAT : 261.06861793069476 213.29867010983816 -47.7699478208566: 1.3375e-04 - val_loss: 0.0041e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
 83/273 [========>.....................] - ETA: 0s - loss: 0.00163375e-04 - val_loss: 0.0041e-04
273/273 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 1.1888e-04e-04
273/273 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 5.9776e-05e-04
261/273 [===========================>..] - ETA: 0s - loss: 9.3571e-04 - val_loss: 5.9776e-05e-04
118/273 [===========>..................] - ETA: 0s - loss: 8.6161e-04e-04 - val_loss: 7.0002e-05
273/273 [==============================] - 1s 5ms/step - loss: 8.3717e-04 - val_loss: 6.8703e-05
273/273 [==============================] - 1s 5ms/step - loss: 7.0846e-04 - val_loss: 7.9459e-05
273/273 [==============================] - 1s 5ms/step - loss: 6.7582e-04 - val_loss: 1.9280e-04
 37/273 [===>..........................] - ETA: 1s - loss: 8.2639e-04e-04 - val_loss: 1.9280e-04
FITB : 26.1981780875726 19.474624608239232 -6.723553479333368: 7.0150e-04 - val_loss: 6.1981e-05
FITB : 26.1981780875726 19.474624608239232 -6.723553479333368: 7.0150e-04 - val_loss: 6.1981e-05
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
49/50 [============================>.] - ETA: 0s - loss: 0.00360038 - val_loss: 8.9038e-0481e-05
50/50 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 6.8687e-0481e-05
50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 2.5777e-0481e-05
35/50 [====================>.........] - ETA: 0s - loss: 0.00210020 - val_loss: 5.0707e-0481e-05
50/50 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 3.9222e-0481e-05
Epoch 35/50
50/50 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 9.0399e-04
Epoch 36/50
50/50 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 3.9222e-0481e-05
Epoch 37/50
50/50 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 3.4892e-04
13/13 [==============================] - 0s 1ms/step
13/13 [==============================] - 0s 1ms/step
HPE : 0.00024784063140695036 0.012260283529143871 0.01574295497697146
HPE : 15.797921052964751 15.841399464581311 0.04347841161655985
{'Ticker': 'GS', 'Mean Squared Error': 0.00032521222404098505, 'Mean Absolute Error': 0.014657043784624775, 'Root Mean Squared Error': 0.018033641452601442}
{'Ticker': 'L', 'Mean Squared Error': 0.0001043485237897087, 'Mean Absolute Error': 0.007619614960309186, 'Root Mean Squared Error': 0.010215112519679296}
{'Ticker': 'RJF', 'Mean Squared Error': 0.00015767002526397226, 'Mean Absolute Error': 0.008874257090541775, 'Root Mean Squared Error': 0.012556672539489602}
{'Ticker': 'TXN', 'Mean Squared Error': 0.00013409897563385092, 'Mean Absolute Error': 0.00917522151603215, 'Root Mean Squared Error': 0.011580111209908605}
{'Ticker': 'CI', 'Mean Squared Error': 0.0002261876593800997, 'Mean Absolute Error': 0.012355980179142152, 'Root Mean Squared Error': 0.015039536541399796}
{'Ticker': 'CAT', 'Mean Squared Error': 0.00026281598264817774, 'Mean Absolute Error': 0.01339980538420017, 'Root Mean Squared Error': 0.01621160024945649}
{'Ticker': 'CCL', 'Mean Squared Error': 0.0005318510261244893, 'Mean Absolute Error': 0.01709389319343803, 'Root Mean Squared Error': 0.023061895544913242}
{'Ticker': 'WAT', 'Mean Squared Error': 0.0001841625335529362, 'Mean Absolute Error': 0.009691346283587457, 'Root Mean Squared Error': 0.013570649710052066}
{'Ticker': 'FITB', 'Mean Squared Error': 5.977600082294062e-05, 'Mean Absolute Error': 0.005747107152366176, 'Root Mean Squared Error': 0.007731494087363749}
{'Ticker': 'HPE', 'Mean Squared Error': 0.00024784063140695036, 'Mean Absolute Error': 0.012260283529143871, 'Root Mean Squared Error': 0.01574295497697146}