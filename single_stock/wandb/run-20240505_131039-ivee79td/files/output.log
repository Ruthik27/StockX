Warning: 'Ticker' column not found in the Excel sheet. Starting with no processed tickers.
Epoch 1/50
167/212 [======================>.......] - ETA: 0s - loss: 0.0070
212/212 [==============================] - 2s 4ms/step - loss: 0.0058 - val_loss: 3.6111e-04
Epoch 2/50
212/212 [==============================] - 1s 3ms/step - loss: 9.6234e-04 - val_loss: 5.2304e-04
Epoch 3/50
212/212 [==============================] - 1s 3ms/step - loss: 6.9772e-04 - val_loss: 9.1174e-05
Epoch 4/50
212/212 [==============================] - 1s 3ms/step - loss: 5.8446e-04 - val_loss: 6.6872e-05
Epoch 5/50
212/212 [==============================] - 1s 3ms/step - loss: 5.8390e-04 - val_loss: 9.6572e-05
Epoch 6/50
212/212 [==============================] - 1s 3ms/step - loss: 4.9457e-04 - val_loss: 1.1559e-04
Epoch 7/50
212/212 [==============================] - 1s 3ms/step - loss: 4.6066e-04 - val_loss: 4.4792e-05
Epoch 8/50
212/212 [==============================] - 1s 3ms/step - loss: 4.7378e-04 - val_loss: 1.7908e-04
Epoch 9/50
212/212 [==============================] - 1s 3ms/step - loss: 4.7224e-04 - val_loss: 4.7330e-04
Epoch 10/50
212/212 [==============================] - 1s 3ms/step - loss: 3.9990e-04 - val_loss: 1.1635e-04
Epoch 11/50
212/212 [==============================] - 1s 3ms/step - loss: 3.3321e-04 - val_loss: 2.3006e-04
Epoch 12/50
212/212 [==============================] - 1s 3ms/step - loss: 3.2866e-04 - val_loss: 4.8360e-04
Epoch 13/50
212/212 [==============================] - 1s 3ms/step - loss: 3.8435e-04 - val_loss: 0.0016
Epoch 14/50
212/212 [==============================] - 1s 3ms/step - loss: 3.4366e-04 - val_loss: 5.3526e-05
Epoch 15/50
212/212 [==============================] - 1s 3ms/step - loss: 3.2728e-04 - val_loss: 4.3158e-04
Epoch 16/50
212/212 [==============================] - 1s 3ms/step - loss: 3.0366e-04 - val_loss: 3.4983e-04
Epoch 17/50
212/212 [==============================] - 1s 3ms/step - loss: 3.3899e-04 - val_loss: 2.3719e-04
53/53 [==============================] - 0s 876us/step
53/53 [==============================] - 0s 821us/step
CSCO : 4.47924376098833e-05 0.005109332638368699 0.006692715264366421
CSCO : 53.91968911039742 35.101404140220374 -18.818284970177046
Data for CSCO saved successfully.
Epoch 1/50
  1/111 [..............................] - ETA: 1:45 - loss: 0.1616
111/111 [==============================] - 2s 6ms/step - loss: 0.0178 - val_loss: 0.0015
Epoch 2/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0011
Epoch 3/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 9.6235e-04
Epoch 4/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0013
Epoch 5/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0021
Epoch 6/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 8.7618e-04
Epoch 7/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026
Epoch 8/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0016
Epoch 9/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 5.1561e-04
Epoch 10/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 5.1154e-04
Epoch 11/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 4.7091e-04
Epoch 12/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 4.3742e-04
Epoch 13/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.5520e-04
Epoch 14/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 4.3117e-04
Epoch 15/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 4.2286e-04
Epoch 16/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 6.1711e-04
Epoch 17/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 3.9404e-04
Epoch 18/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 4.2302e-04
Epoch 19/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.0475e-04
Epoch 20/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 5.5156e-04
Epoch 21/50
111/111 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 3.9828e-04
Epoch 22/50
111/111 [==============================] - 0s 3ms/step - loss: 9.1240e-04 - val_loss: 7.8787e-04
Epoch 23/50
111/111 [==============================] - 0s 3ms/step - loss: 9.4810e-04 - val_loss: 0.0012
Epoch 24/50
111/111 [==============================] - 0s 3ms/step - loss: 8.8141e-04 - val_loss: 4.5250e-04
Epoch 25/50
111/111 [==============================] - 0s 3ms/step - loss: 9.1871e-04 - val_loss: 6.3905e-04
Epoch 26/50
111/111 [==============================] - 0s 3ms/step - loss: 8.6359e-04 - val_loss: 4.4800e-04
Epoch 27/50
111/111 [==============================] - 0s 3ms/step - loss: 7.7592e-04 - val_loss: 3.6251e-04
Epoch 28/50
111/111 [==============================] - 0s 3ms/step - loss: 8.3116e-04 - val_loss: 4.0186e-04
Epoch 29/50
111/111 [==============================] - 0s 3ms/step - loss: 7.8731e-04 - val_loss: 4.7825e-04
Epoch 30/50
111/111 [==============================] - 0s 3ms/step - loss: 8.2383e-04 - val_loss: 8.1372e-04
Epoch 31/50
111/111 [==============================] - 0s 3ms/step - loss: 8.0051e-04 - val_loss: 3.7428e-04
Epoch 32/50
111/111 [==============================] - 0s 3ms/step - loss: 8.0051e-04 - val_loss: 3.7428e-04
Epoch 33/50
111/111 [==============================] - 0s 3ms/step - loss: 7.9432e-04 - val_loss: 3.6675e-04
Epoch 34/50
111/111 [==============================] - 0s 3ms/step - loss: 7.2349e-04 - val_loss: 6.2744e-04
Epoch 35/50
111/111 [==============================] - 0s 3ms/step - loss: 7.4088e-04 - val_loss: 3.7306e-04
Epoch 36/50
111/111 [==============================] - 0s 3ms/step - loss: 7.0106e-04 - val_loss: 5.9000e-04
Epoch 37/50
111/111 [==============================] - 0s 3ms/step - loss: 7.2617e-04 - val_loss: 3.9488e-04
28/28 [==============================] - 0s 863us/step
28/28 [==============================] - 0s 786us/step
UAL : 0.00036251425899156 0.012167557145071135 0.019039807220441074
UAL : 37.87905254234436 29.659211037711923 -8.219841504632438
Data for UAL saved successfully.
Epoch 1/50
124/236 [==============>...............] - ETA: 0s - loss: 0.0037
111/111 [==============================] - 0s 3ms/step - loss: 7.2617e-04 - val_loss: 3.9488e-04
Epoch 4/50=============================] - 0s 3ms/step - loss: 7.2617e-04 - val_loss: 3.9488e-04
 41/236 [====>.........................] - ETA: 0s - loss: 1.9143e-04
Epoch 4/50=============================] - 0s 3ms/step - loss: 7.2617e-04 - val_loss: 3.9488e-04
Epoch 10/50============================] - 0s 3ms/step - loss: 7.2617e-04 - val_loss: 3.9488e-04
Epoch 10/50============================] - 0s 3ms/step - loss: 7.2617e-04 - val_loss: 3.9488e-04
TROW : 0.000102015897276887 0.006954774798212179 0.010100291940181087e-04 - val_loss: 3.9488e-04
TROW : 0.000102015897276887 0.006954774798212179 0.010100291940181087e-04 - val_loss: 3.9488e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
146/146 [==============================] - 0s 3ms/step - loss: 2.7007e-04 - val_loss: 0.0012e-04
146/146 [==============================] - 0s 3ms/step - loss: 1.8156e-04 - val_loss: 0.0040e-04
146/146 [==============================] - 0s 3ms/step - loss: 1.8156e-04 - val_loss: 0.0040e-04
146/146 [==============================] - 0s 3ms/step - loss: 1.8156e-04 - val_loss: 0.0040e-04
Epoch 3/50=============================] - 0s 3ms/step - loss: 1.8156e-04 - val_loss: 0.0040e-04
Epoch 3/50=============================] - 0s 3ms/step - loss: 1.8156e-04 - val_loss: 0.0040e-04
Epoch 9/50=============================] - 0s 3ms/step - loss: 1.8156e-04 - val_loss: 0.0040e-04
Epoch 9/50=============================] - 0s 3ms/step - loss: 1.8156e-04 - val_loss: 0.0040e-04
144/144 [==============================] - 2s 4ms/step - loss: 0.0181 - val_loss: 7.9988e-04e-04
144/144 [==============================] - 2s 4ms/step - loss: 0.0181 - val_loss: 7.9988e-04e-04
 41/144 [=======>......................] - ETA: 0s - loss: 0.00140181 - val_loss: 7.9988e-04e-04
144/144 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 5.2805e-04e-04
144/144 [==============================] - 0s 3ms/step - loss: 9.9214e-04 - val_loss: 1.1819e-04
144/144 [==============================] - 0s 3ms/step - loss: 7.4011e-04 - val_loss: 1.7805e-04
121/144 [========================>.....] - ETA: 0s - loss: 6.2519e-04e-04 - val_loss: 1.7805e-04
144/144 [==============================] - 0s 3ms/step - loss: 6.1660e-04 - val_loss: 9.5646e-05
144/144 [==============================] - 0s 3ms/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 37/50============================] - 0s 3ms/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 42/50============================] - 0s 3ms/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 42/50============================] - 0s 3ms/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Data for TPR saved successfully.=======] - 0s 3ms/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 3/50PR saved successfully.=======] - 0s 3ms/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 6/50PR saved successfully.=======] - 0s 3ms/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 9/50PR saved successfully.=======] - 0s 3ms/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 12/50R saved successfully.=======] - 0s 3ms/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 15/50R saved successfully.=======] - 0s 3ms/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
61/61 [==============================] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 3/50===========================] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 3/50===========================] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 12/50==========================] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Data for CE saved successfully.======] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Data for CE saved successfully.======] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 3/50E saved successfully.======] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 5/50E saved successfully.======] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 7/50E saved successfully.======] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 9/50E saved successfully.======] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 9/50E saved successfully.======] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 12/50 saved successfully.======] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 14/50 saved successfully.======] - 0s 948us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
97/97 [==============================] - 0s 759us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
97/97 [==============================] - 0s 759us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
97/97 [==============================] - 0s 759us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 3/50===========================] - 0s 759us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 5/50===========================] - 0s 759us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 7/50===========================] - 0s 759us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 7/50===========================] - 0s 759us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 10/50==========================] - 0s 759us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
Epoch 10/50==========================] - 0s 759us/step - loss: 5.0189e-04 - val_loss: 2.3879e-04
BA : 0.0006071573119856195 0.017729861792508038 0.0246405623309538049e-04 - val_loss: 2.3879e-04
BA : 0.0006071573119856195 0.017729861792508038 0.0246405623309538049e-04 - val_loss: 2.3879e-04
Epoch 3/506071573119856195 0.017729861792508038 0.0246405623309538049e-04 - val_loss: 2.3879e-04
Epoch 6/506071573119856195 0.017729861792508038 0.0246405623309538049e-04 - val_loss: 2.3879e-04
Epoch 9/506071573119856195 0.017729861792508038 0.0246405623309538049e-04 - val_loss: 2.3879e-04
Epoch 13/50071573119856195 0.017729861792508038 0.0246405623309538049e-04 - val_loss: 2.3879e-04
51/51 [==============================] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
51/51 [==============================] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 3/50===========================] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 5/50===========================] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 9/50===========================] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 12/50==========================] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 15/50==========================] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 19/50==========================] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 22/50==========================] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Data for GILD saved successfully.====] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Data for GILD saved successfully.====] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 3/50ILD saved successfully.====] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 8/50ILD saved successfully.====] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 13/50LD saved successfully.====] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
Epoch 13/50LD saved successfully.====] - 0s 881us/step405623309538049e-04 - val_loss: 2.3879e-04
EQIX : 0.0001931627783988852 0.01079935118230106 0.013898301277454206e-04 - val_loss: 2.3879e-04
Epoch 3/50001931627783988852 0.01079935118230106 0.013898301277454206e-04 - val_loss: 2.3879e-04
Epoch 5/50001931627783988852 0.01079935118230106 0.013898301277454206e-04 - val_loss: 2.3879e-04
Epoch 7/50001931627783988852 0.01079935118230106 0.013898301277454206e-04 - val_loss: 2.3879e-04
Epoch 9/50001931627783988852 0.01079935118230106 0.013898301277454206e-04 - val_loss: 2.3879e-04
Epoch 11/5001931627783988852 0.01079935118230106 0.013898301277454206e-04 - val_loss: 2.3879e-04
Epoch 14/5001931627783988852 0.01079935118230106 0.013898301277454206e-04 - val_loss: 2.3879e-04
Epoch 16/5001931627783988852 0.01079935118230106 0.013898301277454206e-04 - val_loss: 2.3879e-04
80/80 [==============================] - 0s 795us/step898301277454206e-04 - val_loss: 2.3879e-04
80/80 [==============================] - 0s 795us/step898301277454206e-04 - val_loss: 2.3879e-04
103/103 [==============================] - 0s 3ms/step - loss: 7.8101e-04 - val_loss: 0.0011e-04
Epoch 5/50=============================] - 0s 3ms/step - loss: 7.8101e-04 - val_loss: 0.0011e-04
Epoch 10/50============================] - 0s 3ms/step - loss: 7.8101e-04 - val_loss: 0.0011e-04
Epoch 10/50============================] - 0s 3ms/step - loss: 7.8101e-04 - val_loss: 0.0011e-04
Epoch 16/50============================] - 0s 3ms/step - loss: 7.8101e-04 - val_loss: 0.0011e-04
318/318 [==============================] - 2s 3ms/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 4/50=============================] - 2s 3ms/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 6/50=============================] - 2s 3ms/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 8/50=============================] - 2s 3ms/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 10/50============================] - 2s 3ms/step - loss: 0.0024 - val_loss: 0.00150011e-04
80/80 [==============================] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Data for MDT saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Data for MDT saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 3/50DT saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 6/50DT saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 9/50DT saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 12/50T saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 12/50T saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/500T saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 16/50T saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 22/50T saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 28/50T saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 34/50T saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 34/50T saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
Epoch 40/50T saved successfully.=====] - 0s 795us/step - loss: 0.0024 - val_loss: 0.00150011e-04
55/55 [==============================] - 1s 7ms/step - loss: 0.0319 - val_loss: 0.0029150011e-04
55/55 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 7.3752e-0411e-04
55/55 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.6041e-0411e-04
55/55 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.9947e-04e-0404
55/55 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 2.9947e-04e-0404
55/55 [==============================] - 0s 3ms/step - loss: 8.2570e-04 - val_loss: 2.0278e-0404
Epoch 4/50===========================] - 0s 3ms/step - loss: 8.2570e-04 - val_loss: 2.0278e-0404
Epoch 10/50==========================] - 0s 3ms/step - loss: 8.2570e-04 - val_loss: 2.0278e-0404
Epoch 10/50==========================] - 0s 3ms/step - loss: 8.2570e-04 - val_loss: 2.0278e-0404
A : 0.00015052437228906036 0.009160592340484407 0.012268837446517106-04 - val_loss: 2.0278e-0404
A : 0.00015052437228906036 0.009160592340484407 0.012268837446517106-04 - val_loss: 2.0278e-0404
29/29 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
29/29 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 1/50===========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 1/50===========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 1/50===========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 1/50===========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 7/50===========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 7/50===========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 7/50===========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 13/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 16/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 16/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 19/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 21/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 23/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 25/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 27/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 29/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 31/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 31/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 34/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 36/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 38/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 40/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 42/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 44/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 44/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 47/50==========================] - 0s 3ms/step - loss: 0.0034 - val_loss: 5.4661e-04e-0404
97/97 [==============================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
97/97 [==============================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 3/50===========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 6/50===========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 10/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 13/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 16/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 20/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 20/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 3/500==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 6/500==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 8/500==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 11/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 14/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 14/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 2/500==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 11/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 23/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 29/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
Epoch 29/50==========================] - 0s 759us/step loss: 0.0034 - val_loss: 5.4661e-04e-0404
ENPH : 0.0003203880959921415 0.012907274052813247 0.01789938814574793 val_loss: 5.4661e-04e-0404
ENPH : 0.0003203880959921415 0.012907274052813247 0.01789938814574793 val_loss: 5.4661e-04e-0404
192/192 [==============================] - 1s 3ms/step - loss: 1.9116e-04 - val_loss: 0.00170404
192/192 [==============================] - 1s 3ms/step - loss: 1.1584e-04 - val_loss: 0.01110404
192/192 [==============================] - 1s 3ms/step - loss: 1.1584e-04 - val_loss: 0.01110404
192/192 [==============================] - 1s 3ms/step - loss: 1.1584e-04 - val_loss: 0.01110404
Epoch 1/50=============================] - 1s 3ms/step - loss: 1.1584e-04 - val_loss: 0.01110404
Epoch 3/50=============================] - 1s 3ms/step - loss: 1.1584e-04 - val_loss: 0.01110404
Epoch 6/50=============================] - 1s 3ms/step - loss: 1.1584e-04 - val_loss: 0.01110404
Epoch 10/50============================] - 1s 3ms/step - loss: 1.1584e-04 - val_loss: 0.01110404
Epoch 13/50============================] - 1s 3ms/step - loss: 1.1584e-04 - val_loss: 0.01110404
Epoch 13/50============================] - 1s 3ms/step - loss: 1.1584e-04 - val_loss: 0.01110404
CDNS : 0.000643348891754474 0.01804791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 3/5000643348891754474 0.01804791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 8/5000643348891754474 0.01804791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 8/5000643348891754474 0.01804791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Data for MSCI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Data for MSCI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 11/50CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 11/50CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 17/50CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 17/50CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 3/500CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 5/500CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 7/500CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 9/500CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 12/50CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 14/50CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
Epoch 14/50CI saved successfully.04791749206336 0.0253643232071047884e-04 - val_loss: 0.01110404
EIX : 0.00045603906826280615 0.016539881273390546 0.021355071253985693-04 - val_loss: 0.01110404
Epoch 3/50045603906826280615 0.016539881273390546 0.021355071253985693-04 - val_loss: 0.01110404
Epoch 9/50045603906826280615 0.016539881273390546 0.021355071253985693-04 - val_loss: 0.01110404
Epoch 21/5045603906826280615 0.016539881273390546 0.021355071253985693-04 - val_loss: 0.01110404
Epoch 27/5045603906826280615 0.016539881273390546 0.021355071253985693-04 - val_loss: 0.01110404
Epoch 33/5045603906826280615 0.016539881273390546 0.021355071253985693-04 - val_loss: 0.01110404
Epoch 39/5045603906826280615 0.016539881273390546 0.021355071253985693-04 - val_loss: 0.01110404
Epoch 45/5045603906826280615 0.016539881273390546 0.021355071253985693-04 - val_loss: 0.01110404
Epoch 45/5045603906826280615 0.016539881273390546 0.021355071253985693-04 - val_loss: 0.01110404
25/25 [==============================] - 0s 903us/step1355071253985693-04 - val_loss: 0.01110404
 21/242 [=>............................] - ETA: 0s - loss: 3.1342e-043-04 - val_loss: 0.01110404
242/242 [==============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 9/50=============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 12/50============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 14/50============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 14/50============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/500============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 7/500============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 10/50============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 14/50============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 16/50============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 19/50============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 19/50============================] - 1s 3ms/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
54/54 [==============================] - 0s 989us/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
54/54 [==============================] - 0s 989us/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 4/50===========================] - 0s 989us/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 7/50===========================] - 0s 989us/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 9/50===========================] - 0s 989us/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 12/50==========================] - 0s 989us/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 15/50==========================] - 0s 989us/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 17/50==========================] - 0s 989us/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 19/50==========================] - 0s 989us/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 19/50==========================] - 0s 989us/step - loss: 2.7290e-04 - val_loss: 1.4419e-04
WBA : 22.006653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 3/5006653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 8/5006653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 13/506653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 18/506653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 18/506653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 18/506653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 3/5006653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 15/506653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 15/506653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
Epoch 15/506653472467608 78.70697237258989 56.700318900122284: 2.7290e-04 - val_loss: 1.4419e-04
247/247 [==============================] - 2s 4ms/step - loss: 6.7491e-04 - val_loss: 0.0074e-04
Epoch 5/50=============================] - 2s 4ms/step - loss: 6.7491e-04 - val_loss: 0.0074e-04
Epoch 7/50=============================] - 2s 4ms/step - loss: 6.7491e-04 - val_loss: 0.0074e-04
Epoch 9/50=============================] - 2s 4ms/step - loss: 6.7491e-04 - val_loss: 0.0074e-04
Epoch 12/50============================] - 2s 4ms/step - loss: 6.7491e-04 - val_loss: 0.0074e-04
AJG : 0.0030646793669592506 0.032350006638790625 0.055359546303769961e-04 - val_loss: 0.0074e-04
AJG : 0.0030646793669592506 0.032350006638790625 0.055359546303769961e-04 - val_loss: 0.0074e-04
AJG : 0.0030646793669592506 0.032350006638790625 0.055359546303769961e-04 - val_loss: 0.0074e-04
Epoch 3/5030646793669592506 0.032350006638790625 0.055359546303769961e-04 - val_loss: 0.0074e-04
Epoch 3/5030646793669592506 0.032350006638790625 0.055359546303769961e-04 - val_loss: 0.0074e-04
Epoch 6/5030646793669592506 0.032350006638790625 0.055359546303769961e-04 - val_loss: 0.0074e-04
Epoch 8/5030646793669592506 0.032350006638790625 0.055359546303769961e-04 - val_loss: 0.0074e-04
Epoch 10/500646793669592506 0.032350006638790625 0.055359546303769961e-04 - val_loss: 0.0074e-04
Epoch 10/500646793669592506 0.032350006638790625 0.055359546303769961e-04 - val_loss: 0.0074e-04
97/97 [==============================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
97/97 [==============================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/50===========================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 6/50===========================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 8/50===========================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 11/50==========================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 13/50==========================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 16/50==========================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 18/50==========================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 20/50==========================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 23/50==========================] - 0s 758us/step359546303769961e-04 - val_loss: 0.0074e-04
74/74 [==============================] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
74/74 [==============================] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Data for C saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 3/50 saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 6/50 saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 9/50 saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 12/50saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 14/50saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 17/50saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 20/50saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 23/50saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 26/50saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
Epoch 26/50saved successfully.=======] - 0s 812us/step359546303769961e-04 - val_loss: 0.0074e-04
T : 0.00015572703843643544 0.008111781207329591 0.0124790640048216531e-04 - val_loss: 0.0074e-04
Epoch 3/505572703843643544 0.008111781207329591 0.0124790640048216531e-04 - val_loss: 0.0074e-04
Epoch 7/505572703843643544 0.008111781207329591 0.0124790640048216531e-04 - val_loss: 0.0074e-04
Epoch 7/505572703843643544 0.008111781207329591 0.0124790640048216531e-04 - val_loss: 0.0074e-04
Epoch 13/50572703843643544 0.008111781207329591 0.0124790640048216531e-04 - val_loss: 0.0074e-04
223/223 [==============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 4/50=============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 7/50=============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 10/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 13/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 17/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 20/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 23/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 26/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 29/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 32/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 36/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 39/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 42/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 44/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 47/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 47/50============================] - 2s 4ms/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
56/56 [==============================] - 0s 814us/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
56/56 [==============================] - 0s 814us/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 4/50===========================] - 0s 814us/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 6/50===========================] - 0s 814us/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 9/50===========================] - 0s 814us/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 12/50==========================] - 0s 814us/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 12/50==========================] - 0s 814us/step - loss: 0.0040 - val_loss: 3.6405e-04e-04
HUM : 479.76902371585317 191.44062972441316 -288.32839399144s: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 9/5076902371585317 191.44062972441316 -288.32839399144s: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 15/506902371585317 191.44062972441316 -288.32839399144s: 0.0040 - val_loss: 3.6405e-04e-04
Epoch 15/506902371585317 191.44062972441316 -288.32839399144s: 0.0040 - val_loss: 3.6405e-04e-04
CBOE : 0.00019716708797946743 0.01099582074086389 0.014041619848844628- val_loss: 3.6405e-04e-04
57/57 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 3.6454e-0404e-04
20/57 [=========>....................] - ETA: 0s - loss: 0.00130016 - val_loss: 3.1944e-0404e-04
20/57 [=========>....................] - ETA: 0s - loss: 0.00130016 - val_loss: 3.1944e-0404e-04
57/57 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 2.7877e-0404e-04
57/57 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 2.7877e-0404e-04
Epoch 4/50===========================] - 0s 3ms/step - loss: 0.0014 - val_loss: 2.7877e-0404e-04
Epoch 10/50==========================] - 0s 3ms/step - loss: 0.0014 - val_loss: 2.7877e-0404e-04
Epoch 10/50==========================] - 0s 3ms/step - loss: 0.0014 - val_loss: 2.7877e-0404e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
288/308 [===========================>..] - ETA: 0s - loss: 3.9670e-04 val_loss: 2.7877e-0404e-04
Epoch 4/50==========================>..] - ETA: 0s - loss: 3.9670e-04 val_loss: 2.7877e-0404e-04
Epoch 7/50==========================>..] - ETA: 0s - loss: 3.9670e-04 val_loss: 2.7877e-0404e-04
Epoch 10/50=========================>..] - ETA: 0s - loss: 3.9670e-04 val_loss: 2.7877e-0404e-04
Epoch 13/50=========================>..] - ETA: 0s - loss: 3.9670e-04 val_loss: 2.7877e-0404e-04
SYY : 67.21412880618595 36.680277214160924 -30.533851592025039670e-04 val_loss: 2.7877e-0404e-04
SYY : 67.21412880618595 36.680277214160924 -30.533851592025039670e-04 val_loss: 2.7877e-0404e-04
Epoch 3/501412880618595 36.680277214160924 -30.533851592025039670e-04 val_loss: 2.7877e-0404e-04
Epoch 3/501412880618595 36.680277214160924 -30.533851592025039670e-04 val_loss: 2.7877e-0404e-04
341/388 [=========================>....] - ETA: 0s - loss: 1.7560e-04 val_loss: 2.7877e-0404e-04
Epoch 8/50========================>....] - ETA: 0s - loss: 1.7560e-04 val_loss: 2.7877e-0404e-04
Epoch 10/50=======================>....] - ETA: 0s - loss: 1.7560e-04 val_loss: 2.7877e-0404e-04
Epoch 10/50=======================>....] - ETA: 0s - loss: 1.7560e-04 val_loss: 2.7877e-0404e-04
Epoch 13/50=======================>....] - ETA: 0s - loss: 1.7560e-04 val_loss: 2.7877e-0404e-04
Epoch 13/50=======================>....] - ETA: 0s - loss: 1.7560e-04 val_loss: 2.7877e-0404e-04
MSI : 5.930758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 3/500758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 6/500758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 10/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 14/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 18/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 22/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 26/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 30/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 34/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 38/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 42/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 46/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
Epoch 46/50758573167917e-05 0.005304380829971193 0.007701141845965387 val_loss: 2.7877e-0404e-04
FCX : 35.18734983208799 18.622473187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 3/508734983208799 18.622473187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 6/508734983208799 18.622473187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 8/508734983208799 18.622473187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 11/50734983208799 18.622473187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 13/50734983208799 18.622473187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Data for ADM saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Data for ADM saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 3/50DM saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 7/50DM saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 10/50M saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 13/50M saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 13/50M saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 3/500M saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 5/500M saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 11/50M saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 17/50M saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
Epoch 17/50M saved successfully.3187744617 -16.5648766443433745965387 val_loss: 2.7877e-0404e-04
BLDR : 130.66746933048776 14.140254678374472 -116.5272146521132965387 val_loss: 2.7877e-0404e-04
Epoch 3/50.66746933048776 14.140254678374472 -116.5272146521132965387 val_loss: 2.7877e-0404e-04
Epoch 5/50.66746933048776 14.140254678374472 -116.5272146521132965387 val_loss: 2.7877e-0404e-04
Epoch 7/50.66746933048776 14.140254678374472 -116.5272146521132965387 val_loss: 2.7877e-0404e-04
Epoch 10/5066746933048776 14.140254678374472 -116.5272146521132965387 val_loss: 2.7877e-0404e-04
Epoch 12/5066746933048776 14.140254678374472 -116.5272146521132965387 val_loss: 2.7877e-0404e-04
Epoch 12/5066746933048776 14.140254678374472 -116.5272146521132965387 val_loss: 2.7877e-0404e-04
80/80 [==============================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
80/80 [==============================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 3/50===========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 6/50===========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 8/50===========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 10/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 12/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 15/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 17/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 19/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 21/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 23/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 26/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 28/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 30/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 30/50==========================] - 0s 806us/step146521132965387 val_loss: 2.7877e-0404e-04
80/80 [==============================] - 0s 802us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 3/50===========================] - 0s 802us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 14/50==========================] - 0s 802us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 20/50==========================] - 0s 802us/step146521132965387 val_loss: 2.7877e-0404e-04
Epoch 32/50==========================] - 0s 802us/step146521132965387 val_loss: 2.7877e-0404e-04
PSX : 0.0003772620644047494 0.014180603225475692 0.019423235168342823 val_loss: 2.7877e-0404e-04
PSX : 0.0003772620644047494 0.014180603225475692 0.019423235168342823 val_loss: 2.7877e-0404e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
PSX : 0.0003772620644047494 0.014180603225475692 0.019423235168342823 val_loss: 2.7877e-0404e-04
143/143 [==============================] - 0s 3ms/step - loss: 3.5229e-04 - val_loss: 8.4453e-04
143/143 [==============================] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
143/143 [==============================] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 2/50=============================] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
Epoch 6/50=============================] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
Epoch 10/50============================] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
Data for HUBB saved successfully.======] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
Data for HUBB saved successfully.======] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
Epoch 3/50UBB saved successfully.======] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
Epoch 6/50UBB saved successfully.======] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
Epoch 8/50UBB saved successfully.======] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
Epoch 11/50BB saved successfully.======] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
Epoch 13/50BB saved successfully.======] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
Epoch 13/50BB saved successfully.======] - 0s 3ms/step - loss: 2.6713e-04 - val_loss: 4.7602e-04
PPG : 0.00012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
Epoch 3/50012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
Epoch 5/50012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
Epoch 9/50012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
Epoch 12/5012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
Epoch 12/5012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
Epoch 2/50012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
Epoch 4/50012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
Epoch 8/50012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
Epoch 12/5012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
Epoch 12/5012908884788058561 0.009026407655097336 0.011361727328209633-04 - val_loss: 4.7602e-04
IRM : 0.00038300764364680896 0.01569618049999519 0.0195705810758599853-04 - val_loss: 4.7602e-04
Epoch 9/50038300764364680896 0.01569618049999519 0.0195705810758599853-04 - val_loss: 4.7602e-04
Epoch 21/5038300764364680896 0.01569618049999519 0.0195705810758599853-04 - val_loss: 4.7602e-04
Epoch 27/5038300764364680896 0.01569618049999519 0.0195705810758599853-04 - val_loss: 4.7602e-04
Epoch 33/5038300764364680896 0.01569618049999519 0.0195705810758599853-04 - val_loss: 4.7602e-04
Epoch 33/5038300764364680896 0.01569618049999519 0.0195705810758599853-04 - val_loss: 4.7602e-04
 78/184 [===========>..................] - ETA: 0s - loss: 0.001399853-04 - val_loss: 4.7602e-04
184/184 [==============================] - 1s 3ms/step - loss: 0.0012 - val_loss: 0.00147602e-04
184/184 [==============================] - 1s 3ms/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
184/184 [==============================] - 1s 3ms/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
46/46 [==============================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
46/46 [==============================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 3/50===========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 5/50===========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 10/50==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 16/50==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 21/50==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 21/50==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 26/50==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 26/50==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 4/500==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 6/500==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 8/500==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 11/50==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 13/50==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 15/50==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
Epoch 15/50==========================] - 0s 941us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
81/81 [==============================] - 0s 963us/step - loss: 5.0115e-04 - val_loss: 4.8495e-04
 65/198 [========>.....................] - ETA: 0s - loss: 7.6097e-04e-04 - val_loss: 4.8495e-04
Epoch 4/50=======>.....................] - ETA: 0s - loss: 7.6097e-04e-04 - val_loss: 4.8495e-04
Epoch 8/50=======>.....................] - ETA: 0s - loss: 7.6097e-04e-04 - val_loss: 4.8495e-04
Epoch 11/50======>.....................] - ETA: 0s - loss: 7.6097e-04e-04 - val_loss: 4.8495e-04
Epoch 15/50======>.....................] - ETA: 0s - loss: 7.6097e-04e-04 - val_loss: 4.8495e-04
Epoch 19/50======>.....................] - ETA: 0s - loss: 7.6097e-04e-04 - val_loss: 4.8495e-04
Epoch 19/50======>.....................] - ETA: 0s - loss: 7.6097e-04e-04 - val_loss: 4.8495e-04
STZ : 0.00030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
Epoch 3/50030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
Epoch 6/50030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
Epoch 10/5030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
Epoch 15/5030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
Epoch 19/5030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
Epoch 23/5030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
Epoch 27/5030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
Epoch 32/5030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
Epoch 36/5030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
Epoch 36/5030632880484329664 0.014141141278009474 0.017502251422125574-04 - val_loss: 4.8495e-04
BG : 9.686258110824187e-05 0.007024435899959813 0.00984187894196234774-04 - val_loss: 4.8495e-04
Epoch 3/50258110824187e-05 0.007024435899959813 0.00984187894196234774-04 - val_loss: 4.8495e-04
Epoch 6/50258110824187e-05 0.007024435899959813 0.00984187894196234774-04 - val_loss: 4.8495e-04
Epoch 12/5058110824187e-05 0.007024435899959813 0.00984187894196234774-04 - val_loss: 4.8495e-04
Epoch 17/5058110824187e-05 0.007024435899959813 0.00984187894196234774-04 - val_loss: 4.8495e-04
Epoch 22/5058110824187e-05 0.007024435899959813 0.00984187894196234774-04 - val_loss: 4.8495e-04
Epoch 27/5058110824187e-05 0.007024435899959813 0.00984187894196234774-04 - val_loss: 4.8495e-04
Epoch 27/5058110824187e-05 0.007024435899959813 0.00984187894196234774-04 - val_loss: 4.8495e-04
169/274 [=================>............] - ETA: 0s - loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 4/50================>............] - ETA: 0s - loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 6/50================>............] - ETA: 0s - loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 9/50================>............] - ETA: 0s - loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 11/50===============>............] - ETA: 0s - loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 13/50===============>............] - ETA: 0s - loss: 2.6153e-044-04 - val_loss: 4.8495e-04
69/69 [==============================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
69/69 [==============================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
69/69 [==============================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 3/50===========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 5/50===========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 7/50===========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 9/50===========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 11/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 14/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 16/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 18/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 20/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 23/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 25/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 27/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 29/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 31/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 34/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 34/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 37/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 40/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 42/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 44/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 47/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 49/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 49/50==========================] - 0s 1ms/step loss: 2.6153e-044-04 - val_loss: 4.8495e-04
81/81 [==============================] - 0s 988us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
81/81 [==============================] - 0s 988us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 4/50===========================] - 0s 988us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 7/50===========================] - 0s 988us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 10/50==========================] - 0s 988us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
59/59 [==============================] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
59/59 [==============================] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/50===========================] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 8/50===========================] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 12/50==========================] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 16/50==========================] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 16/50==========================] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 3/500==========================] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Data for SMCI saved successfully.====] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Data for SMCI saved successfully.====] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/50MCI saved successfully.====] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 7/50MCI saved successfully.====] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
Epoch 11/50CI saved successfully.====] - 0s 851us/steposs: 2.6153e-044-04 - val_loss: 4.8495e-04
CPRT : 0.00038907698206035884 0.015761474329943494 0.01972503439947213-04 - val_loss: 4.8495e-04
CPRT : 0.00038907698206035884 0.015761474329943494 0.01972503439947213-04 - val_loss: 4.8495e-04
Epoch 3/500038907698206035884 0.015761474329943494 0.01972503439947213-04 - val_loss: 4.8495e-04
Epoch 7/500038907698206035884 0.015761474329943494 0.01972503439947213-04 - val_loss: 4.8495e-04
Epoch 13/50038907698206035884 0.015761474329943494 0.01972503439947213-04 - val_loss: 4.8495e-04
Epoch 19/50038907698206035884 0.015761474329943494 0.01972503439947213-04 - val_loss: 4.8495e-04
272/274 [============================>.] - ETA: 0s - loss: 8.6250e-043-04 - val_loss: 4.8495e-04
272/274 [============================>.] - ETA: 0s - loss: 8.6250e-043-04 - val_loss: 4.8495e-04
Epoch 3/50===========================>.] - ETA: 0s - loss: 8.6250e-043-04 - val_loss: 4.8495e-04
Epoch 6/50===========================>.] - ETA: 0s - loss: 8.6250e-043-04 - val_loss: 4.8495e-04
Epoch 8/50===========================>.] - ETA: 0s - loss: 8.6250e-043-04 - val_loss: 4.8495e-04
Epoch 10/50==========================>.] - ETA: 0s - loss: 8.6250e-043-04 - val_loss: 4.8495e-04
Epoch 12/50==========================>.] - ETA: 0s - loss: 8.6250e-043-04 - val_loss: 4.8495e-04
Epoch 12/50==========================>.] - ETA: 0s - loss: 8.6250e-043-04 - val_loss: 4.8495e-04
TFX : 210.67181576805376 124.43095466987526 -86.24086109817856250e-043-04 - val_loss: 4.8495e-04
Epoch 3/5067181576805376 124.43095466987526 -86.24086109817856250e-043-04 - val_loss: 4.8495e-04
Epoch 9/5067181576805376 124.43095466987526 -86.24086109817856250e-043-04 - val_loss: 4.8495e-04
Epoch 9/5067181576805376 124.43095466987526 -86.24086109817856250e-043-04 - val_loss: 4.8495e-04
Epoch 15/507181576805376 124.43095466987526 -86.24086109817856250e-043-04 - val_loss: 4.8495e-04
Epoch 3/5007181576805376 124.43095466987526 -86.24086109817856250e-043-04 - val_loss: 4.8495e-04
Epoch 5/5007181576805376 124.43095466987526 -86.24086109817856250e-043-04 - val_loss: 4.8495e-04
Epoch 10/507181576805376 124.43095466987526 -86.24086109817856250e-043-04 - val_loss: 4.8495e-04
42/42 [==============================] - 0s 919us/step09817856250e-043-04 - val_loss: 4.8495e-04
42/42 [==============================] - 0s 919us/step09817856250e-043-04 - val_loss: 4.8495e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/50===========================] - 0s 919us/step09817856250e-043-04 - val_loss: 4.8495e-04
Epoch 6/50===========================] - 0s 919us/step09817856250e-043-04 - val_loss: 4.8495e-04
Epoch 9/50===========================] - 0s 919us/step09817856250e-043-04 - val_loss: 4.8495e-04
Epoch 11/50==========================] - 0s 919us/step09817856250e-043-04 - val_loss: 4.8495e-04
69/69 [==============================] - 0s 865us/step09817856250e-043-04 - val_loss: 4.8495e-04
Epoch 14/50==========================] - 0s 865us/step09817856250e-043-04 - val_loss: 4.8495e-04
Epoch 14/50==========================] - 0s 865us/step09817856250e-043-04 - val_loss: 4.8495e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 14/50==========================] - 0s 865us/step09817856250e-043-04 - val_loss: 4.8495e-04
192/192 [==============================] - 1s 3ms/step - loss: 5.2086e-04 - val_loss: 5.9086e-04
192/192 [==============================] - 1s 3ms/step - loss: 5.2086e-04 - val_loss: 5.9086e-04
Epoch 9/50=============================] - 1s 3ms/step - loss: 5.2086e-04 - val_loss: 5.9086e-04
CB : 0.00029258650852221496 0.013893629604695753 0.017105160289287416e-04 - val_loss: 5.9086e-04
CB : 0.00029258650852221496 0.013893629604695753 0.017105160289287416e-04 - val_loss: 5.9086e-04
Epoch 3/5029258650852221496 0.013893629604695753 0.017105160289287416e-04 - val_loss: 5.9086e-04
Epoch 5/5029258650852221496 0.013893629604695753 0.017105160289287416e-04 - val_loss: 5.9086e-04
Epoch 7/5029258650852221496 0.013893629604695753 0.017105160289287416e-04 - val_loss: 5.9086e-04
Epoch 9/5029258650852221496 0.013893629604695753 0.017105160289287416e-04 - val_loss: 5.9086e-04
69/69 [==============================] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
Data for TSN saved successfully.=====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
Data for TSN saved successfully.=====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 3/50SN saved successfully.=====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 7/50SN saved successfully.=====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
Data for GNRC saved successfully.====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
Data for GNRC saved successfully.====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/50NRC saved successfully.====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 6/50NRC saved successfully.====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 8/50NRC saved successfully.====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 11/50RC saved successfully.====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 11/50RC saved successfully.====] - 0s 903us/step105160289287416e-04 - val_loss: 5.9086e-04
81/81 [==============================] - 0s 847us/step105160289287416e-04 - val_loss: 5.9086e-04
81/81 [==============================] - 0s 847us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 4/50===========================] - 0s 847us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 6/50===========================] - 0s 847us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 9/50===========================] - 0s 847us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 11/50==========================] - 0s 847us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 13/50==========================] - 0s 847us/step105160289287416e-04 - val_loss: 5.9086e-04
Epoch 13/50==========================] - 0s 847us/step105160289287416e-04 - val_loss: 5.9086e-04
PEG : 63.554694812765064 42.52883746194327 -21.0258573508217959287416e-04 - val_loss: 5.9086e-04
Epoch 10/504694812765064 42.52883746194327 -21.0258573508217959287416e-04 - val_loss: 5.9086e-04
Epoch 16/504694812765064 42.52883746194327 -21.0258573508217959287416e-04 - val_loss: 5.9086e-04
Epoch 16/504694812765064 42.52883746194327 -21.0258573508217959287416e-04 - val_loss: 5.9086e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
323/323 [==============================] - 1s 2ms/step - loss: 5.0424e-05 - val_loss: 9.9762e-04
Epoch 6/50=============================] - 1s 2ms/step - loss: 5.0424e-05 - val_loss: 9.9762e-04
Epoch 9/50=============================] - 1s 2ms/step - loss: 5.0424e-05 - val_loss: 9.9762e-04
Epoch 11/50============================] - 1s 2ms/step - loss: 5.0424e-05 - val_loss: 9.9762e-04
Epoch 13/50============================] - 1s 2ms/step - loss: 5.0424e-05 - val_loss: 9.9762e-04
Epoch 16/50============================] - 1s 2ms/step - loss: 5.0424e-05 - val_loss: 9.9762e-04
Epoch 16/50============================] - 1s 2ms/step - loss: 5.0424e-05 - val_loss: 9.9762e-04
LLY : 0.00025706229075621437 0.009939639724329817 0.01603316221948167e-05 - val_loss: 9.9762e-04
Epoch 3/50025706229075621437 0.009939639724329817 0.01603316221948167e-05 - val_loss: 9.9762e-04
Epoch 5/50025706229075621437 0.009939639724329817 0.01603316221948167e-05 - val_loss: 9.9762e-04
Epoch 7/50025706229075621437 0.009939639724329817 0.01603316221948167e-05 - val_loss: 9.9762e-04
Epoch 10/5025706229075621437 0.009939639724329817 0.01603316221948167e-05 - val_loss: 9.9762e-04
Epoch 10/5025706229075621437 0.009939639724329817 0.01603316221948167e-05 - val_loss: 9.9762e-04
COST : 0.00013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 3/500013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 6/500013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 9/500013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 13/50013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 16/50013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 20/50013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 23/50013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 27/50013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 30/50013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 34/50013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
Epoch 34/50013901079076605952 0.008813350738506004 0.01179028374408604-05 - val_loss: 9.9762e-04
REG : 0.00010764045658588906 0.0076364499649086955 0.01037499188365412905 - val_loss: 9.9762e-04
Epoch 9/50010764045658588906 0.0076364499649086955 0.01037499188365412905 - val_loss: 9.9762e-04
Epoch 15/5010764045658588906 0.0076364499649086955 0.01037499188365412905 - val_loss: 9.9762e-04
Epoch 15/5010764045658588906 0.0076364499649086955 0.01037499188365412905 - val_loss: 9.9762e-04
Epoch 21/5010764045658588906 0.0076364499649086955 0.01037499188365412905 - val_loss: 9.9762e-04
149/274 [===============>..............] - ETA: 0s - loss: 1.2580e-042905 - val_loss: 9.9762e-04
274/274 [==============================] - 1s 3ms/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
Epoch 6/50=============================] - 1s 3ms/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
Epoch 9/50=============================] - 1s 3ms/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
Epoch 11/50============================] - 1s 3ms/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
Epoch 14/50============================] - 1s 3ms/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
Epoch 14/50============================] - 1s 3ms/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
69/69 [==============================] - 0s 926us/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
Epoch 3/50===========================] - 0s 926us/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
Epoch 5/50===========================] - 0s 926us/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
Epoch 9/50===========================] - 0s 926us/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
Epoch 9/50===========================] - 0s 926us/step - loss: 1.1424e-04 - val_loss: 0.0331e-04
MDLZ : 0.0002326977882826096 0.01156845799238246 0.015254435036493824e-04 - val_loss: 0.0331e-04
Epoch 3/50002326977882826096 0.01156845799238246 0.015254435036493824e-04 - val_loss: 0.0331e-04
Epoch 7/50002326977882826096 0.01156845799238246 0.015254435036493824e-04 - val_loss: 0.0331e-04
Epoch 11/5002326977882826096 0.01156845799238246 0.015254435036493824e-04 - val_loss: 0.0331e-04
Epoch 11/5002326977882826096 0.01156845799238246 0.015254435036493824e-04 - val_loss: 0.0331e-04
39/39 [==============================] - 0s 895us/step254435036493824e-04 - val_loss: 0.0331e-04
Epoch 3/50===========================] - 0s 895us/step254435036493824e-04 - val_loss: 0.0331e-04
Epoch 5/50===========================] - 0s 895us/step254435036493824e-04 - val_loss: 0.0331e-04
Epoch 8/50===========================] - 0s 895us/step254435036493824e-04 - val_loss: 0.0331e-04
Epoch 11/50==========================] - 0s 895us/step254435036493824e-04 - val_loss: 0.0331e-04
Epoch 14/50==========================] - 0s 895us/step254435036493824e-04 - val_loss: 0.0331e-04
ZBRA : 213.84178884115937 110.02380447884082 -103.8179843623185593824e-04 - val_loss: 0.0331e-04
ZBRA : 213.84178884115937 110.02380447884082 -103.8179843623185593824e-04 - val_loss: 0.0331e-04
Epoch 3/50.84178884115937 110.02380447884082 -103.8179843623185593824e-04 - val_loss: 0.0331e-04
Epoch 5/50.84178884115937 110.02380447884082 -103.8179843623185593824e-04 - val_loss: 0.0331e-04
Epoch 7/50.84178884115937 110.02380447884082 -103.8179843623185593824e-04 - val_loss: 0.0331e-04
Epoch 10/5084178884115937 110.02380447884082 -103.8179843623185593824e-04 - val_loss: 0.0331e-04
69/69 [==============================] - 0s 911us/step843623185593824e-04 - val_loss: 0.0331e-04
69/69 [==============================] - 0s 911us/step843623185593824e-04 - val_loss: 0.0331e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/50===========================] - 0s 911us/step843623185593824e-04 - val_loss: 0.0331e-04
Epoch 6/50===========================] - 0s 911us/step843623185593824e-04 - val_loss: 0.0331e-04
Epoch 6/50===========================] - 0s 911us/step843623185593824e-04 - val_loss: 0.0331e-04
Epoch 9/50===========================] - 0s 911us/step843623185593824e-04 - val_loss: 0.0331e-04
Epoch 11/50==========================] - 0s 911us/step843623185593824e-04 - val_loss: 0.0331e-04
Epoch 13/50==========================] - 0s 911us/step843623185593824e-04 - val_loss: 0.0331e-04
Epoch 13/50==========================] - 0s 911us/step843623185593824e-04 - val_loss: 0.0331e-04
XEL : 0.0002340931330174653 0.01130179541211024 0.0153001023858491824e-04 - val_loss: 0.0331e-04
Epoch 3/5002340931330174653 0.01130179541211024 0.0153001023858491824e-04 - val_loss: 0.0331e-04
Epoch 5/5002340931330174653 0.01130179541211024 0.0153001023858491824e-04 - val_loss: 0.0331e-04
Epoch 11/502340931330174653 0.01130179541211024 0.0153001023858491824e-04 - val_loss: 0.0331e-04
Epoch 11/502340931330174653 0.01130179541211024 0.0153001023858491824e-04 - val_loss: 0.0331e-04
Epoch 16/502340931330174653 0.01130179541211024 0.0153001023858491824e-04 - val_loss: 0.0331e-04
Epoch 3/5002340931330174653 0.01130179541211024 0.0153001023858491824e-04 - val_loss: 0.0331e-04
Epoch 6/5002340931330174653 0.01130179541211024 0.0153001023858491824e-04 - val_loss: 0.0331e-04
Epoch 10/502340931330174653 0.01130179541211024 0.0153001023858491824e-04 - val_loss: 0.0331e-04
Epoch 14/502340931330174653 0.01130179541211024 0.0153001023858491824e-04 - val_loss: 0.0331e-04
148/148 [==============================] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
Epoch 23/50============================] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
Epoch 27/50============================] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
Epoch 32/50============================] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
Epoch 32/50============================] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
Epoch 3/500============================] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
Epoch 14/50============================] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
Epoch 26/50============================] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
Epoch 38/50============================] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
Epoch 38/50============================] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
Data for FTV saved successfully.=======] - 0s 3ms/step - loss: 5.4340e-04 - val_loss: 1.9121e-04
119/119 [==============================] - 0s 3ms/step - loss: 8.8149e-04 - val_loss: 0.0011e-04
 93/119 [======================>.......] - ETA: 0s - loss: 6.7561e-04e-04 - val_loss: 0.0011e-04
 36/119 [========>.....................] - ETA: 0s - loss: 4.7321e-04e-04 - val_loss: 0.0011e-04
 36/119 [========>.....................] - ETA: 0s - loss: 4.7321e-04e-04 - val_loss: 0.0011e-04
119/119 [==============================] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 3/50=============================] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 3/50=============================] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 9/50=============================] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 9/50=============================] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Data for ACGL saved successfully.======] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Data for ACGL saved successfully.======] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 4/50CGL saved successfully.======] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 7/50CGL saved successfully.======] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 10/50GL saved successfully.======] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 13/50GL saved successfully.======] - 0s 3ms/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
57/57 [==============================] - 0s 927us/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
57/57 [==============================] - 0s 927us/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Data for FAST saved successfully.====] - 0s 927us/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 3/50AST saved successfully.====] - 0s 927us/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 6/50AST saved successfully.====] - 0s 927us/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 9/50AST saved successfully.====] - 0s 927us/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
Epoch 12/50ST saved successfully.====] - 0s 927us/step - loss: 5.2759e-04 - val_loss: 0.0020e-04
TJX : 9.819543056455272e-05 0.007563631016741645 0.009909360754587187e-04 - val_loss: 0.0020e-04
TJX : 9.819543056455272e-05 0.007563631016741645 0.009909360754587187e-04 - val_loss: 0.0020e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/509543056455272e-05 0.007563631016741645 0.009909360754587187e-04 - val_loss: 0.0020e-04
Epoch 6/509543056455272e-05 0.007563631016741645 0.009909360754587187e-04 - val_loss: 0.0020e-04
Epoch 8/509543056455272e-05 0.007563631016741645 0.009909360754587187e-04 - val_loss: 0.0020e-04
Epoch 10/50543056455272e-05 0.007563631016741645 0.009909360754587187e-04 - val_loss: 0.0020e-04
Epoch 12/50543056455272e-05 0.007563631016741645 0.009909360754587187e-04 - val_loss: 0.0020e-04
Epoch 12/50543056455272e-05 0.007563631016741645 0.009909360754587187e-04 - val_loss: 0.0020e-04
80/80 [==============================] - 0s 921us/step909360754587187e-04 - val_loss: 0.0020e-04
Epoch 3/50===========================] - 0s 921us/step909360754587187e-04 - val_loss: 0.0020e-04
Epoch 7/50===========================] - 0s 921us/step909360754587187e-04 - val_loss: 0.0020e-04
Epoch 7/50===========================] - 0s 921us/step909360754587187e-04 - val_loss: 0.0020e-04
20/20 [==============================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 3/50===========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 8/50===========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 14/50==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 20/50==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 26/50==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 26/50==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/500==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 7/500==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 9/500==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 12/50==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 14/50==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 16/50==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 19/50==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
Epoch 21/50==========================] - 0s 1ms/stepep909360754587187e-04 - val_loss: 0.0020e-04
D : 0.00019130752094324773 0.009613191930791616 0.0138313962036826837e-04 - val_loss: 0.0020e-04
D : 0.00019130752094324773 0.009613191930791616 0.0138313962036826837e-04 - val_loss: 0.0020e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
D : 0.00019130752094324773 0.009613191930791616 0.0138313962036826837e-04 - val_loss: 0.0020e-04
Epoch 5/509130752094324773 0.009613191930791616 0.0138313962036826837e-04 - val_loss: 0.0020e-04
Epoch 7/509130752094324773 0.009613191930791616 0.0138313962036826837e-04 - val_loss: 0.0020e-04
Epoch 7/509130752094324773 0.009613191930791616 0.0138313962036826837e-04 - val_loss: 0.0020e-04
Epoch 10/50130752094324773 0.009613191930791616 0.0138313962036826837e-04 - val_loss: 0.0020e-04
Epoch 12/50130752094324773 0.009613191930791616 0.0138313962036826837e-04 - val_loss: 0.0020e-04
Epoch 12/50130752094324773 0.009613191930791616 0.0138313962036826837e-04 - val_loss: 0.0020e-04
Epoch 12/50130752094324773 0.009613191930791616 0.0138313962036826837e-04 - val_loss: 0.0020e-04
MRK : 0.00014969893145711842 0.009378716270387421 0.012235151468499211-04 - val_loss: 0.0020e-04
Epoch 3/50014969893145711842 0.009378716270387421 0.012235151468499211-04 - val_loss: 0.0020e-04
Epoch 7/50014969893145711842 0.009378716270387421 0.012235151468499211-04 - val_loss: 0.0020e-04
Epoch 12/5014969893145711842 0.009378716270387421 0.012235151468499211-04 - val_loss: 0.0020e-04
Epoch 17/5014969893145711842 0.009378716270387421 0.012235151468499211-04 - val_loss: 0.0020e-04
Epoch 17/5014969893145711842 0.009378716270387421 0.012235151468499211-04 - val_loss: 0.0020e-04
33/33 [==============================] - 0s 936us/step2235151468499211-04 - val_loss: 0.0020e-04
33/33 [==============================] - 0s 936us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 4/50===========================] - 0s 936us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 7/50===========================] - 0s 936us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 9/50===========================] - 0s 936us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 12/50==========================] - 0s 936us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 14/50==========================] - 0s 936us/step2235151468499211-04 - val_loss: 0.0020e-04
66/66 [==============================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
66/66 [==============================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
66/66 [==============================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 3/50===========================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 7/50===========================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 11/50==========================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 15/50==========================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 19/50==========================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 23/50==========================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 27/50==========================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 31/50==========================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 35/50==========================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
Epoch 35/50==========================] - 0s 877us/step2235151468499211-04 - val_loss: 0.0020e-04
52/52 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 8.1661e-0420e-04
Epoch 12/50==========================] - 0s 3ms/step - loss: 0.0053 - val_loss: 8.1661e-0420e-04
Epoch 24/50==========================] - 0s 3ms/step - loss: 0.0053 - val_loss: 8.1661e-0420e-04
Epoch 36/50==========================] - 0s 3ms/step - loss: 0.0053 - val_loss: 8.1661e-0420e-04
Epoch 36/50==========================] - 0s 3ms/step - loss: 0.0053 - val_loss: 8.1661e-0420e-04
Epoch 42/50==========================] - 0s 3ms/step - loss: 0.0053 - val_loss: 8.1661e-0420e-04
 19/274 [=>............................] - ETA: 0s - loss: 6.9433e-04 val_loss: 8.1661e-0420e-04
274/274 [==============================] - 1s 3ms/step - loss: 7.1111e-04 - val_loss: 2.8076e-04
274/274 [==============================] - 1s 3ms/step - loss: 7.1111e-04 - val_loss: 2.8076e-04
218/274 [======================>.......] - ETA: 0s - loss: 4.3321e-04e-04 - val_loss: 2.8076e-04
274/274 [==============================] - 1s 3ms/step - loss: 4.6569e-04 - val_loss: 1.8982e-04
Epoch 14/50============================] - 1s 3ms/step - loss: 4.6569e-04 - val_loss: 1.8982e-04
Epoch 16/50============================] - 1s 3ms/step - loss: 4.6569e-04 - val_loss: 1.8982e-04
Epoch 19/50============================] - 1s 3ms/step - loss: 4.6569e-04 - val_loss: 1.8982e-04
Epoch 21/50============================] - 1s 3ms/step - loss: 4.6569e-04 - val_loss: 1.8982e-04
Epoch 23/50============================] - 1s 3ms/step - loss: 4.6569e-04 - val_loss: 1.8982e-04
Epoch 26/50============================] - 1s 3ms/step - loss: 4.6569e-04 - val_loss: 1.8982e-04
Epoch 28/50============================] - 1s 3ms/step - loss: 4.6569e-04 - val_loss: 1.8982e-04
Epoch 28/50============================] - 1s 3ms/step - loss: 4.6569e-04 - val_loss: 1.8982e-04
IPG : 5.988226234307375e-05 0.005367208432997234 0.007738363027351053e-04 - val_loss: 1.8982e-04
Epoch 27/50226234307375e-05 0.005367208432997234 0.007738363027351053e-04 - val_loss: 1.8982e-04
5/5 [==============================] - 0s 1ms/step.007738363027351053e-04 - val_loss: 1.8982e-04
5/5 [==============================] - 0s 1ms/step.007738363027351053e-04 - val_loss: 1.8982e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
 92/276 [=========>....................] - ETA: 0s - loss: 2.1321e-04e-04 - val_loss: 1.8982e-04
276/276 [==============================] - 1s 3ms/step - loss: 1.7192e-04 - val_loss: 0.0073e-04
276/276 [==============================] - 1s 3ms/step - loss: 1.7192e-04 - val_loss: 0.0073e-04
276/276 [==============================] - 1s 3ms/step - loss: 1.0580e-04 - val_loss: 0.0058e-04
276/276 [==============================] - 1s 3ms/step - loss: 1.0580e-04 - val_loss: 0.0058e-04
276/276 [==============================] - 1s 3ms/step - loss: 1.0580e-04 - val_loss: 0.0058e-04
276/276 [==============================] - 1s 3ms/step - loss: 9.7305e-05 - val_loss: 0.0108e-04
276/276 [==============================] - 1s 3ms/step - loss: 9.7305e-05 - val_loss: 0.0108e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
276/276 [==============================] - 1s 3ms/step - loss: 9.7305e-05 - val_loss: 0.0108e-04
Epoch 9/50=============================] - 1s 3ms/step - loss: 9.7305e-05 - val_loss: 0.0108e-04
Epoch 15/50============================] - 1s 3ms/step - loss: 9.7305e-05 - val_loss: 0.0108e-04
Epoch 27/50============================] - 1s 3ms/step - loss: 9.7305e-05 - val_loss: 0.0108e-04
Epoch 39/50============================] - 1s 3ms/step - loss: 9.7305e-05 - val_loss: 0.0108e-04
Epoch 45/50============================] - 1s 3ms/step - loss: 9.7305e-05 - val_loss: 0.0108e-04
Epoch 45/50============================] - 1s 3ms/step - loss: 9.7305e-05 - val_loss: 0.0108e-04
16/16 [==============================] - 0s 1ms/stepep - loss: 9.7305e-05 - val_loss: 0.0108e-04
67/67 [==============================] - 0s 3ms/step - loss: 6.6230e-04 - val_loss: 7.8292e-0404
67/67 [==============================] - 0s 3ms/step - loss: 4.9315e-04 - val_loss: 0.0023e-0404
67/67 [==============================] - 0s 3ms/step - loss: 4.9315e-04 - val_loss: 0.0023e-0404
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 4/50===========================] - 0s 3ms/step - loss: 4.9315e-04 - val_loss: 0.0023e-0404
Epoch 4/50===========================] - 0s 3ms/step - loss: 4.9315e-04 - val_loss: 0.0023e-0404
Epoch 10/50==========================] - 0s 3ms/step - loss: 4.9315e-04 - val_loss: 0.0023e-0404
Epoch 10/50==========================] - 0s 3ms/step - loss: 4.9315e-04 - val_loss: 0.0023e-0404
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
314/319 [============================>.] - ETA: 0s - loss: 1.3867e-0404 - val_loss: 0.0023e-0404
319/319 [==============================] - 1s 3ms/step - loss: 1.3783e-04 - val_loss: 2.6226e-04
319/319 [==============================] - 1s 3ms/step - loss: 1.3783e-04 - val_loss: 2.6226e-04
Epoch 8/50=============================] - 1s 3ms/step - loss: 1.3783e-04 - val_loss: 2.6226e-04
Epoch 10/50============================] - 1s 3ms/step - loss: 1.3783e-04 - val_loss: 2.6226e-04
Epoch 12/50============================] - 1s 3ms/step - loss: 1.3783e-04 - val_loss: 2.6226e-04
ECL : 0.000262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
ECL : 0.000262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 3/500262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 5/500262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 7/500262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 10/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 12/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 15/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 17/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 20/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 23/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 25/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 28/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 30/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 33/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 35/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 37/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 37/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 3/500262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 8/500262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 12/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 12/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 3/500262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 7/500262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 10/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
Epoch 10/50262260636175672 0.014248437712552369 0.0161944631332956583e-04 - val_loss: 2.6226e-04
SBUX : 0.0005033976388367059 0.01864148517437448 0.022436524660399383e-04 - val_loss: 2.6226e-04
Epoch 15/5005033976388367059 0.01864148517437448 0.022436524660399383e-04 - val_loss: 2.6226e-04
Epoch 27/5005033976388367059 0.01864148517437448 0.022436524660399383e-04 - val_loss: 2.6226e-04
Epoch 27/5005033976388367059 0.01864148517437448 0.022436524660399383e-04 - val_loss: 2.6226e-04
Epoch 33/5005033976388367059 0.01864148517437448 0.022436524660399383e-04 - val_loss: 2.6226e-04
161/161 [==============================] - 0s 3ms/step - loss: 4.3052e-04 - val_loss: 2.2137e-04
 96/161 [================>.............] - ETA: 0s - loss: 2.4260e-04e-04 - val_loss: 2.2137e-04
161/161 [==============================] - 0s 3ms/step - loss: 2.2564e-04 - val_loss: 7.2482e-04
161/161 [==============================] - 0s 3ms/step - loss: 2.2564e-04 - val_loss: 7.2482e-04
161/161 [==============================] - 0s 3ms/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
161/161 [==============================] - 0s 3ms/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 4/50=============================] - 0s 3ms/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 4/50=============================] - 0s 3ms/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 10/50============================] - 0s 3ms/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 10/50============================] - 0s 3ms/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
48/48 [==============================] - 0s 844us/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 3/50===========================] - 0s 844us/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 7/50===========================] - 0s 844us/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 12/50==========================] - 0s 844us/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 12/50==========================] - 0s 844us/step - loss: 1.7092e-04 - val_loss: 0.0047e-04
DPZ : 361.6846347613023 296.95244385538547 -64.73219090591681: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 11/50846347613023 296.95244385538547 -64.73219090591681: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 23/50846347613023 296.95244385538547 -64.73219090591681: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 29/50846347613023 296.95244385538547 -64.73219090591681: 1.7092e-04 - val_loss: 0.0047e-04
Epoch 29/50846347613023 296.95244385538547 -64.73219090591681: 1.7092e-04 - val_loss: 0.0047e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
274/274 [==============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
274/274 [==============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 9/50=============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 11/50============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 14/50============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 14/50============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 16/50============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 16/50============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 3/500============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 5/500============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 5/500============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 8/500============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 10/50============================] - 1s 3ms/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
97/97 [==============================] - 0s 746us/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
97/97 [==============================] - 0s 746us/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 3/50===========================] - 0s 746us/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 5/50===========================] - 0s 746us/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 7/50===========================] - 0s 746us/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 9/50===========================] - 0s 746us/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 11/50==========================] - 0s 746us/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 13/50==========================] - 0s 746us/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
Epoch 13/50==========================] - 0s 746us/step - loss: 8.8705e-04 - val_loss: 2.1188e-04
CAT : 0.00020757958695118332 0.009552322977801647 0.014407622529452364-04 - val_loss: 2.1188e-04
 61/201 [========>.....................] - ETA: 0s - loss: 7.4107e-054-04 - val_loss: 2.1188e-04
Epoch 4/50=======>.....................] - ETA: 0s - loss: 7.4107e-054-04 - val_loss: 2.1188e-04
Epoch 7/50=======>.....................] - ETA: 0s - loss: 7.4107e-054-04 - val_loss: 2.1188e-04
Epoch 11/50======>.....................] - ETA: 0s - loss: 7.4107e-054-04 - val_loss: 2.1188e-04
Epoch 15/50======>.....................] - ETA: 0s - loss: 7.4107e-054-04 - val_loss: 2.1188e-04
Epoch 18/50======>.....................] - ETA: 0s - loss: 7.4107e-054-04 - val_loss: 2.1188e-04
Epoch 18/50======>.....................] - ETA: 0s - loss: 7.4107e-054-04 - val_loss: 2.1188e-04
ODFL : 0.0014684379620079745 0.02933628359759615 0.0383202030528019854-04 - val_loss: 2.1188e-04
Epoch 3/50014684379620079745 0.02933628359759615 0.0383202030528019854-04 - val_loss: 2.1188e-04
Epoch 5/50014684379620079745 0.02933628359759615 0.0383202030528019854-04 - val_loss: 2.1188e-04
Epoch 7/50014684379620079745 0.02933628359759615 0.0383202030528019854-04 - val_loss: 2.1188e-04
Epoch 9/50014684379620079745 0.02933628359759615 0.0383202030528019854-04 - val_loss: 2.1188e-04
Epoch 11/5014684379620079745 0.02933628359759615 0.0383202030528019854-04 - val_loss: 2.1188e-04
90/90 [==============================] - 0s 780us/step3202030528019854-04 - val_loss: 2.1188e-04
Data for MCD saved successfully.=====] - 0s 780us/step3202030528019854-04 - val_loss: 2.1188e-04
Data for MCD saved successfully.=====] - 0s 780us/step3202030528019854-04 - val_loss: 2.1188e-04
Epoch 3/50CD saved successfully.=====] - 0s 780us/step3202030528019854-04 - val_loss: 2.1188e-04
Epoch 6/50CD saved successfully.=====] - 0s 780us/step3202030528019854-04 - val_loss: 2.1188e-04
Epoch 9/50CD saved successfully.=====] - 0s 780us/step3202030528019854-04 - val_loss: 2.1188e-04
Epoch 12/50D saved successfully.=====] - 0s 780us/step3202030528019854-04 - val_loss: 2.1188e-04
Epoch 12/50D saved successfully.=====] - 0s 780us/step3202030528019854-04 - val_loss: 2.1188e-04
Epoch 15/50D saved successfully.=====] - 0s 780us/step3202030528019854-04 - val_loss: 2.1188e-04
117/166 [====================>.........] - ETA: 0s - loss: 4.0732e-044-04 - val_loss: 2.1188e-04
Epoch 4/50===================>.........] - ETA: 0s - loss: 4.0732e-044-04 - val_loss: 2.1188e-04
Epoch 9/50===================>.........] - ETA: 0s - loss: 4.0732e-044-04 - val_loss: 2.1188e-04
Epoch 9/50===================>.........] - ETA: 0s - loss: 4.0732e-044-04 - val_loss: 2.1188e-04
Epoch 13/50==================>.........] - ETA: 0s - loss: 4.0732e-044-04 - val_loss: 2.1188e-04
Epoch 13/50==================>.........] - ETA: 0s - loss: 4.0732e-044-04 - val_loss: 2.1188e-04
Epoch 9/500==================>.........] - ETA: 0s - loss: 4.0732e-044-04 - val_loss: 2.1188e-04
176/176 [==============================] - 2s 4ms/step - loss: 0.0038 - val_loss: 3.6309e-04e-04
 41/176 [=====>........................] - ETA: 0s - loss: 3.6024e-04 - val_loss: 3.6309e-04e-04
176/176 [==============================] - 0s 3ms/step - loss: 3.1022e-04 - val_loss: 8.2382e-04
Epoch 13/50============================] - 0s 3ms/step - loss: 3.1022e-04 - val_loss: 8.2382e-04
Epoch 13/50============================] - 0s 3ms/step - loss: 3.1022e-04 - val_loss: 8.2382e-04
EG : 0.00019101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
EG : 0.00019101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 3/5019101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 5/5019101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 7/5019101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 10/509101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 12/509101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 15/509101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 18/509101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 20/509101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 23/509101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 26/509101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 28/509101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
Epoch 28/509101193106124044 0.009471934151320499 0.013820706604990948e-04 - val_loss: 8.2382e-04
69/69 [==============================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
69/69 [==============================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
Epoch 4/50===========================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
Epoch 6/50===========================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
Epoch 8/50===========================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
Epoch 11/50==========================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
Epoch 13/50==========================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
Epoch 15/50==========================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
Epoch 18/50==========================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
Epoch 20/50==========================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
Epoch 20/50==========================] - 0s 839us/step820706604990948e-04 - val_loss: 8.2382e-04
PNR : 0.0005414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
PNR : 0.0005414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
Epoch 4/5005414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
Epoch 7/5005414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
Epoch 10/505414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
Epoch 13/505414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
Epoch 16/505414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
Epoch 18/505414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
Epoch 21/505414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
Epoch 24/505414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
Epoch 24/505414216706404121 0.020476931769301484 0.023268469452037718e-04 - val_loss: 8.2382e-04
GLW : 2.0544508019439157e-05 0.003643815422217708 0.004532604992654793-04 - val_loss: 8.2382e-04
GLW : 2.0544508019439157e-05 0.003643815422217708 0.004532604992654793-04 - val_loss: 8.2382e-04
Epoch 4/5044508019439157e-05 0.003643815422217708 0.004532604992654793-04 - val_loss: 8.2382e-04
Epoch 7/5044508019439157e-05 0.003643815422217708 0.004532604992654793-04 - val_loss: 8.2382e-04
Epoch 9/5044508019439157e-05 0.003643815422217708 0.004532604992654793-04 - val_loss: 8.2382e-04
Epoch 11/504508019439157e-05 0.003643815422217708 0.004532604992654793-04 - val_loss: 8.2382e-04
Epoch 11/504508019439157e-05 0.003643815422217708 0.004532604992654793-04 - val_loss: 8.2382e-04
BDX : 0.00014722739566903347 0.008627004914620874 0.012133729668532815-04 - val_loss: 8.2382e-04
Epoch 3/50014722739566903347 0.008627004914620874 0.012133729668532815-04 - val_loss: 8.2382e-04
Epoch 14/5014722739566903347 0.008627004914620874 0.012133729668532815-04 - val_loss: 8.2382e-04
Epoch 20/5014722739566903347 0.008627004914620874 0.012133729668532815-04 - val_loss: 8.2382e-04
Epoch 26/5014722739566903347 0.008627004914620874 0.012133729668532815-04 - val_loss: 8.2382e-04
Epoch 38/5014722739566903347 0.008627004914620874 0.012133729668532815-04 - val_loss: 8.2382e-04
Epoch 44/5014722739566903347 0.008627004914620874 0.012133729668532815-04 - val_loss: 8.2382e-04
Epoch 44/5014722739566903347 0.008627004914620874 0.012133729668532815-04 - val_loss: 8.2382e-04
Epoch 50/5014722739566903347 0.008627004914620874 0.012133729668532815-04 - val_loss: 8.2382e-04
159/159 [==============================] - 0s 3ms/step - loss: 1.6222e-04 - val_loss: 3.3471e-04
144/159 [==========================>...] - ETA: 0s - loss: 1.1361e-04e-04 - val_loss: 3.3471e-04
144/159 [==========================>...] - ETA: 0s - loss: 1.1361e-04e-04 - val_loss: 3.3471e-04
Epoch 1/50=============================] - 0s 3ms/step - loss: 1.1396e-04 - val_loss: 8.4688e-04
Epoch 1/50=============================] - 0s 3ms/step - loss: 1.1396e-04 - val_loss: 8.4688e-04
Epoch 7/50=============================] - 0s 3ms/step - loss: 1.1396e-04 - val_loss: 8.4688e-04
Epoch 7/50=============================] - 0s 3ms/step - loss: 1.1396e-04 - val_loss: 8.4688e-04
Epoch 13/50============================] - 0s 3ms/step - loss: 1.1396e-04 - val_loss: 8.4688e-04
Epoch 13/50============================] - 0s 3ms/step - loss: 1.1396e-04 - val_loss: 8.4688e-04
74/74 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 8.5274e-0488e-04
74/74 [==============================] - 0s 2ms/step - loss: 6.7567e-04 - val_loss: 3.0499e-0404
74/74 [==============================] - 0s 2ms/step - loss: 6.7567e-04 - val_loss: 3.0499e-0404
74/74 [==============================] - 0s 2ms/step - loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 3/50===========================] - 0s 2ms/step - loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 3/50===========================] - 0s 2ms/step - loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 8/50===========================] - 0s 2ms/step - loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 10/50==========================] - 0s 2ms/step - loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 13/50==========================] - 0s 2ms/step - loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 13/50==========================] - 0s 2ms/step - loss: 4.9976e-04 - val_loss: 2.4389e-0404
66/66 [==============================] - 0s 802us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 3/50===========================] - 0s 802us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 6/50===========================] - 0s 802us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 12/50==========================] - 0s 802us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 18/50==========================] - 0s 802us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 18/50==========================] - 0s 802us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
29/29 [==============================] - 0s 940us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 3/50===========================] - 0s 940us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 7/50===========================] - 0s 940us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 7/50===========================] - 0s 940us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
30/30 [==============================] - 0s 877us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 3/50===========================] - 0s 877us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 5/50===========================] - 0s 877us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 7/50===========================] - 0s 877us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 10/50==========================] - 0s 877us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 12/50==========================] - 0s 877us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 12/50==========================] - 0s 877us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
69/69 [==============================] - 0s 818us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
69/69 [==============================] - 0s 818us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 4/50===========================] - 0s 818us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 7/50===========================] - 0s 818us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 11/50==========================] - 0s 818us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 14/50==========================] - 0s 818us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
Epoch 14/50==========================] - 0s 818us/step loss: 4.9976e-04 - val_loss: 2.4389e-0404
HOLX : 67.20838708235108 39.25080841321954 -27.957578669131543.9976e-04 - val_loss: 2.4389e-0404
Epoch 3/5020838708235108 39.25080841321954 -27.957578669131543.9976e-04 - val_loss: 2.4389e-0404
Epoch 6/5020838708235108 39.25080841321954 -27.957578669131543.9976e-04 - val_loss: 2.4389e-0404
Epoch 9/5020838708235108 39.25080841321954 -27.957578669131543.9976e-04 - val_loss: 2.4389e-0404
Epoch 11/500838708235108 39.25080841321954 -27.957578669131543.9976e-04 - val_loss: 2.4389e-0404
Epoch 11/500838708235108 39.25080841321954 -27.957578669131543.9976e-04 - val_loss: 2.4389e-0404
EXPD : 0.00034345905169454405 0.013287082905068047 0.018532648264469494 - val_loss: 2.4389e-0404
Epoch 9/500034345905169454405 0.013287082905068047 0.018532648264469494 - val_loss: 2.4389e-0404
Epoch 15/50034345905169454405 0.013287082905068047 0.018532648264469494 - val_loss: 2.4389e-0404
Epoch 15/50034345905169454405 0.013287082905068047 0.018532648264469494 - val_loss: 2.4389e-0404
21/21 [==============================] - 0s 1ms/step.018532648264469494 - val_loss: 2.4389e-0404
21/21 [==============================] - 0s 1ms/step.018532648264469494 - val_loss: 2.4389e-0404
Epoch 4/50===========================] - 0s 1ms/step.018532648264469494 - val_loss: 2.4389e-0404
Epoch 7/50===========================] - 0s 1ms/step.018532648264469494 - val_loss: 2.4389e-0404
Epoch 9/50===========================] - 0s 1ms/step.018532648264469494 - val_loss: 2.4389e-0404
Epoch 12/50==========================] - 0s 1ms/step.018532648264469494 - val_loss: 2.4389e-0404
Epoch 12/50==========================] - 0s 1ms/step.018532648264469494 - val_loss: 2.4389e-0404
TXN : 0.00012734692641152082 0.009480217445115952 0.0112848095425452794 - val_loss: 2.4389e-0404
Epoch 3/50012734692641152082 0.009480217445115952 0.0112848095425452794 - val_loss: 2.4389e-0404
Epoch 14/5012734692641152082 0.009480217445115952 0.0112848095425452794 - val_loss: 2.4389e-0404
Epoch 20/5012734692641152082 0.009480217445115952 0.0112848095425452794 - val_loss: 2.4389e-0404
Epoch 26/5012734692641152082 0.009480217445115952 0.0112848095425452794 - val_loss: 2.4389e-0404
Epoch 26/5012734692641152082 0.009480217445115952 0.0112848095425452794 - val_loss: 2.4389e-0404
Epoch 32/5012734692641152082 0.009480217445115952 0.0112848095425452794 - val_loss: 2.4389e-0404
  1/233 [..............................] - ETA: 0s - loss: 1.6819e-0494 - val_loss: 2.4389e-0404
233/233 [==============================] - 1s 3ms/step - loss: 1.2740e-04 - val_loss: 0.00110404
Epoch 8/50=============================] - 1s 3ms/step - loss: 1.2740e-04 - val_loss: 0.00110404
Epoch 11/50============================] - 1s 3ms/step - loss: 1.2740e-04 - val_loss: 0.00110404
Epoch 14/50============================] - 1s 3ms/step - loss: 1.2740e-04 - val_loss: 0.00110404
Epoch 14/50============================] - 1s 3ms/step - loss: 1.2740e-04 - val_loss: 0.00110404
FI : 0.0001233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 3/501233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 6/501233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 10/50233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 13/50233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 17/50233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 21/50233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 21/50233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 25/50233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 25/50233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 4/500233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 6/500233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 9/500233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 11/50233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 11/50233967446094871 0.007636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Data for TMO saved successfully.636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 3/50MO saved successfully.636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 5/50MO saved successfully.636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 8/50MO saved successfully.636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 10/50O saved successfully.636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 13/50O saved successfully.636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
Epoch 13/50O saved successfully.636204635522216 0.0111084087343546740e-04 - val_loss: 0.00110404
66/66 [==============================] - 0s 814us/step084087343546740e-04 - val_loss: 0.00110404
101/165 [=================>............] - ETA: 0s - loss: 0.00226740e-04 - val_loss: 0.00110404
Epoch 4/50================>............] - ETA: 0s - loss: 0.00226740e-04 - val_loss: 0.00110404
Epoch 8/50================>............] - ETA: 0s - loss: 0.00226740e-04 - val_loss: 0.00110404
Epoch 13/50===============>............] - ETA: 0s - loss: 0.00226740e-04 - val_loss: 0.00110404
Epoch 17/50===============>............] - ETA: 0s - loss: 0.00226740e-04 - val_loss: 0.00110404
Epoch 21/50===============>............] - ETA: 0s - loss: 0.00226740e-04 - val_loss: 0.00110404
Epoch 25/50===============>............] - ETA: 0s - loss: 0.00226740e-04 - val_loss: 0.00110404
Epoch 30/50===============>............] - ETA: 0s - loss: 0.00226740e-04 - val_loss: 0.00110404
Epoch 30/50===============>............] - ETA: 0s - loss: 0.00226740e-04 - val_loss: 0.00110404
RL : 0.00011061683624557867 0.007985290195264939 0.010517453886068560e-04 - val_loss: 0.00110404
Epoch 3/5011061683624557867 0.007985290195264939 0.010517453886068560e-04 - val_loss: 0.00110404
Epoch 6/5011061683624557867 0.007985290195264939 0.010517453886068560e-04 - val_loss: 0.00110404
Epoch 10/501061683624557867 0.007985290195264939 0.010517453886068560e-04 - val_loss: 0.00110404
Epoch 10/501061683624557867 0.007985290195264939 0.010517453886068560e-04 - val_loss: 0.00110404
47/47 [==============================] - 0s 862us/step517453886068560e-04 - val_loss: 0.00110404
Epoch 3/50===========================] - 0s 862us/step517453886068560e-04 - val_loss: 0.00110404
Epoch 6/50===========================] - 0s 862us/step517453886068560e-04 - val_loss: 0.00110404
Epoch 11/50==========================] - 0s 862us/step517453886068560e-04 - val_loss: 0.00110404
Epoch 11/50==========================] - 0s 862us/step517453886068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
CCI : 98.52720069542652 109.50865357935429 10.98145288392777386068560e-04 - val_loss: 0.00110404
MMM : 0.0003190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
MMM : 0.0003190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
Epoch 3/5003190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
Epoch 5/5003190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
Epoch 5/5003190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
Epoch 8/5003190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
Epoch 10/503190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
Epoch 12/503190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
Epoch 14/503190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
Epoch 14/503190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
Epoch 17/503190352886603722 0.014325913697852327 0.017861558965005606e-04 - val_loss: 0.00110404
57/57 [==============================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
57/57 [==============================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Data for MOS saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 3/50OS saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 5/50OS saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 10/50S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 14/50S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 14/50S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
Epoch 14/50S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 14/50S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 5/500S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 5/500S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 5/500S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 9/500S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 11/50S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 11/50S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 11/50S saved successfully.=====] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
69/69 [==============================] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
69/69 [==============================] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Data for HSY saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Data for HSY saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 4/50SY saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 7/50SY saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 10/50Y saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 13/50Y saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 15/50Y saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 18/50Y saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 20/50Y saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 22/50Y saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 25/50Y saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 28/50Y saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 30/50Y saved successfully.=====] - 0s 2ms/step17861558965005606e-04 - val_loss: 0.00110404
39/39 [==============================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
39/39 [==============================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
39/39 [==============================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 4/50===========================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 4/50===========================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 8/50===========================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 10/50==========================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 10/50==========================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 13/50==========================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 15/50==========================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
Epoch 15/50==========================] - 0s 1ms/step17861558965005606e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
DHI : 0.0004387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
Epoch 14/504387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
Epoch 14/504387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
Epoch 14/504387159596350342 0.01460203192109689 0.0209455474895032106e-04 - val_loss: 0.00110404
ED : 89.2807023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
ED : 89.2807023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
ED : 89.2807023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 4/5007023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 4/5007023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 4/5007023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 4/5007023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 9/5007023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 9/5007023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 9/5007023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 13/507023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 13/507023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 13/507023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 17/507023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 17/507023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
Epoch 17/507023364436 53.078375992215626 -36.202326344227974895032106e-04 - val_loss: 0.00110404
ES : 0.0015100366869728408 0.02561972955010071 0.03885919050846068506e-04 - val_loss: 0.00110404
ES : 0.0015100366869728408 0.02561972955010071 0.03885919050846068506e-04 - val_loss: 0.00110404
ES : 0.0015100366869728408 0.02561972955010071 0.03885919050846068506e-04 - val_loss: 0.00110404
Epoch 4/505100366869728408 0.02561972955010071 0.03885919050846068506e-04 - val_loss: 0.00110404
Epoch 4/505100366869728408 0.02561972955010071 0.03885919050846068506e-04 - val_loss: 0.00110404
Epoch 4/505100366869728408 0.02561972955010071 0.03885919050846068506e-04 - val_loss: 0.00110404
Epoch 4/505100366869728408 0.02561972955010071 0.03885919050846068506e-04 - val_loss: 0.00110404