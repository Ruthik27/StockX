{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4adfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c04333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 17:12:25,229 - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to sp500_companies.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S&P_500_companies'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# If the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the <tbody> element in the HTML where the data resides\n",
    "    table_body = soup.find('tbody')\n",
    "    \n",
    "    # Initialize a list to store your data\n",
    "    data = []\n",
    "    \n",
    "    # Find all <tr> elements\n",
    "    rows = table_body.find_all('tr')\n",
    "    for row in rows:\n",
    "        # Find all <td> elements in this row\n",
    "        cols = row.find_all('td')\n",
    "        \n",
    "        # Get the text from all the <td> elements and add to the list\n",
    "        data.append([ele.text.strip() for ele in cols])\n",
    "    \n",
    "    # Create a DataFrame from the data list\n",
    "    df = pd.DataFrame(data, columns=['Ticker', 'Company', 'Sector', 'Sub-Industry', 'Headquarters', 'Date First Added', 'CIK', 'Founded'])\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv('sp500_companies.csv', index=False)\n",
    "\n",
    "    print('Data scraped and saved to sp500_companies.csv')\n",
    "else:\n",
    "    print('Failed to retrieve the webpage. Status code:', response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c84efd1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for ticker in df['Ticker']:\n",
    "#    print(ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58a88020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Company</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Sub-Industry</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Date First Added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>0000066740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>0000091142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>0000001800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>0001551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>XYL</td>\n",
       "      <td>Xylem Inc.</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Machinery &amp; Supplies &amp; Components</td>\n",
       "      <td>White Plains, New York</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>0001524472</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>1997-10-06</td>\n",
       "      <td>0001041061</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Electronic Equipment &amp; Instruments</td>\n",
       "      <td>Lincolnshire, Illinois</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>0000877212</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Warsaw, Indiana</td>\n",
       "      <td>2001-08-07</td>\n",
       "      <td>0001136869</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Parsippany, New Jersey</td>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>0001555280</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker             Company                  Sector  \\\n",
       "0     None                None                    None   \n",
       "1      MMM                  3M             Industrials   \n",
       "2      AOS         A. O. Smith             Industrials   \n",
       "3      ABT              Abbott             Health Care   \n",
       "4     ABBV              AbbVie             Health Care   \n",
       "..     ...                 ...                     ...   \n",
       "498    XYL          Xylem Inc.             Industrials   \n",
       "499    YUM         Yum! Brands  Consumer Discretionary   \n",
       "500   ZBRA  Zebra Technologies  Information Technology   \n",
       "501    ZBH       Zimmer Biomet             Health Care   \n",
       "502    ZTS              Zoetis             Health Care   \n",
       "\n",
       "                                     Sub-Industry             Headquarters  \\\n",
       "0                                            None                     None   \n",
       "1                        Industrial Conglomerates    Saint Paul, Minnesota   \n",
       "2                               Building Products     Milwaukee, Wisconsin   \n",
       "3                           Health Care Equipment  North Chicago, Illinois   \n",
       "4                                   Biotechnology  North Chicago, Illinois   \n",
       "..                                            ...                      ...   \n",
       "498  Industrial Machinery & Supplies & Components   White Plains, New York   \n",
       "499                                   Restaurants     Louisville, Kentucky   \n",
       "500            Electronic Equipment & Instruments   Lincolnshire, Illinois   \n",
       "501                         Health Care Equipment          Warsaw, Indiana   \n",
       "502                               Pharmaceuticals   Parsippany, New Jersey   \n",
       "\n",
       "    Date First Added         CIK      Founded  \n",
       "0               None        None         None  \n",
       "1         1957-03-04  0000066740         1902  \n",
       "2         2017-07-26  0000091142         1916  \n",
       "3         1957-03-04  0000001800         1888  \n",
       "4         2012-12-31  0001551152  2013 (1888)  \n",
       "..               ...         ...          ...  \n",
       "498       2011-11-01  0001524472         2011  \n",
       "499       1997-10-06  0001041061         1997  \n",
       "500       2019-12-23  0000877212         1969  \n",
       "501       2001-08-07  0001136869         1927  \n",
       "502       2013-06-21  0001555280         1952  \n",
       "\n",
       "[503 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91be5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_tickers = ['MMM','AOS','ABT','ABBV','ACN','ADM','ADBE','ADP','AES','AFL','A','ABNB','APD','AKAM','ALK','ALB','ARE','ALGN','ALLE','LNT','ALL','GOOGL','GOOG','MO','AMZN','AMCR','AMD','AEE','AAL','AEP','AXP','AIG','AMT','AWK','AMP','AME','AMGN','APH','ADI','ANSS','AON','APA','AAPL','AMAT','APTV','ACGL','ANET','AJG','AIZ','T','ATO','ADSK','AZO','AVB','AVY','AXON','BKR','BALL','BAC','BBWI','BAX','BDX','WRB','BRK.B','BBY','BIO','TECH','BIIB','BLK','BX','BK','BA','BKNG','BWA','BXP','BSX','BMY','AVGO','BR','BRO','BF.B','BG','CHRW','CDNS','CZR','CPT','CPB','COF','CAH','KMX','CCL','CARR','CTLT','CAT','CBOE','CBRE','CDW','CE','COR','CNC','CNP','CDAY','CF','CRL','SCHW','CHTR','CVX','CMG','CB','CHD','CI','CINF','CTAS','CSCO','C','CFG','CLX','CME','CMS','KO','CTSH','CL','CMCSA','CMA','CAG','COP','ED','STZ','CEG','COO','CPRT','GLW','CTVA','CSGP','COST','CTRA','CCI','CSX','CMI','CVS','DHI','DHR','DRI','DVA','DE','DAL','XRAY','DVN','DXCM','FANG','DLR','DFS','DIS','DG','DLTR','D','DPZ','DOV','DOW','DTE','DUK','DD','EMN','ETN','EBAY','ECL','EIX','EW','EA','ELV','LLY','EMR','ENPH','ETR','EOG','EPAM','EQT','EFX','EQIX','EQR','ESS','EL','ETSY','EG','EVRG','ES','EXC','EXPE','EXPD','EXR','XOM','FFIV','FDS','FICO','FAST','FRT','FDX','FITB','FSLR','FE','FIS','FI','FLT','FMC','F','FTNT','FTV','FOXA','FOX','BEN','FCX','GRMN','IT','GEHC','GEN','GNRC','GD','GE','GIS','GM','GPC','GILD','GL','GPN','GS','HAL','HIG','HAS','HCA','PEAK','HSIC','HSY','HES','HPE','HLT','HOLX','HD','HON','HRL','HST','HWM','HPQ','HUBB','HUM','HBAN','HII','IBM','IEX','IDXX','ITW','ILMN','INCY','IR','PODD','INTC','ICE','IFF','IP','IPG','INTU','ISRG','IVZ','INVH','IQV','IRM','JBHT','JKHY','J','JNJ','JCI','JPM','JNPR','K','KVUE','KDP','KEY','KEYS','KMB','KIM','KMI','KLAC','KHC','KR','LHX','LH','LRCX','LW','LVS','LDOS','LEN','LIN','LYV','LKQ','LMT','L','LOW','LULU','LYB','MTB','MRO','MPC','MKTX','MAR','MMC','MLM','MAS','MA','MTCH','MKC','MCD','MCK','MDT','MRK','META','MET','MTD','MGM','MCHP','MU','MSFT','MAA','MRNA','MHK','MOH','TAP','MDLZ','MPWR','MNST','MCO','MS','MOS','MSI','MSCI','NDAQ','NTAP','NFLX','NEM','NWSA','NWS','NEE','NKE','NI','NDSN','NSC','NTRS','NOC','NCLH','NRG','NUE','NVDA','NVR','NXPI','ORLY','OXY','ODFL','OMC','ON','OKE','ORCL','OTIS','PCAR','PKG','PANW','PARA','PH','PAYX','PAYC','PYPL','PNR','PEP','PFE','PCG','PM','PSX','PNW','PXD','PNC','POOL','PPG','PPL','PFG','PG','PGR','PLD','PRU','PEG','PTC','PSA','PHM','QRVO','PWR','QCOM','DGX','RL','RJF','RTX','O','REG','REGN','RF','RSG','RMD','RVTY','RHI','ROK','ROL','ROP','ROST','RCL','SPGI','CRM','SBAC','SLB','STX','SEE','SRE','NOW','SHW','SPG','SWKS','SJM','SNA','SEDG','SO','LUV','SWK','SBUX','STT','STLD','STE','SYK','SYF','SNPS','SYY','TMUS','TROW','TTWO','TPR','TRGP','TGT','TEL','TDY','TFX','TER','TSLA','TXN','TXT','TMO','TJX','TSCO','TT','TDG','TRV','TRMB','TFC','TYL','TSN','USB','UDR','ULTA','UNP','UAL','UPS','URI','UNH','UHS','VLO','VTR','VLTO','VRSN','VRSK','VZ','VRTX','VFC','VTRS','VICI','V','VMC','WAB','WBA','WMT','WBD','WM','WAT','WEC','WFC','WELL','WST','WDC','WRK','WY','WHR','WMB','WTW','GWW','WYNN','XEL','XYL','YUM','ZBRA','ZBH','ZION','ZT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8923544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp500_tickers = ['UAL','UPS','URI','UNH','UHS','VLO','VTR','VLTO','VRSN','VRSK','VZ','VRTX','VFC','VTRS','VICI','V','VMC','WAB','WBA','WMT','WBD','WM','WAT','WEC','WFC','WELL','WST','WDC','WRK','WY','WHR','WMB','WTW','GWW','WYNN','XEL','XYL','YUM','ZBRA','ZBH','ZION','ZT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a1e51b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (4.20.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from selenium) (0.10.4)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/ruthikkale/anaconda3/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c1e0335",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 15:48:02,347 - INFO - Data for  is outdated or missing. Downloading the latest data.\n",
      "2024-05-12 15:48:02,503 - ERROR - An error occurred while processing : HTTP Error 404: Not Found\n",
      "2024-05-12 15:48:02,507 - INFO - Data for MMM is up-to-date. No download needed.\n",
      "2024-05-12 15:48:04,510 - INFO - Data for AOS is up-to-date. No download needed.\n",
      "2024-05-12 15:48:06,513 - INFO - Data for ABT is up-to-date. No download needed.\n",
      "2024-05-12 15:48:08,520 - INFO - Data for ABBV is up-to-date. No download needed.\n",
      "2024-05-12 15:48:10,527 - INFO - Data for ACN is up-to-date. No download needed.\n",
      "2024-05-12 15:48:12,531 - INFO - Data for ADBE is up-to-date. No download needed.\n",
      "2024-05-12 15:48:14,537 - INFO - Data for AMD is up-to-date. No download needed.\n",
      "2024-05-12 15:48:16,544 - INFO - Data for AES is up-to-date. No download needed.\n",
      "2024-05-12 15:48:18,550 - INFO - Data for AFL is up-to-date. No download needed.\n",
      "2024-05-12 15:48:20,552 - INFO - Data for A is up-to-date. No download needed.\n",
      "2024-05-12 15:48:22,560 - INFO - Data for APD is up-to-date. No download needed.\n",
      "2024-05-12 15:48:24,564 - INFO - Data for ABNB is up-to-date. No download needed.\n",
      "2024-05-12 15:48:26,571 - INFO - Data for AKAM is up-to-date. No download needed.\n",
      "2024-05-12 15:48:28,577 - INFO - Data for ALB is up-to-date. No download needed.\n",
      "2024-05-12 15:48:30,583 - INFO - Data for ARE is up-to-date. No download needed.\n",
      "2024-05-12 15:48:32,589 - INFO - Data for ALGN is up-to-date. No download needed.\n",
      "2024-05-12 15:48:34,595 - INFO - Data for ALLE is up-to-date. No download needed.\n",
      "2024-05-12 15:48:36,604 - INFO - Data for LNT is up-to-date. No download needed.\n",
      "2024-05-12 15:48:38,611 - INFO - Data for ALL is up-to-date. No download needed.\n",
      "2024-05-12 15:48:40,618 - INFO - Data for GOOGL is up-to-date. No download needed.\n",
      "2024-05-12 15:48:42,621 - INFO - Data for GOOG is up-to-date. No download needed.\n",
      "2024-05-12 15:48:44,629 - INFO - Data for MO is up-to-date. No download needed.\n",
      "2024-05-12 15:48:46,633 - INFO - Data for AMZN is up-to-date. No download needed.\n",
      "2024-05-12 15:48:48,639 - INFO - Data for AMCR is up-to-date. No download needed.\n",
      "2024-05-12 15:48:50,646 - INFO - Data for AEE is up-to-date. No download needed.\n",
      "2024-05-12 15:48:52,653 - INFO - Data for AAL is up-to-date. No download needed.\n",
      "2024-05-12 15:48:54,658 - INFO - Data for AEP is up-to-date. No download needed.\n",
      "2024-05-12 15:48:56,666 - INFO - Data for AXP is up-to-date. No download needed.\n",
      "2024-05-12 15:48:58,669 - INFO - Data for AIG is up-to-date. No download needed.\n",
      "2024-05-12 15:49:00,671 - INFO - Data for AMT is up-to-date. No download needed.\n",
      "2024-05-12 15:49:02,678 - INFO - Data for AWK is up-to-date. No download needed.\n",
      "2024-05-12 15:49:04,685 - INFO - Data for AMP is up-to-date. No download needed.\n",
      "2024-05-12 15:49:06,689 - INFO - Data for AME is up-to-date. No download needed.\n",
      "2024-05-12 15:49:08,695 - INFO - Data for AMGN is up-to-date. No download needed.\n",
      "2024-05-12 15:49:10,701 - INFO - Data for APH is up-to-date. No download needed.\n",
      "2024-05-12 15:49:12,705 - INFO - Data for ADI is up-to-date. No download needed.\n",
      "2024-05-12 15:49:14,711 - INFO - Data for ANSS is up-to-date. No download needed.\n",
      "2024-05-12 15:49:16,718 - INFO - Data for AON is up-to-date. No download needed.\n",
      "2024-05-12 15:49:18,724 - INFO - Data for APA is up-to-date. No download needed.\n",
      "2024-05-12 15:49:20,729 - INFO - Data for AAPL is up-to-date. No download needed.\n",
      "2024-05-12 15:49:22,737 - INFO - Data for AMAT is up-to-date. No download needed.\n",
      "2024-05-12 15:49:24,744 - INFO - Data for APTV is up-to-date. No download needed.\n",
      "2024-05-12 15:49:26,747 - INFO - Data for ACGL is up-to-date. No download needed.\n",
      "2024-05-12 15:49:28,754 - INFO - Data for ADM is up-to-date. No download needed.\n",
      "2024-05-12 15:49:30,761 - INFO - Data for ANET is up-to-date. No download needed.\n",
      "2024-05-12 15:49:32,764 - INFO - Data for AJG is up-to-date. No download needed.\n",
      "2024-05-12 15:49:34,766 - INFO - Data for AIZ is up-to-date. No download needed.\n",
      "2024-05-12 15:49:36,771 - INFO - Data for T is up-to-date. No download needed.\n",
      "2024-05-12 15:49:38,778 - INFO - Data for ATO is up-to-date. No download needed.\n",
      "2024-05-12 15:49:40,781 - INFO - Data for ADSK is up-to-date. No download needed.\n",
      "2024-05-12 15:49:42,786 - INFO - Data for ADP is up-to-date. No download needed.\n",
      "2024-05-12 15:49:44,789 - INFO - Data for AZO is up-to-date. No download needed.\n",
      "2024-05-12 15:49:46,795 - INFO - Data for AVB is up-to-date. No download needed.\n",
      "2024-05-12 15:49:48,802 - INFO - Data for AVY is up-to-date. No download needed.\n",
      "2024-05-12 15:49:50,808 - INFO - Data for AXON is up-to-date. No download needed.\n",
      "2024-05-12 15:49:52,812 - INFO - Data for BKR is up-to-date. No download needed.\n",
      "2024-05-12 15:49:54,816 - INFO - Data for BALL is up-to-date. No download needed.\n",
      "2024-05-12 15:49:56,820 - INFO - Data for BAC is up-to-date. No download needed.\n",
      "2024-05-12 15:49:58,824 - INFO - Data for BK is up-to-date. No download needed.\n",
      "2024-05-12 15:50:00,828 - INFO - Data for BBWI is up-to-date. No download needed.\n",
      "2024-05-12 15:50:02,833 - INFO - Data for BAX is up-to-date. No download needed.\n",
      "2024-05-12 15:50:04,837 - INFO - Data for BDX is up-to-date. No download needed.\n",
      "2024-05-12 15:50:06,844 - INFO - Data for BRK.B is outdated or missing. Downloading the latest data.\n",
      "2024-05-12 15:50:07,024 - ERROR - An error occurred while processing BRK.B: HTTP Error 404: Not Found\n",
      "2024-05-12 15:50:07,029 - INFO - Data for BBY is up-to-date. No download needed.\n",
      "2024-05-12 15:50:09,036 - INFO - Data for BIO is up-to-date. No download needed.\n",
      "2024-05-12 15:50:11,042 - INFO - Data for TECH is up-to-date. No download needed.\n",
      "2024-05-12 15:50:13,046 - INFO - Data for BIIB is up-to-date. No download needed.\n",
      "2024-05-12 15:50:15,049 - INFO - Data for BLK is up-to-date. No download needed.\n",
      "2024-05-12 15:50:17,057 - INFO - Data for BX is up-to-date. No download needed.\n",
      "2024-05-12 15:50:19,064 - INFO - Data for BA is up-to-date. No download needed.\n",
      "2024-05-12 15:50:21,070 - INFO - Data for BKNG is up-to-date. No download needed.\n",
      "2024-05-12 15:50:23,074 - INFO - Data for BWA is up-to-date. No download needed.\n",
      "2024-05-12 15:50:25,080 - INFO - Data for BXP is up-to-date. No download needed.\n",
      "2024-05-12 15:50:27,082 - INFO - Data for BSX is up-to-date. No download needed.\n",
      "2024-05-12 15:50:29,086 - INFO - Data for BMY is up-to-date. No download needed.\n",
      "2024-05-12 15:50:31,093 - INFO - Data for AVGO is up-to-date. No download needed.\n",
      "2024-05-12 15:50:33,099 - INFO - Data for BR is up-to-date. No download needed.\n",
      "2024-05-12 15:50:35,103 - INFO - Data for BRO is up-to-date. No download needed.\n",
      "2024-05-12 15:50:37,110 - INFO - Data for BF.B is outdated or missing. Downloading the latest data.\n",
      "2024-05-12 15:50:37,231 - ERROR - An error occurred while processing BF.B: HTTP Error 404: Not Found\n",
      "2024-05-12 15:50:37,234 - INFO - Data for BLDR is up-to-date. No download needed.\n",
      "2024-05-12 15:50:39,241 - INFO - Data for BG is up-to-date. No download needed.\n",
      "2024-05-12 15:50:41,248 - INFO - Data for CDNS is up-to-date. No download needed.\n",
      "2024-05-12 15:50:43,253 - INFO - Data for CZR is up-to-date. No download needed.\n",
      "2024-05-12 15:50:45,257 - INFO - Data for CPT is up-to-date. No download needed.\n",
      "2024-05-12 15:50:47,264 - INFO - Data for CPB is up-to-date. No download needed.\n",
      "2024-05-12 15:50:49,269 - INFO - Data for COF is up-to-date. No download needed.\n",
      "2024-05-12 15:50:51,275 - INFO - Data for CAH is up-to-date. No download needed.\n",
      "2024-05-12 15:50:53,282 - INFO - Data for KMX is up-to-date. No download needed.\n",
      "2024-05-12 15:50:55,289 - INFO - Data for CCL is up-to-date. No download needed.\n",
      "2024-05-12 15:50:57,296 - INFO - Data for CARR is up-to-date. No download needed.\n",
      "2024-05-12 15:50:59,298 - INFO - Data for CTLT is up-to-date. No download needed.\n",
      "2024-05-12 15:51:01,303 - INFO - Data for CAT is up-to-date. No download needed.\n",
      "2024-05-12 15:51:03,305 - INFO - Data for CBOE is up-to-date. No download needed.\n",
      "2024-05-12 15:51:05,312 - INFO - Data for CBRE is up-to-date. No download needed.\n",
      "2024-05-12 15:51:07,317 - INFO - Data for CDW is up-to-date. No download needed.\n",
      "2024-05-12 15:51:09,320 - INFO - Data for CE is up-to-date. No download needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 15:51:11,325 - INFO - Data for COR is up-to-date. No download needed.\n",
      "2024-05-12 15:51:13,330 - INFO - Data for CNC is up-to-date. No download needed.\n",
      "2024-05-12 15:51:15,335 - INFO - Data for CNP is up-to-date. No download needed.\n",
      "2024-05-12 15:51:17,342 - INFO - Data for CF is up-to-date. No download needed.\n",
      "2024-05-12 15:51:19,348 - INFO - Data for CHRW is up-to-date. No download needed.\n",
      "2024-05-12 15:51:21,355 - INFO - Data for CRL is up-to-date. No download needed.\n",
      "2024-05-12 15:51:23,358 - INFO - Data for SCHW is up-to-date. No download needed.\n",
      "2024-05-12 15:51:25,365 - INFO - Data for CHTR is up-to-date. No download needed.\n",
      "2024-05-12 15:51:27,370 - INFO - Data for CVX is up-to-date. No download needed.\n",
      "2024-05-12 15:51:29,374 - INFO - Data for CMG is up-to-date. No download needed.\n",
      "2024-05-12 15:51:31,377 - INFO - Data for CB is up-to-date. No download needed.\n",
      "2024-05-12 15:51:33,386 - INFO - Data for CHD is up-to-date. No download needed.\n",
      "2024-05-12 15:51:35,394 - INFO - Data for CI is up-to-date. No download needed.\n",
      "2024-05-12 15:51:37,400 - INFO - Data for CINF is up-to-date. No download needed.\n",
      "2024-05-12 15:51:39,401 - INFO - Data for CTAS is up-to-date. No download needed.\n",
      "2024-05-12 15:51:41,408 - INFO - Data for CSCO is up-to-date. No download needed.\n",
      "2024-05-12 15:51:43,413 - INFO - Data for C is up-to-date. No download needed.\n",
      "2024-05-12 15:51:45,419 - INFO - Data for CFG is up-to-date. No download needed.\n",
      "2024-05-12 15:51:47,421 - INFO - Data for CLX is up-to-date. No download needed.\n",
      "2024-05-12 15:51:49,424 - INFO - Data for CME is up-to-date. No download needed.\n",
      "2024-05-12 15:51:51,431 - INFO - Data for CMS is up-to-date. No download needed.\n",
      "2024-05-12 15:51:53,435 - INFO - Data for KO is up-to-date. No download needed.\n",
      "2024-05-12 15:51:55,442 - INFO - Data for CTSH is up-to-date. No download needed.\n",
      "2024-05-12 15:51:57,445 - INFO - Data for CL is up-to-date. No download needed.\n",
      "2024-05-12 15:51:59,448 - INFO - Data for CMCSA is up-to-date. No download needed.\n",
      "2024-05-12 15:52:01,451 - INFO - Data for CMA is up-to-date. No download needed.\n",
      "2024-05-12 15:52:03,457 - INFO - Data for CAG is up-to-date. No download needed.\n",
      "2024-05-12 15:52:05,460 - INFO - Data for COP is up-to-date. No download needed.\n",
      "2024-05-12 15:52:07,466 - INFO - Data for ED is up-to-date. No download needed.\n",
      "2024-05-12 15:52:09,472 - INFO - Data for STZ is up-to-date. No download needed.\n",
      "2024-05-12 15:52:11,478 - INFO - Data for CEG is up-to-date. No download needed.\n",
      "2024-05-12 15:52:13,484 - INFO - Data for COO is up-to-date. No download needed.\n",
      "2024-05-12 15:52:15,487 - INFO - Data for CPRT is up-to-date. No download needed.\n",
      "2024-05-12 15:52:17,490 - INFO - Data for GLW is up-to-date. No download needed.\n",
      "2024-05-12 15:52:19,497 - INFO - Data for CPAY is up-to-date. No download needed.\n",
      "2024-05-12 15:52:21,500 - INFO - Data for CTVA is up-to-date. No download needed.\n",
      "2024-05-12 15:52:23,508 - INFO - Data for CSGP is up-to-date. No download needed.\n",
      "2024-05-12 15:52:25,513 - INFO - Data for COST is up-to-date. No download needed.\n",
      "2024-05-12 15:52:27,519 - INFO - Data for CTRA is up-to-date. No download needed.\n",
      "2024-05-12 15:52:29,524 - INFO - Data for CCI is up-to-date. No download needed.\n",
      "2024-05-12 15:52:31,526 - INFO - Data for CSX is up-to-date. No download needed.\n",
      "2024-05-12 15:52:33,532 - INFO - Data for CMI is up-to-date. No download needed.\n",
      "2024-05-12 15:52:35,535 - INFO - Data for CVS is up-to-date. No download needed.\n",
      "2024-05-12 15:52:37,540 - INFO - Data for DHR is up-to-date. No download needed.\n",
      "2024-05-12 15:52:39,547 - INFO - Data for DRI is up-to-date. No download needed.\n",
      "2024-05-12 15:52:41,551 - INFO - Data for DVA is up-to-date. No download needed.\n",
      "2024-05-12 15:52:43,553 - INFO - Data for DAY is up-to-date. No download needed.\n",
      "2024-05-12 15:52:45,560 - INFO - Data for DECK is up-to-date. No download needed.\n",
      "2024-05-12 15:52:47,566 - INFO - Data for DE is up-to-date. No download needed.\n",
      "2024-05-12 15:52:49,571 - INFO - Data for DAL is up-to-date. No download needed.\n",
      "2024-05-12 15:52:51,578 - INFO - Data for DVN is up-to-date. No download needed.\n",
      "2024-05-12 15:52:53,583 - INFO - Data for DXCM is up-to-date. No download needed.\n",
      "2024-05-12 15:52:55,587 - INFO - Data for FANG is up-to-date. No download needed.\n",
      "2024-05-12 15:52:57,590 - INFO - Data for DLR is up-to-date. No download needed.\n",
      "2024-05-12 15:52:59,592 - INFO - Data for DFS is up-to-date. No download needed.\n",
      "2024-05-12 15:53:01,595 - INFO - Data for DG is up-to-date. No download needed.\n",
      "2024-05-12 15:53:03,601 - INFO - Data for DLTR is up-to-date. No download needed.\n",
      "2024-05-12 15:53:05,614 - INFO - Data for D is up-to-date. No download needed.\n",
      "2024-05-12 15:53:07,624 - INFO - Data for DPZ is up-to-date. No download needed.\n",
      "2024-05-12 15:53:09,634 - INFO - Data for DOV is up-to-date. No download needed.\n",
      "2024-05-12 15:53:11,643 - INFO - Data for DOW is up-to-date. No download needed.\n",
      "2024-05-12 15:53:13,652 - INFO - Data for DHI is up-to-date. No download needed.\n",
      "2024-05-12 15:53:15,658 - INFO - Data for DTE is up-to-date. No download needed.\n",
      "2024-05-12 15:53:17,665 - INFO - Data for DUK is up-to-date. No download needed.\n",
      "2024-05-12 15:53:19,668 - INFO - Data for DD is up-to-date. No download needed.\n",
      "2024-05-12 15:53:21,670 - INFO - Data for EMN is up-to-date. No download needed.\n",
      "2024-05-12 15:53:23,676 - INFO - Data for ETN is up-to-date. No download needed.\n",
      "2024-05-12 15:53:25,679 - INFO - Data for EBAY is up-to-date. No download needed.\n",
      "2024-05-12 15:53:27,685 - INFO - Data for ECL is up-to-date. No download needed.\n",
      "2024-05-12 15:53:29,689 - INFO - Data for EIX is up-to-date. No download needed.\n",
      "2024-05-12 15:53:31,693 - INFO - Data for EW is up-to-date. No download needed.\n",
      "2024-05-12 15:53:33,700 - INFO - Data for EA is up-to-date. No download needed.\n",
      "2024-05-12 15:53:35,706 - INFO - Data for ELV is up-to-date. No download needed.\n",
      "2024-05-12 15:53:37,710 - INFO - Data for LLY is up-to-date. No download needed.\n",
      "2024-05-12 15:53:39,713 - INFO - Data for EMR is up-to-date. No download needed.\n",
      "2024-05-12 15:53:41,730 - INFO - Data for ENPH is up-to-date. No download needed.\n",
      "2024-05-12 15:53:43,732 - INFO - Data for ETR is up-to-date. No download needed.\n",
      "2024-05-12 15:53:45,736 - INFO - Data for EOG is up-to-date. No download needed.\n",
      "2024-05-12 15:53:47,744 - INFO - Data for EPAM is up-to-date. No download needed.\n",
      "2024-05-12 15:53:49,752 - INFO - Data for EQT is up-to-date. No download needed.\n",
      "2024-05-12 15:53:51,754 - INFO - Data for EFX is up-to-date. No download needed.\n",
      "2024-05-12 15:53:53,761 - INFO - Data for EQIX is up-to-date. No download needed.\n",
      "2024-05-12 15:53:55,764 - INFO - Data for EQR is up-to-date. No download needed.\n",
      "2024-05-12 15:53:57,769 - INFO - Data for ESS is up-to-date. No download needed.\n",
      "2024-05-12 15:53:59,772 - INFO - Data for EL is up-to-date. No download needed.\n",
      "2024-05-12 15:54:01,779 - INFO - Data for ETSY is up-to-date. No download needed.\n",
      "2024-05-12 15:54:03,786 - INFO - Data for EG is up-to-date. No download needed.\n",
      "2024-05-12 15:54:05,793 - INFO - Data for EVRG is up-to-date. No download needed.\n",
      "2024-05-12 15:54:07,798 - INFO - Data for ES is up-to-date. No download needed.\n",
      "2024-05-12 15:54:09,805 - INFO - Data for EXC is up-to-date. No download needed.\n",
      "2024-05-12 15:54:11,812 - INFO - Data for EXPE is up-to-date. No download needed.\n",
      "2024-05-12 15:54:13,815 - INFO - Data for EXPD is up-to-date. No download needed.\n",
      "2024-05-12 15:54:15,817 - INFO - Data for EXR is up-to-date. No download needed.\n",
      "2024-05-12 15:54:17,825 - INFO - Data for XOM is up-to-date. No download needed.\n",
      "2024-05-12 15:54:19,830 - INFO - Data for FFIV is up-to-date. No download needed.\n",
      "2024-05-12 15:54:21,835 - INFO - Data for FDS is up-to-date. No download needed.\n",
      "2024-05-12 15:54:23,842 - INFO - Data for FICO is up-to-date. No download needed.\n",
      "2024-05-12 15:54:25,844 - INFO - Data for FAST is up-to-date. No download needed.\n",
      "2024-05-12 15:54:27,849 - INFO - Data for FRT is up-to-date. No download needed.\n",
      "2024-05-12 15:54:29,854 - INFO - Data for FDX is up-to-date. No download needed.\n",
      "2024-05-12 15:54:31,859 - INFO - Data for FIS is up-to-date. No download needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 15:54:33,862 - INFO - Data for FITB is up-to-date. No download needed.\n",
      "2024-05-12 15:54:35,867 - INFO - Data for FSLR is up-to-date. No download needed.\n",
      "2024-05-12 15:54:37,868 - INFO - Data for FE is up-to-date. No download needed.\n",
      "2024-05-12 15:54:39,871 - INFO - Data for FI is up-to-date. No download needed.\n",
      "2024-05-12 15:54:41,873 - INFO - Data for FMC is up-to-date. No download needed.\n",
      "2024-05-12 15:54:43,879 - INFO - Data for F is up-to-date. No download needed.\n",
      "2024-05-12 15:54:45,883 - INFO - Data for FTNT is up-to-date. No download needed.\n",
      "2024-05-12 15:54:47,889 - INFO - Data for FTV is up-to-date. No download needed.\n",
      "2024-05-12 15:54:49,893 - INFO - Data for FOXA is up-to-date. No download needed.\n",
      "2024-05-12 15:54:51,896 - INFO - Data for FOX is up-to-date. No download needed.\n",
      "2024-05-12 15:54:53,899 - INFO - Data for BEN is up-to-date. No download needed.\n",
      "2024-05-12 15:54:55,905 - INFO - Data for FCX is up-to-date. No download needed.\n",
      "2024-05-12 15:54:57,911 - INFO - Data for GRMN is up-to-date. No download needed.\n",
      "2024-05-12 15:54:59,918 - INFO - Data for IT is up-to-date. No download needed.\n",
      "2024-05-12 15:55:01,924 - INFO - Data for GE is up-to-date. No download needed.\n",
      "2024-05-12 15:55:03,927 - INFO - Data for GEHC is up-to-date. No download needed.\n",
      "2024-05-12 15:55:05,934 - INFO - Data for GEV is outdated or missing. Downloading the latest data.\n",
      "2024-05-12 15:55:06,083 - ERROR - An error occurred while processing GEV: HTTP Error 400: Bad Request\n",
      "2024-05-12 15:55:06,089 - INFO - Data for GEN is up-to-date. No download needed.\n",
      "2024-05-12 15:55:08,095 - INFO - Data for GNRC is up-to-date. No download needed.\n",
      "2024-05-12 15:55:10,102 - INFO - Data for GD is up-to-date. No download needed.\n",
      "2024-05-12 15:55:12,107 - INFO - Data for GIS is up-to-date. No download needed.\n",
      "2024-05-12 15:55:14,112 - INFO - Data for GM is up-to-date. No download needed.\n",
      "2024-05-12 15:55:16,119 - INFO - Data for GPC is up-to-date. No download needed.\n",
      "2024-05-12 15:55:18,124 - INFO - Data for GILD is up-to-date. No download needed.\n",
      "2024-05-12 15:55:20,128 - INFO - Data for GPN is up-to-date. No download needed.\n",
      "2024-05-12 15:55:22,131 - INFO - Data for GL is up-to-date. No download needed.\n",
      "2024-05-12 15:55:24,132 - INFO - Data for GS is up-to-date. No download needed.\n",
      "2024-05-12 15:55:26,135 - INFO - Data for HAL is up-to-date. No download needed.\n",
      "2024-05-12 15:55:28,137 - INFO - Data for HIG is up-to-date. No download needed.\n",
      "2024-05-12 15:55:30,144 - INFO - Data for HAS is up-to-date. No download needed.\n",
      "2024-05-12 15:55:32,150 - INFO - Data for HCA is up-to-date. No download needed.\n",
      "2024-05-12 15:55:34,155 - INFO - Data for DOC is up-to-date. No download needed.\n",
      "2024-05-12 15:55:36,160 - INFO - Data for HSIC is up-to-date. No download needed.\n",
      "2024-05-12 15:55:38,166 - INFO - Data for HSY is up-to-date. No download needed.\n",
      "2024-05-12 15:55:40,170 - INFO - Data for HES is up-to-date. No download needed.\n",
      "2024-05-12 15:55:42,177 - INFO - Data for HPE is up-to-date. No download needed.\n",
      "2024-05-12 15:55:44,183 - INFO - Data for HLT is up-to-date. No download needed.\n",
      "2024-05-12 15:55:46,185 - INFO - Data for HOLX is up-to-date. No download needed.\n",
      "2024-05-12 15:55:48,192 - INFO - Data for HD is up-to-date. No download needed.\n",
      "2024-05-12 15:55:50,195 - INFO - Data for HON is up-to-date. No download needed.\n",
      "2024-05-12 15:55:52,200 - INFO - Data for HRL is up-to-date. No download needed.\n",
      "2024-05-12 15:55:54,206 - INFO - Data for HST is up-to-date. No download needed.\n",
      "2024-05-12 15:55:56,212 - INFO - Data for HWM is up-to-date. No download needed.\n",
      "2024-05-12 15:55:58,219 - INFO - Data for HPQ is up-to-date. No download needed.\n",
      "2024-05-12 15:56:00,226 - INFO - Data for HUBB is up-to-date. No download needed.\n",
      "2024-05-12 15:56:02,232 - INFO - Data for HUM is up-to-date. No download needed.\n",
      "2024-05-12 15:56:04,238 - INFO - Data for HBAN is up-to-date. No download needed.\n",
      "2024-05-12 15:56:06,242 - INFO - Data for HII is up-to-date. No download needed.\n",
      "2024-05-12 15:56:08,245 - INFO - Data for IBM is up-to-date. No download needed.\n",
      "2024-05-12 15:56:10,251 - INFO - Data for IEX is up-to-date. No download needed.\n",
      "2024-05-12 15:56:12,257 - INFO - Data for IDXX is up-to-date. No download needed.\n",
      "2024-05-12 15:56:14,264 - INFO - Data for ITW is up-to-date. No download needed.\n",
      "2024-05-12 15:56:16,271 - INFO - Data for ILMN is up-to-date. No download needed.\n",
      "2024-05-12 15:56:18,274 - INFO - Data for INCY is up-to-date. No download needed.\n",
      "2024-05-12 15:56:20,277 - INFO - Data for IR is up-to-date. No download needed.\n",
      "2024-05-12 15:56:22,284 - INFO - Data for PODD is up-to-date. No download needed.\n",
      "2024-05-12 15:56:24,291 - INFO - Data for INTC is up-to-date. No download needed.\n",
      "2024-05-12 15:56:26,294 - INFO - Data for ICE is up-to-date. No download needed.\n",
      "2024-05-12 15:56:28,300 - INFO - Data for IFF is up-to-date. No download needed.\n",
      "2024-05-12 15:56:30,303 - INFO - Data for IP is up-to-date. No download needed.\n",
      "2024-05-12 15:56:32,307 - INFO - Data for IPG is up-to-date. No download needed.\n",
      "2024-05-12 15:56:34,314 - INFO - Data for INTU is up-to-date. No download needed.\n",
      "2024-05-12 15:56:36,316 - INFO - Data for ISRG is up-to-date. No download needed.\n",
      "2024-05-12 15:56:38,324 - INFO - Data for IVZ is up-to-date. No download needed.\n",
      "2024-05-12 15:56:40,329 - INFO - Data for INVH is up-to-date. No download needed.\n",
      "2024-05-12 15:56:42,333 - INFO - Data for IQV is up-to-date. No download needed.\n",
      "2024-05-12 15:56:44,336 - INFO - Data for IRM is up-to-date. No download needed.\n",
      "2024-05-12 15:56:46,342 - INFO - Data for JBHT is up-to-date. No download needed.\n",
      "2024-05-12 15:56:48,346 - INFO - Data for JBL is up-to-date. No download needed.\n",
      "2024-05-12 15:56:50,353 - INFO - Data for JKHY is up-to-date. No download needed.\n",
      "2024-05-12 15:56:52,360 - INFO - Data for J is up-to-date. No download needed.\n",
      "2024-05-12 15:56:54,363 - INFO - Data for JNJ is up-to-date. No download needed.\n",
      "2024-05-12 15:56:56,370 - INFO - Data for JCI is up-to-date. No download needed.\n",
      "2024-05-12 15:56:58,374 - INFO - Data for JPM is up-to-date. No download needed.\n",
      "2024-05-12 15:57:00,377 - INFO - Data for JNPR is up-to-date. No download needed.\n",
      "2024-05-12 15:57:02,381 - INFO - Data for K is up-to-date. No download needed.\n",
      "2024-05-12 15:57:04,387 - INFO - Data for KVUE is up-to-date. No download needed.\n",
      "2024-05-12 15:57:06,389 - INFO - Data for KDP is up-to-date. No download needed.\n",
      "2024-05-12 15:57:08,393 - INFO - Data for KEY is up-to-date. No download needed.\n",
      "2024-05-12 15:57:10,399 - INFO - Data for KEYS is up-to-date. No download needed.\n",
      "2024-05-12 15:57:12,407 - INFO - Data for KMB is up-to-date. No download needed.\n",
      "2024-05-12 15:57:14,413 - INFO - Data for KIM is up-to-date. No download needed.\n",
      "2024-05-12 15:57:16,419 - INFO - Data for KMI is up-to-date. No download needed.\n",
      "2024-05-12 15:57:18,425 - INFO - Data for KLAC is up-to-date. No download needed.\n",
      "2024-05-12 15:57:20,427 - INFO - Data for KHC is up-to-date. No download needed.\n",
      "2024-05-12 15:57:22,431 - INFO - Data for KR is up-to-date. No download needed.\n",
      "2024-05-12 15:57:24,433 - INFO - Data for LHX is up-to-date. No download needed.\n",
      "2024-05-12 15:57:26,437 - INFO - Data for LH is up-to-date. No download needed.\n",
      "2024-05-12 15:57:28,439 - INFO - Data for LRCX is up-to-date. No download needed.\n",
      "2024-05-12 15:57:30,445 - INFO - Data for LW is up-to-date. No download needed.\n",
      "2024-05-12 15:57:32,452 - INFO - Data for LVS is up-to-date. No download needed.\n",
      "2024-05-12 15:57:34,455 - INFO - Data for LDOS is up-to-date. No download needed.\n",
      "2024-05-12 15:57:36,461 - INFO - Data for LEN is up-to-date. No download needed.\n",
      "2024-05-12 15:57:38,464 - INFO - Data for LIN is up-to-date. No download needed.\n",
      "2024-05-12 15:57:40,471 - INFO - Data for LYV is up-to-date. No download needed.\n",
      "2024-05-12 15:57:42,474 - INFO - Data for LKQ is up-to-date. No download needed.\n",
      "2024-05-12 15:57:44,480 - INFO - Data for LMT is up-to-date. No download needed.\n",
      "2024-05-12 15:57:46,486 - INFO - Data for L is up-to-date. No download needed.\n",
      "2024-05-12 15:57:48,492 - INFO - Data for LOW is up-to-date. No download needed.\n",
      "2024-05-12 15:57:50,498 - INFO - Data for LULU is up-to-date. No download needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 15:57:52,503 - INFO - Data for LYB is up-to-date. No download needed.\n",
      "2024-05-12 15:57:54,509 - INFO - Data for MTB is up-to-date. No download needed.\n",
      "2024-05-12 15:57:56,511 - INFO - Data for MRO is up-to-date. No download needed.\n",
      "2024-05-12 15:57:58,514 - INFO - Data for MPC is up-to-date. No download needed.\n",
      "2024-05-12 15:58:00,520 - INFO - Data for MKTX is up-to-date. No download needed.\n",
      "2024-05-12 15:58:02,526 - INFO - Data for MAR is up-to-date. No download needed.\n",
      "2024-05-12 15:58:04,533 - INFO - Data for MMC is up-to-date. No download needed.\n",
      "2024-05-12 15:58:06,538 - INFO - Data for MLM is up-to-date. No download needed.\n",
      "2024-05-12 15:58:08,544 - INFO - Data for MAS is up-to-date. No download needed.\n",
      "2024-05-12 15:58:10,546 - INFO - Data for MA is up-to-date. No download needed.\n",
      "2024-05-12 15:58:12,554 - INFO - Data for MTCH is up-to-date. No download needed.\n",
      "2024-05-12 15:58:14,562 - INFO - Data for MKC is up-to-date. No download needed.\n",
      "2024-05-12 15:58:16,568 - INFO - Data for MCD is up-to-date. No download needed.\n",
      "2024-05-12 15:58:18,573 - INFO - Data for MCK is up-to-date. No download needed.\n",
      "2024-05-12 15:58:20,579 - INFO - Data for MDT is up-to-date. No download needed.\n",
      "2024-05-12 15:58:22,589 - INFO - Data for MRK is up-to-date. No download needed.\n",
      "2024-05-12 15:58:24,591 - INFO - Data for META is up-to-date. No download needed.\n",
      "2024-05-12 15:58:26,603 - INFO - Data for MET is up-to-date. No download needed.\n",
      "2024-05-12 15:58:28,611 - INFO - Data for MTD is up-to-date. No download needed.\n",
      "2024-05-12 15:58:30,614 - INFO - Data for MGM is up-to-date. No download needed.\n",
      "2024-05-12 15:58:32,626 - INFO - Data for MCHP is up-to-date. No download needed.\n",
      "2024-05-12 15:58:34,629 - INFO - Data for MU is up-to-date. No download needed.\n",
      "2024-05-12 15:58:36,632 - INFO - Data for MSFT is up-to-date. No download needed.\n",
      "2024-05-12 15:58:38,640 - INFO - Data for MAA is up-to-date. No download needed.\n",
      "2024-05-12 15:58:40,648 - INFO - Data for MRNA is up-to-date. No download needed.\n",
      "2024-05-12 15:58:42,659 - INFO - Data for MHK is up-to-date. No download needed.\n",
      "2024-05-12 15:58:44,662 - INFO - Data for MOH is up-to-date. No download needed.\n",
      "2024-05-12 15:58:46,673 - INFO - Data for TAP is up-to-date. No download needed.\n",
      "2024-05-12 15:58:48,680 - INFO - Data for MDLZ is up-to-date. No download needed.\n",
      "2024-05-12 15:58:50,683 - INFO - Data for MPWR is up-to-date. No download needed.\n",
      "2024-05-12 15:58:52,695 - INFO - Data for MNST is up-to-date. No download needed.\n",
      "2024-05-12 15:58:54,705 - INFO - Data for MCO is up-to-date. No download needed.\n",
      "2024-05-12 15:58:56,714 - INFO - Data for MS is up-to-date. No download needed.\n",
      "2024-05-12 15:58:58,723 - INFO - Data for MOS is up-to-date. No download needed.\n",
      "2024-05-12 15:59:00,733 - INFO - Data for MSI is up-to-date. No download needed.\n",
      "2024-05-12 15:59:02,744 - INFO - Data for MSCI is up-to-date. No download needed.\n",
      "2024-05-12 15:59:04,747 - INFO - Data for NDAQ is up-to-date. No download needed.\n",
      "2024-05-12 15:59:06,757 - INFO - Data for NTAP is up-to-date. No download needed.\n",
      "2024-05-12 15:59:08,768 - INFO - Data for NFLX is up-to-date. No download needed.\n",
      "2024-05-12 15:59:10,778 - INFO - Data for NEM is up-to-date. No download needed.\n",
      "2024-05-12 15:59:12,781 - INFO - Data for NWSA is up-to-date. No download needed.\n",
      "2024-05-12 15:59:14,783 - INFO - Data for NWS is up-to-date. No download needed.\n",
      "2024-05-12 15:59:16,792 - INFO - Data for NEE is up-to-date. No download needed.\n",
      "2024-05-12 15:59:18,803 - INFO - Data for NKE is up-to-date. No download needed.\n",
      "2024-05-12 15:59:20,810 - INFO - Data for NI is up-to-date. No download needed.\n",
      "2024-05-12 15:59:22,815 - INFO - Data for NDSN is up-to-date. No download needed.\n",
      "2024-05-12 15:59:24,819 - INFO - Data for NSC is up-to-date. No download needed.\n",
      "2024-05-12 15:59:26,828 - INFO - Data for NTRS is up-to-date. No download needed.\n",
      "2024-05-12 15:59:28,839 - INFO - Data for NOC is up-to-date. No download needed.\n",
      "2024-05-12 15:59:30,842 - INFO - Data for NCLH is up-to-date. No download needed.\n",
      "2024-05-12 15:59:32,853 - INFO - Data for NRG is up-to-date. No download needed.\n",
      "2024-05-12 15:59:34,856 - INFO - Data for NUE is up-to-date. No download needed.\n",
      "2024-05-12 15:59:36,867 - INFO - Data for NVDA is up-to-date. No download needed.\n",
      "2024-05-12 15:59:38,869 - INFO - Data for NVR is up-to-date. No download needed.\n",
      "2024-05-12 15:59:40,880 - INFO - Data for NXPI is up-to-date. No download needed.\n",
      "2024-05-12 15:59:42,890 - INFO - Data for ORLY is up-to-date. No download needed.\n",
      "2024-05-12 15:59:44,897 - INFO - Data for OXY is up-to-date. No download needed.\n",
      "2024-05-12 15:59:46,910 - INFO - Data for ODFL is up-to-date. No download needed.\n",
      "2024-05-12 15:59:48,921 - INFO - Data for OMC is up-to-date. No download needed.\n",
      "2024-05-12 15:59:50,930 - INFO - Data for ON is up-to-date. No download needed.\n",
      "2024-05-12 15:59:52,941 - INFO - Data for OKE is up-to-date. No download needed.\n",
      "2024-05-12 15:59:54,947 - INFO - Data for ORCL is up-to-date. No download needed.\n",
      "2024-05-12 15:59:56,957 - INFO - Data for OTIS is up-to-date. No download needed.\n",
      "2024-05-12 15:59:58,965 - INFO - Data for PCAR is up-to-date. No download needed.\n",
      "2024-05-12 16:00:00,970 - INFO - Data for PKG is up-to-date. No download needed.\n",
      "2024-05-12 16:00:02,979 - INFO - Data for PANW is up-to-date. No download needed.\n",
      "2024-05-12 16:00:04,985 - INFO - Data for PARA is up-to-date. No download needed.\n",
      "2024-05-12 16:00:06,995 - INFO - Data for PH is up-to-date. No download needed.\n",
      "2024-05-12 16:00:09,008 - INFO - Data for PAYX is up-to-date. No download needed.\n",
      "2024-05-12 16:00:11,014 - INFO - Data for PAYC is up-to-date. No download needed.\n",
      "2024-05-12 16:00:13,023 - INFO - Data for PYPL is up-to-date. No download needed.\n",
      "2024-05-12 16:00:15,035 - INFO - Data for PNR is up-to-date. No download needed.\n",
      "2024-05-12 16:00:17,046 - INFO - Data for PEP is up-to-date. No download needed.\n",
      "2024-05-12 16:00:19,058 - INFO - Data for PFE is up-to-date. No download needed.\n",
      "2024-05-12 16:00:21,066 - INFO - Data for PCG is up-to-date. No download needed.\n",
      "2024-05-12 16:00:23,079 - INFO - Data for PM is up-to-date. No download needed.\n",
      "2024-05-12 16:00:25,086 - INFO - Data for PSX is up-to-date. No download needed.\n",
      "2024-05-12 16:00:27,098 - INFO - Data for PNW is up-to-date. No download needed.\n",
      "2024-05-12 16:00:29,105 - INFO - Data for PNC is up-to-date. No download needed.\n",
      "2024-05-12 16:00:31,114 - INFO - Data for POOL is up-to-date. No download needed.\n",
      "2024-05-12 16:00:33,118 - INFO - Data for PPG is up-to-date. No download needed.\n",
      "2024-05-12 16:00:35,120 - INFO - Data for PPL is up-to-date. No download needed.\n",
      "2024-05-12 16:00:37,126 - INFO - Data for PFG is up-to-date. No download needed.\n",
      "2024-05-12 16:00:39,130 - INFO - Data for PG is up-to-date. No download needed.\n",
      "2024-05-12 16:00:41,135 - INFO - Data for PGR is up-to-date. No download needed.\n",
      "2024-05-12 16:00:43,142 - INFO - Data for PLD is up-to-date. No download needed.\n",
      "2024-05-12 16:00:45,146 - INFO - Data for PRU is up-to-date. No download needed.\n",
      "2024-05-12 16:00:47,153 - INFO - Data for PEG is up-to-date. No download needed.\n",
      "2024-05-12 16:00:49,159 - INFO - Data for PTC is up-to-date. No download needed.\n",
      "2024-05-12 16:00:51,166 - INFO - Data for PSA is up-to-date. No download needed.\n",
      "2024-05-12 16:00:53,174 - INFO - Data for PHM is up-to-date. No download needed.\n",
      "2024-05-12 16:00:55,181 - INFO - Data for QRVO is up-to-date. No download needed.\n",
      "2024-05-12 16:00:57,188 - INFO - Data for PWR is up-to-date. No download needed.\n",
      "2024-05-12 16:00:59,191 - INFO - Data for QCOM is up-to-date. No download needed.\n",
      "2024-05-12 16:01:01,193 - INFO - Data for DGX is up-to-date. No download needed.\n",
      "2024-05-12 16:01:03,200 - INFO - Data for RL is up-to-date. No download needed.\n",
      "2024-05-12 16:01:05,202 - INFO - Data for RJF is up-to-date. No download needed.\n",
      "2024-05-12 16:01:07,209 - INFO - Data for RTX is up-to-date. No download needed.\n",
      "2024-05-12 16:01:09,215 - INFO - Data for O is up-to-date. No download needed.\n",
      "2024-05-12 16:01:11,217 - INFO - Data for REG is up-to-date. No download needed.\n",
      "2024-05-12 16:01:13,224 - INFO - Data for REGN is up-to-date. No download needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 16:01:15,226 - INFO - Data for RF is up-to-date. No download needed.\n",
      "2024-05-12 16:01:17,229 - INFO - Data for RSG is up-to-date. No download needed.\n",
      "2024-05-12 16:01:19,231 - INFO - Data for RMD is up-to-date. No download needed.\n",
      "2024-05-12 16:01:21,235 - INFO - Data for RVTY is up-to-date. No download needed.\n",
      "2024-05-12 16:01:23,244 - INFO - Data for RHI is up-to-date. No download needed.\n",
      "2024-05-12 16:01:25,248 - INFO - Data for ROK is up-to-date. No download needed.\n",
      "2024-05-12 16:01:27,255 - INFO - Data for ROL is up-to-date. No download needed.\n",
      "2024-05-12 16:01:29,259 - INFO - Data for ROP is up-to-date. No download needed.\n",
      "2024-05-12 16:01:31,266 - INFO - Data for ROST is up-to-date. No download needed.\n",
      "2024-05-12 16:01:33,269 - INFO - Data for RCL is up-to-date. No download needed.\n",
      "2024-05-12 16:01:35,273 - INFO - Data for SPGI is up-to-date. No download needed.\n",
      "2024-05-12 16:01:37,276 - INFO - Data for CRM is up-to-date. No download needed.\n",
      "2024-05-12 16:01:39,282 - INFO - Data for SBAC is up-to-date. No download needed.\n",
      "2024-05-12 16:01:41,289 - INFO - Data for SLB is up-to-date. No download needed.\n",
      "2024-05-12 16:01:43,294 - INFO - Data for STX is up-to-date. No download needed.\n",
      "2024-05-12 16:01:45,302 - INFO - Data for SRE is up-to-date. No download needed.\n",
      "2024-05-12 16:01:47,306 - INFO - Data for NOW is up-to-date. No download needed.\n",
      "2024-05-12 16:01:49,313 - INFO - Data for SHW is up-to-date. No download needed.\n",
      "2024-05-12 16:01:51,320 - INFO - Data for SPG is up-to-date. No download needed.\n",
      "2024-05-12 16:01:53,323 - INFO - Data for SWKS is up-to-date. No download needed.\n",
      "2024-05-12 16:01:55,330 - INFO - Data for SJM is up-to-date. No download needed.\n",
      "2024-05-12 16:01:57,337 - INFO - Data for SNA is up-to-date. No download needed.\n",
      "2024-05-12 16:01:59,341 - INFO - Data for SOLV is outdated or missing. Downloading the latest data.\n",
      "2024-05-12 16:01:59,510 - ERROR - An error occurred while processing SOLV: HTTP Error 400: Bad Request\n",
      "2024-05-12 16:01:59,515 - INFO - Data for SO is up-to-date. No download needed.\n",
      "2024-05-12 16:02:01,521 - INFO - Data for LUV is up-to-date. No download needed.\n",
      "2024-05-12 16:02:03,528 - INFO - Data for SWK is up-to-date. No download needed.\n",
      "2024-05-12 16:02:05,533 - INFO - Data for SBUX is up-to-date. No download needed.\n",
      "2024-05-12 16:02:07,537 - INFO - Data for STT is up-to-date. No download needed.\n",
      "2024-05-12 16:02:09,540 - INFO - Data for STLD is up-to-date. No download needed.\n",
      "2024-05-12 16:02:11,544 - INFO - Data for STE is up-to-date. No download needed.\n",
      "2024-05-12 16:02:13,548 - INFO - Data for SYK is up-to-date. No download needed.\n",
      "2024-05-12 16:02:15,555 - INFO - Data for SMCI is up-to-date. No download needed.\n",
      "2024-05-12 16:02:17,560 - INFO - Data for SYF is up-to-date. No download needed.\n",
      "2024-05-12 16:02:19,565 - INFO - Data for SNPS is up-to-date. No download needed.\n",
      "2024-05-12 16:02:21,568 - INFO - Data for SYY is up-to-date. No download needed.\n",
      "2024-05-12 16:02:23,574 - INFO - Data for TMUS is up-to-date. No download needed.\n",
      "2024-05-12 16:02:25,580 - INFO - Data for TROW is up-to-date. No download needed.\n",
      "2024-05-12 16:02:27,588 - INFO - Data for TTWO is up-to-date. No download needed.\n",
      "2024-05-12 16:02:29,591 - INFO - Data for TPR is up-to-date. No download needed.\n",
      "2024-05-12 16:02:31,597 - INFO - Data for TRGP is up-to-date. No download needed.\n",
      "2024-05-12 16:02:33,603 - INFO - Data for TGT is up-to-date. No download needed.\n",
      "2024-05-12 16:02:35,608 - INFO - Data for TEL is up-to-date. No download needed.\n",
      "2024-05-12 16:02:37,615 - INFO - Data for TDY is up-to-date. No download needed.\n",
      "2024-05-12 16:02:39,617 - INFO - Data for TFX is up-to-date. No download needed.\n",
      "2024-05-12 16:02:41,624 - INFO - Data for TER is up-to-date. No download needed.\n",
      "2024-05-12 16:02:43,627 - INFO - Data for TSLA is up-to-date. No download needed.\n",
      "2024-05-12 16:02:45,629 - INFO - Data for TXN is up-to-date. No download needed.\n",
      "2024-05-12 16:02:47,636 - INFO - Data for TXT is up-to-date. No download needed.\n",
      "2024-05-12 16:02:49,644 - INFO - Data for TMO is up-to-date. No download needed.\n",
      "2024-05-12 16:02:51,647 - INFO - Data for TJX is up-to-date. No download needed.\n",
      "2024-05-12 16:02:53,651 - INFO - Data for TSCO is up-to-date. No download needed.\n",
      "2024-05-12 16:02:55,654 - INFO - Data for TT is up-to-date. No download needed.\n",
      "2024-05-12 16:02:57,657 - INFO - Data for TDG is up-to-date. No download needed.\n",
      "2024-05-12 16:02:59,662 - INFO - Data for TRV is up-to-date. No download needed.\n",
      "2024-05-12 16:03:01,669 - INFO - Data for TRMB is up-to-date. No download needed.\n",
      "2024-05-12 16:03:03,672 - INFO - Data for TFC is up-to-date. No download needed.\n",
      "2024-05-12 16:03:05,679 - INFO - Data for TYL is up-to-date. No download needed.\n",
      "2024-05-12 16:03:07,684 - INFO - Data for TSN is up-to-date. No download needed.\n",
      "2024-05-12 16:03:09,687 - INFO - Data for USB is up-to-date. No download needed.\n",
      "2024-05-12 16:03:11,693 - INFO - Data for UBER is up-to-date. No download needed.\n",
      "2024-05-12 16:03:13,697 - INFO - Data for UDR is up-to-date. No download needed.\n",
      "2024-05-12 16:03:15,704 - INFO - Data for ULTA is up-to-date. No download needed.\n",
      "2024-05-12 16:03:17,710 - INFO - Data for UNP is up-to-date. No download needed.\n",
      "2024-05-12 16:03:19,715 - INFO - Data for UAL is up-to-date. No download needed.\n",
      "2024-05-12 16:03:21,717 - INFO - Data for UPS is up-to-date. No download needed.\n",
      "2024-05-12 16:03:23,724 - INFO - Data for URI is up-to-date. No download needed.\n",
      "2024-05-12 16:03:25,731 - INFO - Data for UNH is up-to-date. No download needed.\n",
      "2024-05-12 16:03:27,737 - INFO - Data for UHS is up-to-date. No download needed.\n",
      "2024-05-12 16:03:29,741 - INFO - Data for VLO is up-to-date. No download needed.\n",
      "2024-05-12 16:03:31,744 - INFO - Data for VTR is up-to-date. No download needed.\n",
      "2024-05-12 16:03:33,746 - INFO - Data for VLTO is up-to-date. No download needed.\n",
      "2024-05-12 16:03:35,753 - INFO - Data for VRSN is up-to-date. No download needed.\n",
      "2024-05-12 16:03:37,758 - INFO - Data for VRSK is up-to-date. No download needed.\n",
      "2024-05-12 16:03:39,764 - INFO - Data for VZ is up-to-date. No download needed.\n",
      "2024-05-12 16:03:41,771 - INFO - Data for VRTX is up-to-date. No download needed.\n",
      "2024-05-12 16:03:43,777 - INFO - Data for VTRS is up-to-date. No download needed.\n",
      "2024-05-12 16:03:45,784 - INFO - Data for VICI is up-to-date. No download needed.\n",
      "2024-05-12 16:03:47,786 - INFO - Data for V is up-to-date. No download needed.\n",
      "2024-05-12 16:03:49,793 - INFO - Data for VMC is up-to-date. No download needed.\n",
      "2024-05-12 16:03:51,798 - INFO - Data for WRB is up-to-date. No download needed.\n",
      "2024-05-12 16:03:53,805 - INFO - Data for WAB is up-to-date. No download needed.\n",
      "2024-05-12 16:03:55,814 - INFO - Data for WBA is up-to-date. No download needed.\n",
      "2024-05-12 16:03:57,817 - INFO - Data for WMT is up-to-date. No download needed.\n",
      "2024-05-12 16:03:59,824 - INFO - Data for DIS is up-to-date. No download needed.\n",
      "2024-05-12 16:04:01,831 - INFO - Data for WBD is up-to-date. No download needed.\n",
      "2024-05-12 16:04:03,838 - INFO - Data for WM is up-to-date. No download needed.\n",
      "2024-05-12 16:04:05,839 - INFO - Data for WAT is up-to-date. No download needed.\n",
      "2024-05-12 16:04:07,847 - INFO - Data for WEC is up-to-date. No download needed.\n",
      "2024-05-12 16:04:09,851 - INFO - Data for WFC is up-to-date. No download needed.\n",
      "2024-05-12 16:04:11,856 - INFO - Data for WELL is up-to-date. No download needed.\n",
      "2024-05-12 16:04:13,863 - INFO - Data for WST is up-to-date. No download needed.\n",
      "2024-05-12 16:04:15,870 - INFO - Data for WDC is up-to-date. No download needed.\n",
      "2024-05-12 16:04:17,875 - INFO - Data for WRK is up-to-date. No download needed.\n",
      "2024-05-12 16:04:19,881 - INFO - Data for WY is up-to-date. No download needed.\n",
      "2024-05-12 16:04:21,886 - INFO - Data for WMB is up-to-date. No download needed.\n",
      "2024-05-12 16:04:23,889 - INFO - Data for WTW is up-to-date. No download needed.\n",
      "2024-05-12 16:04:25,897 - INFO - Data for GWW is up-to-date. No download needed.\n",
      "2024-05-12 16:04:27,904 - INFO - Data for WYNN is up-to-date. No download needed.\n",
      "2024-05-12 16:04:29,907 - INFO - Data for XEL is up-to-date. No download needed.\n",
      "2024-05-12 16:04:31,913 - INFO - Data for XYL is up-to-date. No download needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 16:04:33,922 - INFO - Data for YUM is up-to-date. No download needed.\n",
      "2024-05-12 16:04:35,927 - INFO - Data for ZBRA is up-to-date. No download needed.\n",
      "2024-05-12 16:04:37,935 - INFO - Data for ZBH is up-to-date. No download needed.\n",
      "2024-05-12 16:04:39,940 - INFO - Data for ZTS is up-to-date. No download needed.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "OUTPUT_FILE_TEMPLATE = \"aapl_historical_data_{time_period}_{show}_{frequency}.csv\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "BASE_URL_TEMPLATE = \"https://finance.yahoo.com/quote/{}/history\"  # URL template to be formatted with ticker symbol\n",
    "OUTPUT_FILE = \"aapl_historical_data.csv\"\n",
    "DATE_RANGE_ID = 'date-range-selector'  # Update this with the actual ID or selector for the date range element\n",
    "FREQUENCY_SELECTOR = 'frequency-selector'  # Update this with the actual ID or selector for the frequency dropdown\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "CSV_FILE_PATH = \"./sp500_companies.csv\"\n",
    "DOWNLOAD_DIRECTORY = './yahoo_/yahoo_sp500/'\n",
    "\n",
    "def setup_driver():\n",
    "    options = FirefoxOptions()\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    return driver\n",
    "\n",
    "def is_file_outdated(file_path):\n",
    "    \"\"\"Check if the existing file is outdated based on its date in the filename.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return True  # File does not exist, so it is considered outdated\n",
    "\n",
    "    # Extract the date part from the filename, assuming it's formatted as 'Ticker_YYYYMMDD.csv'\n",
    "    filename = os.path.basename(file_path)\n",
    "    try:\n",
    "        # Attempt to parse the date from the filename, considering filename format 'Ticker_YYYYMMDD.csv'\n",
    "        date_str = filename.split('_')[-1].split('.')[0]  # Split on underscore, then remove '.csv'\n",
    "        file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        \n",
    "        # Compare file date to today's date\n",
    "        today = datetime.now()\n",
    "        return file_date.date() < today.date()\n",
    "    except ValueError as e:\n",
    "        # Log an error if date parsing fails\n",
    "        logging.error(f\"Error parsing date from filename {filename}: {str(e)}\")\n",
    "        return False  # Assume file is not outdated if we cannot parse the date\n",
    "\n",
    "def is_today_file_exists(filepath):\n",
    "    \"\"\"Check if today's file exists.\"\"\"\n",
    "    return os.path.exists(filepath)\n",
    "\n",
    "def remove_old_file(download_directory, ticker):\n",
    "    \"\"\"Remove the file from the previous day if it exists.\"\"\"\n",
    "    yesterday = datetime.now() - timedelta(days=1)\n",
    "    old_filename = f\"{ticker}_{yesterday.strftime('%Y%m%d')}.csv\"\n",
    "    old_filepath = os.path.join(download_directory, old_filename)\n",
    "    if os.path.exists(old_filepath):\n",
    "        os.remove(old_filepath)\n",
    "        logging.info(f\"Removed old file: {old_filepath}\")\n",
    "\n",
    "def check_and_download_csv(ticker, download_directory):\n",
    "    today_str = datetime.now().strftime('%Y%m%d')\n",
    "    filename = f\"{ticker}_{today_str}.csv\"\n",
    "    file_path = os.path.join(download_directory, filename)\n",
    "    \n",
    "    if not is_today_file_exists(file_path):\n",
    "        logging.info(f\"Data for {ticker} is outdated or missing. Downloading the latest data.\")\n",
    "        csv_download_url = f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1=-252374400&period2=1699142400&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "        download_csv(csv_download_url, filename, download_directory)\n",
    "        remove_old_file(download_directory, ticker)\n",
    "    else:\n",
    "        logging.info(f\"Data for {ticker} is up-to-date. No download needed.\")\n",
    "\n",
    "def download_file(file_path):\n",
    "    download_url = \"http://example.com/download.csv\"  # This URL should be dynamically constructed if needed\n",
    "    urllib.request.urlretrieve(download_url, file_path)\n",
    "    logging.info(f\"Downloaded {file_path}\")\n",
    "\n",
    "def read_tickers(file_path):\n",
    "    with open(file_path, mode='r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        return [row['Ticker'] for row in reader]  # Ensure column name matches your CSV\n",
    "\n",
    "# Use logging in your functions\n",
    "def navigate_to_page(driver, url):\n",
    "    try:\n",
    "        logging.info(f\"Navigating to {url}\")\n",
    "        driver.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred while trying to navigate to the page.\")\n",
    "        logging.error(e)\n",
    "\n",
    "def select_time_period(driver, period):\n",
    "    try:\n",
    "        logging.info(f\"Selecting time period: {period}\")\n",
    "        \n",
    "        # Click the date range dropdown to reveal the options\n",
    "        date_range_dropdown = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"svg[data-icon='CoreArrowDown']\"))\n",
    "        )\n",
    "        logging.info(\"Date range dropdown found and clickable.\")\n",
    "        \n",
    "        date_range_dropdown.click()\n",
    "        logging.info(\"Date range dropdown clicked.\")\n",
    "\n",
    "        # Now that the dropdown is open, click the 'Max' option\n",
    "        max_option = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[@data-value='MAX']\"))\n",
    "        )\n",
    "        logging.info(\"Max option found and clickable.\")\n",
    "        \n",
    "        # Here you can add code to verify if the correct option is being selected\n",
    "        if max_option.get_attribute('data-value') == 'MAX':\n",
    "            logging.info(\"Correct 'Max' option is present.\")\n",
    "        else:\n",
    "            logging.warning(\"The 'Max' option does not have the expected 'data-value' attribute.\")\n",
    "\n",
    "        max_option.click()\n",
    "        logging.info(\"Max option clicked.\")\n",
    "\n",
    "        # After clicking, you can also verify the current selected date range\n",
    "        # This assumes that there's an element that reflects the selected date range.\n",
    "        # You may need to update the selector as per the actual website structure.\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        logging.error(f\"Timed out waiting for time period option: {period}\")\n",
    "        logging.error(e)\n",
    "    except NoSuchElementException as e:\n",
    "        logging.error(f\"Could not find the time period option: {period}\")\n",
    "        logging.error(e)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while selecting time period: {period}\")\n",
    "        logging.error(e)\n",
    "\n",
    "def select_frequency(driver, frequency):\n",
    "    try:\n",
    "        logging.info(f\"Selecting frequency: {frequency}\")\n",
    "        # Add additional logging if necessary\n",
    "        # For example, log the current URL or take a screenshot\n",
    "        current_url = driver.current_url\n",
    "        logging.info(f\"Current URL: {current_url}\")\n",
    "\n",
    "        # Your code to select frequency here...\n",
    "\n",
    "        # After selecting, add an explicit wait for the page to load or for the element to be clickable\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'the-id-of-the-frequency-dropdown'))\n",
    "        )\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        logging.error(f\"Timed out waiting for frequency option: {frequency}\")\n",
    "        logging.error(e)\n",
    "    except NoSuchElementException as e:\n",
    "        logging.error(f\"Could not find the frequency option: {frequency}\")\n",
    "        logging.error(e)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while selecting frequency: {frequency}\")\n",
    "        logging.error(e)\n",
    "        # Optional: Take a screenshot on error\n",
    "        driver.get_screenshot_as_file(\"error_screenshot.png\")\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "def download_csv(download_url, filename, download_directory):\n",
    "    # Ensure the download directory exists\n",
    "    if not os.path.exists(download_directory):\n",
    "        os.makedirs(download_directory)\n",
    "    # Define the full file path\n",
    "    filepath = os.path.join(download_directory, filename)\n",
    "    # Use urllib to download the file\n",
    "    urllib.request.urlretrieve(download_url, filepath)\n",
    "    logging.info(f\"File downloaded: {filepath}\")\n",
    "\n",
    "def read_tickers_from_csv(csv_file, column_name):\n",
    "    tickers = []\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if column_name in row:\n",
    "                tickers.append(row[column_name])\n",
    "    return tickers\n",
    "\n",
    "# Function to check if the file was downloaded more than 24 hours ago\n",
    "def is_file_old(filepath, hours=24):\n",
    "    if not os.path.exists(filepath):\n",
    "        return True\n",
    "    now = datetime.now()\n",
    "    modified_time = datetime.fromtimestamp(os.path.getmtime(filepath))\n",
    "    return (now - modified_time) > timedelta(hours=hours)\n",
    "\n",
    "def main():\n",
    "    # Constants\n",
    "    CSV_FILE = \"./sp500_companies.csv\"\n",
    "    COLUMN_NAME = \"Ticker\"\n",
    "    DOWNLOAD_DIRECTORY = './yahoo_/yahoo_sp500/'\n",
    "\n",
    "    # Read tickers from CSV\n",
    "    tickers = read_tickers_from_csv(CSV_FILE, COLUMN_NAME)\n",
    "\n",
    "    # Iterate over tickers\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Prepare the CSV download URL and filename to include the current date for comparison\n",
    "            today_str = datetime.now().strftime('%Y%m%d')\n",
    "            csv_download_url = f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1=-252374400&period2=1699142400&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "            filename = f\"{ticker}_{today_str}.csv\"\n",
    "            filepath = os.path.join(DOWNLOAD_DIRECTORY, filename)\n",
    "\n",
    "            # Check if the file is outdated or does not exist\n",
    "            if is_file_outdated(filepath):\n",
    "                logging.info(f\"Data for {ticker} is outdated or missing. Downloading the latest data.\")\n",
    "                download_csv(csv_download_url, filename, DOWNLOAD_DIRECTORY)\n",
    "                logging.info(f\"File for {ticker} downloaded successfully.\")\n",
    "            else:\n",
    "                logging.info(f\"Data for {ticker} is up-to-date. No download needed.\")\n",
    "            \n",
    "            # Wait before making the next request\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while processing {ticker}: {str(e)}\")\n",
    "            # Optionally, add ticker to a list or file for failed attempts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743b7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f686277d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f515cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b505d81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 17:32:34,151 - ERROR - An error occurred while processing .\n",
      "2024-05-12 17:32:34,152 - ERROR - HTTP Error 404: Not Found\n",
      "2024-05-12 17:32:34,291 - ERROR - An error occurred while processing BRK.B.\n",
      "2024-05-12 17:32:34,292 - ERROR - HTTP Error 404: Not Found\n",
      "2024-05-12 17:32:34,422 - ERROR - An error occurred while processing GEV.\n",
      "2024-05-12 17:32:34,424 - ERROR - HTTP Error 400: Bad Request\n",
      "2024-05-12 17:32:34,555 - ERROR - An error occurred while processing SOLV.\n",
      "2024-05-12 17:32:34,556 - ERROR - HTTP Error 400: Bad Request\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "OUTPUT_FILE_TEMPLATE = \"aapl_historical_data_{time_period}_{show}_{frequency}.csv\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "BASE_URL_TEMPLATE = \"https://finance.yahoo.com/quote/{}/div\"  # URL template to be formatted with ticker symbol\n",
    "OUTPUT_FILE = \"aapl_historical_data.csv\"\n",
    "DATE_RANGE_ID = 'date-range-selector'  # Update this with the actual ID or selector for the date range element\n",
    "FREQUENCY_SELECTOR = 'frequency-selector'  # Update this with the actual ID or selector for the frequency dropdown\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "CSV_FILE_PATH = \"./sp500_companies.csv\"\n",
    "DOWNLOAD_DIRECTORY = './yahoo_/yahoo_sp500_div/'\n",
    "\n",
    "def setup_driver():\n",
    "    options = FirefoxOptions()\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    return driver\n",
    "\n",
    "def check_and_download_csv(file_path, max_age_hours=24):\n",
    "    if os.path.exists(file_path):\n",
    "        file_mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "        if datetime.now() - file_mod_time > timedelta(hours=max_age_hours):\n",
    "            logging.info(f\"File {file_path} is older than {max_age_hours} hours, re-downloading.\")\n",
    "            download_file(file_path)\n",
    "        else:\n",
    "            logging.info(f\"File {file_path} is up-to-date, no need to re-download.\")\n",
    "    else:\n",
    "        logging.info(f\"File {file_path} does not exist, downloading now.\")\n",
    "        download_file(file_path)\n",
    "\n",
    "def download_file(file_path):\n",
    "    download_url = \"http://example.com/download.csv\"  # This URL should be dynamically constructed if needed\n",
    "    urllib.request.urlretrieve(download_url, file_path)\n",
    "    logging.info(f\"Downloaded {file_path}\")\n",
    "\n",
    "def read_tickers(file_path):\n",
    "    with open(file_path, mode='r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        return [row['Ticker'] for row in reader]  # Ensure column name matches your CSV\n",
    "\n",
    "# Use logging in your functions\n",
    "def navigate_to_page(driver, url):\n",
    "    try:\n",
    "        logging.info(f\"Navigating to {url}\")\n",
    "        driver.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred while trying to navigate to the page.\")\n",
    "        logging.error(e)\n",
    "\n",
    "def select_time_period(driver, period):\n",
    "    try:\n",
    "        logging.info(f\"Selecting time period: {period}\")\n",
    "        \n",
    "        # Click the date range dropdown to reveal the options\n",
    "        date_range_dropdown = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"svg[data-icon='CoreArrowDown']\"))\n",
    "        )\n",
    "        logging.info(\"Date range dropdown found and clickable.\")\n",
    "        \n",
    "        date_range_dropdown.click()\n",
    "        logging.info(\"Date range dropdown clicked.\")\n",
    "\n",
    "        # Now that the dropdown is open, click the 'Max' option\n",
    "        max_option = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[@data-value='MAX']\"))\n",
    "        )\n",
    "        logging.info(\"Max option found and clickable.\")\n",
    "        \n",
    "        # Here you can add code to verify if the correct option is being selected\n",
    "        if max_option.get_attribute('data-value') == 'MAX':\n",
    "            logging.info(\"Correct 'Max' option is present.\")\n",
    "        else:\n",
    "            logging.warning(\"The 'Max' option does not have the expected 'data-value' attribute.\")\n",
    "\n",
    "        max_option.click()\n",
    "        logging.info(\"Max option clicked.\")\n",
    "\n",
    "        # After clicking, you can also verify the current selected date range\n",
    "        # This assumes that there's an element that reflects the selected date range.\n",
    "        # You may need to update the selector as per the actual website structure.\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        logging.error(f\"Timed out waiting for time period option: {period}\")\n",
    "        logging.error(e)\n",
    "    except NoSuchElementException as e:\n",
    "        logging.error(f\"Could not find the time period option: {period}\")\n",
    "        logging.error(e)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while selecting time period: {period}\")\n",
    "        logging.error(e)\n",
    "\n",
    "def select_frequency(driver, frequency):\n",
    "    try:\n",
    "        logging.info(f\"Selecting frequency: {frequency}\")\n",
    "        # Add additional logging if necessary\n",
    "        # For example, log the current URL or take a screenshot\n",
    "        current_url = driver.current_url\n",
    "        logging.info(f\"Current URL: {current_url}\")\n",
    "\n",
    "        # Your code to select frequency here...\n",
    "\n",
    "        # After selecting, add an explicit wait for the page to load or for the element to be clickable\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'the-id-of-the-frequency-dropdown'))\n",
    "        )\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        logging.error(f\"Timed out waiting for frequency option: {frequency}\")\n",
    "        logging.error(e)\n",
    "    except NoSuchElementException as e:\n",
    "        logging.error(f\"Could not find the frequency option: {frequency}\")\n",
    "        logging.error(e)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while selecting frequency: {frequency}\")\n",
    "        logging.error(e)\n",
    "        # Optional: Take a screenshot on error\n",
    "        driver.get_screenshot_as_file(\"error_screenshot.png\")\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "def download_csv(download_url, filename, download_directory='./yahoo_/yahoo_sp500_div/'):\n",
    "    # Ensure the download directory exists\n",
    "    if not os.path.exists(download_directory):\n",
    "        os.makedirs(download_directory)\n",
    "    # Define the full file path\n",
    "    filepath = os.path.join(download_directory, filename)\n",
    "    # Use urllib to download the file\n",
    "    urllib.request.urlretrieve(download_url, filepath)\n",
    "    logging.info(f\"File downloaded: {filepath}\")\n",
    "\n",
    "def read_tickers_from_csv(csv_file, column_name):\n",
    "    tickers = []\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if column_name in row:\n",
    "                tickers.append(row[column_name])\n",
    "    return tickers\n",
    "\n",
    "# Function to check if the file was downloaded more than 24 hours ago\n",
    "def is_file_old(filepath, hours=24):\n",
    "    if not os.path.exists(filepath):\n",
    "        return True\n",
    "    now = datetime.now()\n",
    "    modified_time = datetime.fromtimestamp(os.path.getmtime(filepath))\n",
    "    return (now - modified_time) > timedelta(hours=hours)\n",
    "\n",
    "def main():\n",
    "    # Constants\n",
    "    CSV_FILE = \"./sp500_companies.csv\"\n",
    "    COLUMN_NAME = \"Ticker\"\n",
    "    DOWNLOAD_DIRECTORY = './yahoo_/yahoo_sp500_div/'\n",
    "\n",
    "    # Read tickers from CSV\n",
    "    tickers = read_tickers_from_csv(CSV_FILE, COLUMN_NAME)\n",
    "\n",
    "    # Iterate over tickers\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Prepare the CSV download URL\n",
    "            csv_download_url = f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1=-252374400&period2=1699142400&interval=1d&events=div&includeAdjustedClose=true\"\n",
    "            filename = f\"{ticker}.csv\"\n",
    "            filepath = os.path.join(DOWNLOAD_DIRECTORY, filename)\n",
    "\n",
    "            # Check if file needs to be downloaded\n",
    "            if is_file_old(filepath):\n",
    "                # Download CSV file\n",
    "                download_csv(csv_download_url, filename, DOWNLOAD_DIRECTORY)\n",
    "            \n",
    "                # Wait before making the next request\n",
    "                time.sleep(2)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while processing {ticker}.\")\n",
    "            logging.error(e)\n",
    "            # Optionally, add ticker to a list or file for failed attempts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ganpati@27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0718600",
   "metadata": {},
   "outputs": [],
   "source": [
    "StockX@27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240653b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "passtime1995@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
