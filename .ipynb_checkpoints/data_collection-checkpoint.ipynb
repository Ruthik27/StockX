{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4adfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c04333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to sp500_companies.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S&P_500_companies'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# If the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the <tbody> element in the HTML where the data resides\n",
    "    table_body = soup.find('tbody')\n",
    "    \n",
    "    # Initialize a list to store your data\n",
    "    data = []\n",
    "    \n",
    "    # Find all <tr> elements\n",
    "    rows = table_body.find_all('tr')\n",
    "    for row in rows:\n",
    "        # Find all <td> elements in this row\n",
    "        cols = row.find_all('td')\n",
    "        \n",
    "        # Get the text from all the <td> elements and add to the list\n",
    "        data.append([ele.text.strip() for ele in cols])\n",
    "    \n",
    "    # Create a DataFrame from the data list\n",
    "    df = pd.DataFrame(data, columns=['Ticker', 'Company', 'Sector', 'Sub-Industry', 'Headquarters', 'Date First Added', 'CIK', 'Founded'])\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv('sp500_companies.csv', index=False)\n",
    "\n",
    "    print('Data scraped and saved to sp500_companies.csv')\n",
    "else:\n",
    "    print('Failed to retrieve the webpage. Status code:', response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c84efd1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for ticker in df['Ticker']:\n",
    "#    print(ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47cd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a88020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91be5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_tickers = ['MMM','AOS','ABT','ABBV','ACN','ADM','ADBE','ADP','AES','AFL','A','ABNB','APD','AKAM','ALK','ALB','ARE','ALGN','ALLE','LNT','ALL','GOOGL','GOOG','MO','AMZN','AMCR','AMD','AEE','AAL','AEP','AXP','AIG','AMT','AWK','AMP','AME','AMGN','APH','ADI','ANSS','AON','APA','AAPL','AMAT','APTV','ACGL','ANET','AJG','AIZ','T','ATO','ADSK','AZO','AVB','AVY','AXON','BKR','BALL','BAC','BBWI','BAX','BDX','WRB','BRK.B','BBY','BIO','TECH','BIIB','BLK','BX','BK','BA','BKNG','BWA','BXP','BSX','BMY','AVGO','BR','BRO','BF.B','BG','CHRW','CDNS','CZR','CPT','CPB','COF','CAH','KMX','CCL','CARR','CTLT','CAT','CBOE','CBRE','CDW','CE','COR','CNC','CNP','CDAY','CF','CRL','SCHW','CHTR','CVX','CMG','CB','CHD','CI','CINF','CTAS','CSCO','C','CFG','CLX','CME','CMS','KO','CTSH','CL','CMCSA','CMA','CAG','COP','ED','STZ','CEG','COO','CPRT','GLW','CTVA','CSGP','COST','CTRA','CCI','CSX','CMI','CVS','DHI','DHR','DRI','DVA','DE','DAL','XRAY','DVN','DXCM','FANG','DLR','DFS','DIS','DG','DLTR','D','DPZ','DOV','DOW','DTE','DUK','DD','EMN','ETN','EBAY','ECL','EIX','EW','EA','ELV','LLY','EMR','ENPH','ETR','EOG','EPAM','EQT','EFX','EQIX','EQR','ESS','EL','ETSY','EG','EVRG','ES','EXC','EXPE','EXPD','EXR','XOM','FFIV','FDS','FICO','FAST','FRT','FDX','FITB','FSLR','FE','FIS','FI','FLT','FMC','F','FTNT','FTV','FOXA','FOX','BEN','FCX','GRMN','IT','GEHC','GEN','GNRC','GD','GE','GIS','GM','GPC','GILD','GL','GPN','GS','HAL','HIG','HAS','HCA','PEAK','HSIC','HSY','HES','HPE','HLT','HOLX','HD','HON','HRL','HST','HWM','HPQ','HUBB','HUM','HBAN','HII','IBM','IEX','IDXX','ITW','ILMN','INCY','IR','PODD','INTC','ICE','IFF','IP','IPG','INTU','ISRG','IVZ','INVH','IQV','IRM','JBHT','JKHY','J','JNJ','JCI','JPM','JNPR','K','KVUE','KDP','KEY','KEYS','KMB','KIM','KMI','KLAC','KHC','KR','LHX','LH','LRCX','LW','LVS','LDOS','LEN','LIN','LYV','LKQ','LMT','L','LOW','LULU','LYB','MTB','MRO','MPC','MKTX','MAR','MMC','MLM','MAS','MA','MTCH','MKC','MCD','MCK','MDT','MRK','META','MET','MTD','MGM','MCHP','MU','MSFT','MAA','MRNA','MHK','MOH','TAP','MDLZ','MPWR','MNST','MCO','MS','MOS','MSI','MSCI','NDAQ','NTAP','NFLX','NEM','NWSA','NWS','NEE','NKE','NI','NDSN','NSC','NTRS','NOC','NCLH','NRG','NUE','NVDA','NVR','NXPI','ORLY','OXY','ODFL','OMC','ON','OKE','ORCL','OTIS','PCAR','PKG','PANW','PARA','PH','PAYX','PAYC','PYPL','PNR','PEP','PFE','PCG','PM','PSX','PNW','PXD','PNC','POOL','PPG','PPL','PFG','PG','PGR','PLD','PRU','PEG','PTC','PSA','PHM','QRVO','PWR','QCOM','DGX','RL','RJF','RTX','O','REG','REGN','RF','RSG','RMD','RVTY','RHI','ROK','ROL','ROP','ROST','RCL','SPGI','CRM','SBAC','SLB','STX','SEE','SRE','NOW','SHW','SPG','SWKS','SJM','SNA','SEDG','SO','LUV','SWK','SBUX','STT','STLD','STE','SYK','SYF','SNPS','SYY','TMUS','TROW','TTWO','TPR','TRGP','TGT','TEL','TDY','TFX','TER','TSLA','TXN','TXT','TMO','TJX','TSCO','TT','TDG','TRV','TRMB','TFC','TYL','TSN','USB','UDR','ULTA','UNP','UAL','UPS','URI','UNH','UHS','VLO','VTR','VLTO','VRSN','VRSK','VZ','VRTX','VFC','VTRS','VICI','V','VMC','WAB','WBA','WMT','WBD','WM','WAT','WEC','WFC','WELL','WST','WDC','WRK','WY','WHR','WMB','WTW','GWW','WYNN','XEL','XYL','YUM','ZBRA','ZBH','ZION','ZT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8923544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp500_tickers = ['UAL','UPS','URI','UNH','UHS','VLO','VTR','VLTO','VRSN','VRSK','VZ','VRTX','VFC','VTRS','VICI','V','VMC','WAB','WBA','WMT','WBD','WM','WAT','WEC','WFC','WELL','WST','WDC','WRK','WY','WHR','WMB','WTW','GWW','WYNN','XEL','XYL','YUM','ZBRA','ZBH','ZION','ZT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b505d81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import logging\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "OUTPUT_FILE_TEMPLATE = \"aapl_historical_data_{time_period}_{show}_{frequency}.csv\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "BASE_URL_TEMPLATE = \"https://finance.yahoo.com/quote/{}/history\"  # URL template to be formatted with ticker symbol\n",
    "OUTPUT_FILE = \"aapl_historical_data.csv\"\n",
    "DATE_RANGE_ID = 'date-range-selector'  # Update this with the actual ID or selector for the date range element\n",
    "FREQUENCY_SELECTOR = 'frequency-selector'  # Update this with the actual ID or selector for the frequency dropdown\n",
    "\n",
    "def setup_driver():\n",
    "    options = FirefoxOptions()\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    return driver\n",
    "\n",
    "# Use logging in your functions\n",
    "def navigate_to_page(driver, url):\n",
    "    try:\n",
    "        logging.info(f\"Navigating to {url}\")\n",
    "        driver.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred while trying to navigate to the page.\")\n",
    "        logging.error(e)\n",
    "\n",
    "def select_time_period(driver, period):\n",
    "    try:\n",
    "        logging.info(f\"Selecting time period: {period}\")\n",
    "        \n",
    "        # Click the date range dropdown to reveal the options\n",
    "        date_range_dropdown = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"svg[data-icon='CoreArrowDown']\"))\n",
    "        )\n",
    "        logging.info(\"Date range dropdown found and clickable.\")\n",
    "        \n",
    "        date_range_dropdown.click()\n",
    "        logging.info(\"Date range dropdown clicked.\")\n",
    "\n",
    "        # Now that the dropdown is open, click the 'Max' option\n",
    "        max_option = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[@data-value='MAX']\"))\n",
    "        )\n",
    "        logging.info(\"Max option found and clickable.\")\n",
    "        \n",
    "        # Here you can add code to verify if the correct option is being selected\n",
    "        if max_option.get_attribute('data-value') == 'MAX':\n",
    "            logging.info(\"Correct 'Max' option is present.\")\n",
    "        else:\n",
    "            logging.warning(\"The 'Max' option does not have the expected 'data-value' attribute.\")\n",
    "\n",
    "        max_option.click()\n",
    "        logging.info(\"Max option clicked.\")\n",
    "\n",
    "        # After clicking, you can also verify the current selected date range\n",
    "        # This assumes that there's an element that reflects the selected date range.\n",
    "        # You may need to update the selector as per the actual website structure.\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        logging.error(f\"Timed out waiting for time period option: {period}\")\n",
    "        logging.error(e)\n",
    "    except NoSuchElementException as e:\n",
    "        logging.error(f\"Could not find the time period option: {period}\")\n",
    "        logging.error(e)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while selecting time period: {period}\")\n",
    "        logging.error(e)\n",
    "\n",
    "def select_frequency(driver, frequency):\n",
    "    try:\n",
    "        logging.info(f\"Selecting frequency: {frequency}\")\n",
    "        # Add additional logging if necessary\n",
    "        # For example, log the current URL or take a screenshot\n",
    "        current_url = driver.current_url\n",
    "        logging.info(f\"Current URL: {current_url}\")\n",
    "\n",
    "        # Your code to select frequency here...\n",
    "\n",
    "        # After selecting, add an explicit wait for the page to load or for the element to be clickable\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'the-id-of-the-frequency-dropdown'))\n",
    "        )\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        logging.error(f\"Timed out waiting for frequency option: {frequency}\")\n",
    "        logging.error(e)\n",
    "    except NoSuchElementException as e:\n",
    "        logging.error(f\"Could not find the frequency option: {frequency}\")\n",
    "        logging.error(e)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while selecting frequency: {frequency}\")\n",
    "        logging.error(e)\n",
    "        # Optional: Take a screenshot on error\n",
    "        driver.get_screenshot_as_file(\"error_screenshot.png\")\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "def download_csv(download_url, filename, download_directory='./yahoo_/yahoo_sp500/'):\n",
    "    # Ensure the download directory exists\n",
    "    if not os.path.exists(download_directory):\n",
    "        os.makedirs(download_directory)\n",
    "    # Define the full file path\n",
    "    filepath = os.path.join(download_directory, filename)\n",
    "    # Use urllib to download the file\n",
    "    urllib.request.urlretrieve(download_url, filepath)\n",
    "    logging.info(f\"File downloaded: {filepath}\")\n",
    "\n",
    "def main():\n",
    "    # Other setup code...\n",
    "\n",
    "    with setup_driver() as driver:\n",
    "        for ticker in sp500_tickers:\n",
    "            try:\n",
    "                # Prepare the CSV download URL\n",
    "                csv_download_url = f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1=-252374400&period2=1699142400&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "                filename = f\"{ticker}.csv\"\n",
    "                # Download CSV file\n",
    "                download_csv(csv_download_url, filename)\n",
    "            \n",
    "                # Wait before making the next request\n",
    "                time.sleep(2)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"An error occurred while processing {ticker}.\")\n",
    "                logging.error(e)\n",
    "                # Optionally, add ticker to a list or file for failed attempts\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0f6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
